[{"title":"理论篇-iptables","date":"2017-11-14T08:30:53.000Z","path":"2017/11/14/理论篇-iptables/","text":"123456789101112131415网络包 |rule1 --Y--&gt; action1 | N |rule2 --Y--&gt; action2 |...... |ruleN --Y--&gt; actionN | N |默认规则 iptables按照顺序依次匹配规则，若匹配则执行相应的动作且停止匹配，否则继续匹配。 iptables有很多table: 管理本机进出的filter INPUT 进系统的包 OUTPUT 出系统的包 FORWARD 转发的包 管理后端主机的nat PREROUTING 进行路由判断之前要进行的规则 POSTROUTING 进行路由判断之后进行的规则 OUTPUT 发出去的包 管理特殊flag的mangle 自动的table 123456789101112131415161718# Generated by iptables-save v1.4.7 on Tue Nov 14 21:27:52 2017*nat:PREROUTING ACCEPT [167942:11284276]:POSTROUTING ACCEPT [57:3797]:OUTPUT ACCEPT [57:3797]COMMIT# Completed on Tue Nov 14 21:27:52 2017# Generated by iptables-save v1.4.7 on Tue Nov 14 21:27:52 2017*filter:INPUT DROP [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [190:18992]-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT # 允许本机发出的流量进入本机-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m tcp --dport 22 -j ACCEPTCOMMIT# Completed on Tue Nov 14 21:27:52 2017 routeflags的取值及意义 U (route is up): 该路由是启动的 H (target is a host): 目标是一个主机而非网域 G (use gateway): 需要使用外部的主机来传递封包 R (reinstate route for dynamic routing): 使用动态路由时恢复路由信息的旗标 D (dynamically installed by daemon or redirect): 设定为动态路由 M (modified from routing daemon or redirect): 路由已经被修改了 ! (reject route): 该路由被拒绝","tags":[{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"实战篇-常用运维工具","date":"2017-11-14T07:59:12.000Z","path":"2017/11/14/实战篇-常用运维工具/","text":"MRTG: 监控网络链路流量负载的工具","tags":[{"name":"运维工具","slug":"运维工具","permalink":"http://yoursite.com/tags/运维工具/"}]},{"title":"实战篇-svn","date":"2017-11-10T08:14:00.000Z","path":"2017/11/10/实战篇-svn/","text":"SVN资源库的校验通常，我们会使用rsync这样的工具来备份svn仓库，但是备份完之后的仓库到底完整性如何？我们无从得知。不过svn官方提供了校验命令，即svnadmin verify repo_path。但是，该命令只能按照顺序一个一个执行，不能充分利用多核的计算能力。本人写了一个可以利用多核计算能力的shell脚本。详见github","tags":[{"name":"svn","slug":"svn","permalink":"http://yoursite.com/tags/svn/"}]},{"title":"精华篇-基于mongodb的另类分布式存储架构","date":"2017-11-09T03:07:06.000Z","path":"2017/11/09/精华篇-基于mongodb的另类分布式存储架构/","text":"","tags":[]},{"title":"实战篇-httpd","date":"2017-11-06T09:16:04.000Z","path":"2017/11/06/实战篇-httpd/","text":"贴一片好文，以后有需要在记录。 httpd相关文章","tags":[{"name":"httpd","slug":"httpd","permalink":"http://yoursite.com/tags/httpd/"}]},{"title":"实战篇-dns","date":"2017-11-03T07:20:43.000Z","path":"2017/11/03/实战篇-dns/","text":"system info123456[root@centos-6-9 ~]# lsb_release -aLSB Version: :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarchDistributor ID: CentOSDescription: CentOS release 6.9 (Final)Release: 6.9Codename: Final install1yum install bind bind-chroot configure/etc/named.conf 1234567891011121314151617181920212223242526options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; allow-query &#123; any; &#125;; recursion yes; allow-transfer &#123; none; &#125;;&#125;;zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;;&#125;;zone &quot;centos.dog&quot; IN &#123; type master; file &quot;named.centos.dog&quot;;&#125;;//zone &quot;3.0.10.in-addr.arpa&quot; &#123;// type master;// file &quot;named.10.0.3&quot;;//&#125; /var/named/named.centos.dog 12345678910111213$TTL 600@ IN SOA master.centos.dog. dog.www.centos.dog. (2017110301 3H 15M 1W 1D)@ IN NS master.centos.dog.master.centos.dog. IN A 10.0.3.15@ IN MX 10 www.centos.dog.www.centos.dog. IN A 10.0.3.15linux.centos.dog. IN CNAME www.centos.dog.ftp.centos.dog. IN CNAME www.centos.dog.;test.centos.dog IN A 10.0.3. start stop1/etc/init.d/named start|stop|restart|status","tags":[{"name":"dns","slug":"dns","permalink":"http://yoursite.com/tags/dns/"}]},{"title":"理论篇-cdn","date":"2017-10-31T10:48:51.000Z","path":"2017/10/31/理论篇-dns/","text":"CDN的工作原则: 1. 挑选最优设备为用户服务 2. 如果某个内容被很多用户所需要，它就被缓存到距离用户最近的节点 CDN服务分类: 基于内容分类 网页加速(静态或动态) 流媒体加速 文件传输加速 应用协议加速 基于内容生成 静态的 动态的 常用的网站加速技术: 扩展技术 镜像技术 缓存技术 web cache关键性能指标 并发量 吞吐率 命中率 响应时间和丢包率 dns解析时间 建立连接时间 重定向时间 收到第一个包时间 图片下载时间 页面总下载时间 丢包率 内存存储就web cache而言，缓存对象大小平均为10~12KB。","tags":[{"name":"cdn","slug":"cdn","permalink":"http://yoursite.com/tags/cdn/"}]},{"title":"理论篇-svn","date":"2017-10-26T05:35:31.000Z","path":"2017/10/26/理论篇-svn/","text":"svn主张”主干开发 分支发布” 记住当需要创建多个分支，特别分支是为了并行数个开发而不是发布时，往往意味着有些事情不对了。 解决冲突有两种方式: 悲观锁和乐观锁。svn使用乐观锁。 1234567891011121314svn co remote_url local_project # 签出仓库svn commit -m &quot;xxx&quot; # 签入仓库svn update # 同步远程仓库svn propset svn proplistsvn propgetsvn propedit # 属性相关svn copy -m &quot;xxx&quot; remote_url/trunk remote_url/tags/v0.1 # 创建标签svn copy -m &quot;xxx&quot; remote_url/trunk remote_url/branches/v0.1 # 创建分支svn movesvn revert # 恢复svn resolved # 解决冲突svn blame # 忽略某些文件等功能都是使用属性实现的。 二进制文件和锁123svn propset svn:needs-lock true xxx.txt # 设置锁属性svn lock xxx.txt -m &quot;lock xxx.txt&quot; # 加锁 提交时自动解锁svn unlock --force remote_url/xxx.txt # 强制解锁 标签和分支命名规范 thing to name name style example release branch RB-rel RB-1.0 releases REL-rel REL-1.0 bug fix branches BUG-track BUG-3035 pre-bug fix PRE-track PRE-3035 post-bug fix POST-track POST-3035 developer experiments TRY-initials-desc TRY-MGM-cache-pages 标签和分支主要用于如下四个用途: 发布分支 发布 bug修复 开发人员试验 bug修复，可借助标签功能。","tags":[{"name":"svn","slug":"svn","permalink":"http://yoursite.com/tags/svn/"}]},{"title":"实战篇-todos","date":"2017-10-25T11:43:43.000Z","path":"2017/10/25/实战篇-todos/","text":"todos gitlab高可用方案调研 svn实践 CI/CD学习 相关工具链实践 PHABRICATOR sonar ANSIBLE docker jenkins ansible daily 2017-11-01 svn学习 2017-10-31 svn学习 2017-10-30 svn建站学习(svn+httpd, if.svnadmin) 2017-10-26 svn学习 2017-10-25 svn学习","tags":[{"name":"todo","slug":"todo","permalink":"http://yoursite.com/tags/todo/"}]},{"title":"实战篇-NFS(network file system)","date":"2017-10-23T08:04:04.000Z","path":"2017/10/23/实战篇-NFS-network-file-system/","text":"NFSNFS(network file system)主要是为了让不同的机器、不同的系统间共享数据。通常作为文件服务器来使用。 组成NFS由许多服务组成，所以需要占用很多端口，故需要RPC服务来告知客户端各个服务的端口信息。RPC服务的端口固定为: 111 备注:启动NFS服务的时候，先启动RPC服务。因为NFS服务需要向RPC服务注册端口号。 rpc.nfsd 验证用户登录权限 rpc.mounted 验证用户对文件的访问权限(-rwxrwxrwx owner group) rpc.lockd 管理文件的锁定状态，防止多用户写入 rpc.statd 检查文件的一致性 命令","tags":[{"name":"文件系统","slug":"文件系统","permalink":"http://yoursite.com/tags/文件系统/"}]},{"title":"理论篇-gitlab","date":"2017-10-19T07:27:16.000Z","path":"2017/10/19/理论篇-gitlab/","text":"gitlab架构使用的组件及功能 nginx: 主要负责请求路由及一些静态资源的访问 database: 持久化数据，比如(issues, merge requests etc) redis: task的缓存队列 sidekiq: 主要负责发送邮件，从redis中接收task unicorn: 一个ruby系的http框架，即我们的gitlab gitlab-shell: 负责处理ssh协议的请求 gitaly: 执行所有来自http或ssh的git操作 gitalygitaly是一个git rpc服务，用来处理所有gitlab产生的git操作。实现如下两个目标: 让git操作离数据更近 使用缓存或其他技术优化git服务 gitlab问题列表 remote gitlab you are not allowed to push code to protected branches on this project 该分支只能push request，然后由专人负责merge。不能直接push。 gitlab高可用文件和数据库备份1234# backupgitlab-rake gitlab:backup:create# restoregitlab-rake gitlab:backup:restore 从快照中恢复从快照中恢复比从备份中恢复要快。 多应用服务","tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"}]},{"title":"实战篇-构建rpm包","date":"2017-10-09T03:33:31.000Z","path":"2017/10/09/实战篇-构建rpm包/","text":"referencesRpmbuild Tutorial The magic behind configure, make, make install","tags":[{"name":"rpm","slug":"rpm","permalink":"http://yoursite.com/tags/rpm/"}]},{"title":"理论篇-负载均衡技术","date":"2017-09-30T01:37:10.000Z","path":"2017/09/30/实战篇-高可用架构实战/","text":"所有的高可用解决方案都是成本/复杂度与运行时间之间的权衡。 负载均衡技术有如下几个用途: 系统高可用 系统可扩展 负载均衡能力 要实现故障转移需要两个工具: ipvsadm和keepalived。(heartbeat也可实现类似功能，但配置相对复杂) lvs核心ipvsIPVS(IP Virtual Server)是故障转移的基础。IPVS供能由ipvsadm程序提供。 安装软件12yum install ipvsadmyum install keepalived 配置master配置 12345678910111213141516171819202122232425262728293031! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; xxx@xxx.com &#125; !smtp_server 127.0.0.1 !smtp_connect_timeout 30 router_id PROXY_LVS_GIT_TEST_M&#125;vrrp_instance VI_1 &#123; state MASTER interface eth2 virtual_router_id 100 priority 100 advert_int 5 !smtp_alert ! send an alert when this instance changes state from MASTER to BACKUP unicast_src_ip master_interface_ip # 单播方式 unicast_peer &#123; slave_interface_ip_1 slave_interface_ip_2 &#125; authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.153.227.43/22 &#125;&#125; slave配置 123456789101112131415161718192021222324252627! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; xxx@xxx.com &#125; !smtp_server 127.0.0.1 !smtp_connect_timeout 30 router_id PROXY_LVS_GIT_TEST_S&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth2 virtual_router_id 100 priority 50 advert_int 5 !smtp_alert ! send an alert when this instance changes state from MASTER to BACKUP nopreempt # 当master恢复时，自动回到BACKUP状态 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 10.153.227.43/22 &#125;&#125; 启动与停止12service keepalived startservice keepalived stop","tags":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"理论篇-构建SAAS的准则","date":"2017-09-25T11:22:11.000Z","path":"2017/09/25/理论篇-构建SAAS的准则/","text":"SAAS(software as a service)，软件即服务。该软件有如下几个特点: 开发环境配置自动化，为了最小化新开发人员加入的时间和成本 不要依赖底层操作系统，提供执行环境间的最大可移植性 杜绝对服务或系统管理员的依赖 减少开发环境与生产环境的差异性，提高持续开发的敏捷性 在对工具、架构或开发没有重大改变的情况下可扩展 要想实现SAAS，需要遵守以下12个准则: 代码库 依赖 配置 后端服务 构建、发布和运行 多进程 端口绑定 并发 可分配 开发环境与生产环境 日志 管理进程 referenceThe Twelve-Factor App","tags":[{"name":"saas","slug":"saas","permalink":"http://yoursite.com/tags/saas/"}]},{"title":"理论篇-经典论文系列","date":"2017-09-22T06:32:22.000Z","path":"2017/09/22/理论篇-经典论文系列/","text":"Architectural Styles andthe Design of Network-based Software Architectures","tags":[]},{"title":"理论篇-go","date":"2017-09-12T11:39:55.000Z","path":"2017/09/12/理论篇-go/","text":"CSP(communicating sequential processes) go 有i++ 没有–i，且i++是一个语句，不能被赋值，例如a = i++ go的格式要求非常严格。 go只有一种循环结构for 变量声明的几种方式 1234s := &quot;&quot; # 仅被使用在函数里var s string # 默认初始化为&quot;&quot;var s = &quot;&quot; # 该种方式不常用 除了声明多值时var s string = &quot;xxx&quot; # 给定初始化值 go提供指针，但不提供指针运算。 program structureNames25 keywords 12345break default func interface selectcase defer go map structchan else goto package switchconst fallthrough if range typecontinue for import return var 12345678Constants: true false iota nilTypes: int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string errorFunctions: make len cap new append copy close delete complex real imag panic recover 函数内定义的变量，作用域为函数。函数外定义的变量，作用域为包内的所有文件。以大写字母开头的变量名，其作用域为整个程序。小写字母开头的变量名，其作用域为包。go中更喜欢驼峰风格。 Declarations1four declarations: var const type func Variables1var name type = expression Short Variable Declarations:within a function, an alternate form called short variable declaration may be used to declare and initialize local variables. 1name := expression 12i, j = 0, 1 # declarationi, j = j, i # assignment 短变量声明中不一定都是新的变量，如果其中的变量之前已经声明过，则仅仅是简单的赋值。若所有的变量都被声明过，则会报错。 Pointers123var x intvar y *inty := &amp;x the new functionThe expression new(T) creates an unnamed variable of type T, initializes it to the zero value of T, and return its address, which is a value of type *T. 12p := new(int)fmt.Println(*p) lifetime of variables全局变量的生命周期是整个程序运行期间，局部变量的生命周期是局部调用期间。不可达的变量将会被垃圾回收器回收。 编译器根据具体情况在堆上或者栈上申请变量内存。 Assignmentstuple assignments AssignabilityType Declarations新定义一种类型。类似C语言中的typedef 1type name underlying-type Packages and Files每个源文件可以有个init函数，当程序执行时，init函数会按照声明的顺序自动被调用。初始化顺序为:自底向上，main包是最后一个。 12func init() &#123;&#125; scopescope is a compile-time property. lifetime is a run-time property. 123全局作用域 本地作用域本地作用域可以覆盖全局的搜索变量时先本地后全局，若都找到，则报未定义错误 Basic Data Typesgo提供了四种类型策略: 基本类型、组合类型、引用类型和接口类型。 基本类型包括数字、字符串和布尔值。组合数据类型包括数组和结构体。引用类型包括指针、切片、字典、函数和channel。接口类型后续再介绍。 go的数字类型包含几种大小不同的整型、浮点型和复杂的数据 12345int8 int16 int32 int64uint8 uint16 uint32 uint64rune == int32byte == uint8uintptr # 大小不定，存储指针值 一般底层编程使用 int和uint是在特定平台上最高效的大小。具体大小视平台而定。 12float32 float64complex64 complex128 字符串字符串是一个不可变的字节序列。 内建函数len返回的是字节的数量。index操作(s[i])返回的是第i个字节。 1xxx 复合数据类型123456789101112131415161718192021var q [3]int = [3]int&#123;1, 2, 3&#125; # 数组及初始化s := []int&#123;0, 1, 2, 3, 4, 5&#125;make([]T, len) # 创建一个指定元素类型、长度和容量的slice，此时容量等于长度make([]T, len, cap) #append # 向slice中追加元素ages := make(map[string]int) # mapages := map[string]int&#123; &quot;a&quot;: 1, &quot;b&quot;: 2&#125;equalsages := make(map[string]int)ages[&quot;a&quot;] = 1ages[&quot;b&quot;] = 2delete(ages, &quot;a&quot;) # delete _ = &amp;ages[&quot;a&quot;] # 禁止对map元素取址的原因是重新分配后之前的地址可能无效","tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"}]},{"title":"理论篇-git","date":"2017-09-06T06:17:33.000Z","path":"2017/09/06/理论篇-git/","text":"git的特性分支与合并 平滑的上下文切换 基于角色的代码边界(主分支(生产分支)，测试分支，开发分支) 基于功能的工作流 一次性实验(可大胆的创建分支，测试新想法，如果行不通，删除即可) 小且快分布式 多备份 任意工作流 subversion风格的工作流 整合管理者工作流(大部分的开源项目) 独裁者与助理工作流(linux内核) 数据安全性缓存区域(staging area)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100.├── .git│ ├── COMMIT_EDITMSG│ ├── HEAD│ ├── config│ ├── description│ ├── hooks│ │ ├── applypatch-msg.sample│ │ ├── commit-msg.sample│ │ ├── post-update.sample│ │ ├── pre-applypatch.sample│ │ ├── pre-commit.sample│ │ ├── pre-push.sample│ │ ├── pre-rebase.sample│ │ ├── pre-receive.sample│ │ ├── prepare-commit-msg.sample│ │ └── update.sample│ ├── index│ ├── info│ │ └── exclude│ ├── logs│ │ ├── HEAD│ │ └── refs│ │ ├── heads│ │ │ └── master│ │ └── remotes│ │ └── origin│ │ ├── HEAD│ │ └── master│ ├── objects│ │ ├── 03│ │ │ └── 608c266fb496e0d0e91c47d12feff94d51979b│ │ ├── 14│ │ │ └── faa91e92bf4b5ae35741e6dd21f96a18ee9434│ │ ├── 1d│ │ │ └── a5ff9f64b8f9c3242c4b64c60b7ecc8d7a3317│ │ ├── 3a│ │ │ └── dba43c276a46951f7876286bfad676a33ac791│ │ ├── 3d│ │ │ └── 07907040eb486cdd6591d8beb35cca88cf4f05│ │ ├── 40│ │ │ ├── 5d7004636a4ac3982d1a004abc3cdb728d5c84│ │ │ └── ad0beaedb60fd54bb50944aa29daa92165019d│ │ ├── 64│ │ │ └── ab44c069ec429ab7baf6907b39372d01712491│ │ ├── 68│ │ │ └── b961c0c93dc52a9b4ecd7365e1e9c8228335b0│ │ ├── 75│ │ │ └── 59f2dfc904e98ba4502d61d58b259ac26bd963│ │ ├── 79│ │ │ └── e1b4e4a5b4749ef38580354e0b4e86e936e8b2│ │ ├── 7a│ │ │ └── 00c826727b14e260fef04044892644f6e66edd│ │ ├── 86│ │ │ └── 729e808d7a9aa1b98f401b07e310f9d11fb973│ │ ├── 88│ │ │ └── b7c625f15d3a5209630b2ce1ec795c32a96930│ │ ├── 93│ │ │ └── 1f34e56c1fde33acbe15f68e5950b6c8abdefd│ │ ├── 9a│ │ │ └── 0d2d51ee1717285828be51dafc21d87711ec01│ │ ├── a4│ │ │ └── e3d834847f446a2859cc0e8c6e9845246e241f│ │ ├── aa│ │ │ ├── 48aa278cf2c02f5d726fd3e01f531e1094c8d3│ │ │ └── 66490c4fbeef674f150e4fe4ceeed01afaa868│ │ ├── ba│ │ │ └── f13061a7bcea6f8386d5432059508e6acfa6f6│ │ ├── cd│ │ │ └── 7b9c523a676d03d49bbf1a8110d8c329ab55be│ │ ├── ce│ │ │ └── a79cfa9f191becece59f9e4019d469fe3554a0│ │ ├── d5│ │ │ └── 376c8519e1a8bb32757e5b3296af0b5727be0f│ │ ├── d7│ │ │ └── 87f36cc59c608571c09cc6fd65d2d7a3af1833│ │ ├── dd│ │ │ └── 4c7cc4fec679c0dc3efa1539a28b4a2357c23f│ │ ├── e3│ │ │ ├── 2b361902897d9541d5db5e60752d6fab0aa22a│ │ │ └── 606e7342764b9d8ed8f20da9731d4024cee3cd│ │ ├── ed│ │ │ └── cc7eed7a720a8a28f14511837820849e3390d4│ │ ├── f6│ │ │ └── 9a3d7ea4f061a6a1e62d4ab61dbac717e2a473│ │ ├── fa│ │ │ └── 104313f955fdacf41edd819cd88e4533275e9a│ │ ├── info│ │ └── pack│ ├── packed-refs│ └── refs│ ├── heads│ │ └── master│ ├── remotes│ │ └── origin│ │ ├── HEAD│ │ └── master│ └── tags├── .vimrc└── README.md checkout 123git checkout [-q] [-f] [-m] [&lt;branch&gt;] # 切换分支git checkout [-q] [-f] [-m] [--detach] &lt;commit&gt; # 切换到任何一次提交git checkout [-p|--patch] [&lt;tree-ish&gt;] [--] [&lt;paths&gt;...] # 检出其它提交的某些文件 若不指定&lt;tree-ish&gt; 则从暂存区中检出 常见用法 切换到某个分支 检出某个分支上的某些文件并替换工作区中的文件 检出某个分支，做完修改后，在此基础上创建新的分支 branch 1git branch [--set-upstream | --track | --no-track] [-l] [-f] &lt;branchname&gt; [&lt;start-point&gt;] # 根据某个提交创建分支 referencegit中文版 阮一峰网站","tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"理论篇-虚拟化之各种名词","date":"2017-09-04T04:02:12.000Z","path":"2017/09/04/理论篇-虚拟化之各种名词/","text":"VPS(Virtual Private Server虚拟专用服务器)技术，将一台服务器分割成多个虚拟专享服务器的优质服务。实现VPS的技术分为容器技术和虚拟化技术。在容器或虚拟机中，每个VPS都可分配独立公网IP地址、独立操作系统、实现不同VPS间磁盘空间、内存、CPU资源、进程和系统配置的隔离，为用户和应用程序模拟出”独占”使用计算资源的体验。 IDC(Internet Data Center)即互联网数据中心，可以为用户提供: 申请域名、租用虚拟主机空间、主机托管等服务。","tags":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://yoursite.com/tags/虚拟化技术/"}]},{"title":"理论篇-虚拟机之VirtualBox","date":"2017-09-03T10:29:19.000Z","path":"2017/09/03/理论篇-虚拟机之VirtualBox/","text":"网络连接virtualbox提供了四种网络连接方式 NAT Bridged Adapter Internal Host-only Adapter 各个方式之间的区别 NAT Bridged Adapter Internal Host-only Adapter 虚拟机-&gt;主机 Y Y N 默认不能 需设置 主机-&gt;虚拟机 N Y N 默认不能 需设置 虚拟机-&gt;其它主机 Y Y N 默认不能 需设置 其它主机-&gt;虚拟机 N Y N 默认不能 需设置 虚拟机之间 N Y 同网络名下可以 Y NAT模式下可以通过端口转发，将宿主机端口映射到虚拟机中的某个端口来访问虚拟机中的某个服务。","tags":[{"name":"virtualbox","slug":"virtualbox","permalink":"http://yoursite.com/tags/virtualbox/"}]},{"title":"理论篇-docker","date":"2017-09-03T02:24:32.000Z","path":"2017/09/03/理论篇-docker/","text":"docker的主要目标: Build, Ship and Run any App, Anywhere 虚拟化技术与DockerLinux Container(LXC)Linux Container是一种内核虚拟化技术，可以提供轻量级的虚拟化，以便隔离进程和资源，而且不需要提供指令解释机制以及全虚拟化的其他复杂性。与传统虚拟化技术相比，优势如下: 与宿主机使用同一个内核，性能损耗小 不需要指令集模拟 不需要即时编译 容器可以在CPU核心的本地运行指令，不需要任何专门的解释机制 避免了准虚拟化和系统调用替换中的复杂性 轻量级隔离，在隔离的同时还提供共享机制，以实现容器和宿主机的资源共享 但是，使用的复杂性限制了它的普及。 DockerDocker在LXC基础上进一步优化了容器的使用体验，使这一技术得到了普及。Docker提供了各种容器管理工具(如分发、版本、移植等)让用户无需关注底层的操作，可以简单明了的管理和使用容器。 Docker在开发和运维中的优势 更快速的交付和部署，一次开发，处处部署。 更高效的资源利用，无其他虚拟化管理程序的开销 更轻松的迁移和扩展，任何支持docker的系统上都可以运行容器 更简单的更新管理，Dockerfile 和传统虚拟化技术的比较 Docker容器很快，启动和停止可以在秒级实现，这相比传统的虚拟机方式要快得多 Docker容器对系统资源需求很少，一台主机上可以同时运行数千个Docker容器 Docker通过类似git的操作来方便用户获取、分发和更新应用镜像，指令简明，学习成本低 Docker通过Dockerfile配置文件来支持灵活的自动化创建和部署机制，提高工作效率 虚拟化与Docker虚拟化技术是一个通用概念。在计算领域，一般指的是计算虚拟化或通常说的服务器虚拟化。 维基百科: 在计算机技术中，虚拟化是一种资源管理技术，是将计算机的各种实体资源，如服务器、网络、内存及存储等予以抽象、转换后呈现出来，打破实体结构间的不可分割的障碍，使用户可以用比原本的组态更好的方式来应用这些资源。 虚拟化可分为基于硬件的虚拟化和基于软件的虚拟化。后者又可分为基于应用的虚拟化和基于平台的虚拟化(通常意义的虚拟化)。基于平台的虚拟化又有如下分类: 完全虚拟化 虚拟机模拟完整的底层硬件环境和特权指令的执行过程，客户操作系统无需进行修改。例如VMware Workstation、VirtualBox、QEMU等 硬件辅助虚拟化 利用硬件(主要是CPU)辅助支持(目前x86体系结构上可用的硬件辅助虚拟化技术包括Intel-TV和AMD-V)处理敏感指令来实现完全虚拟化的功能。客户操作系统无需修改。例如VMware Workstation、Xen、KVM。 部分虚拟化 只针对部分硬件资源进行虚拟化，客户操作系统需要进行修改。 超虚拟化 部分硬件接口以软件的形式提供给客户操作系统，客户操作系统需要进行修改，例如早期的Xen 操作系统级虚拟化 内核通过创建多个虚拟的操作系统实例(内核和库)来隔离不同的进程。容器相关技术即在这个范畴 Docker相关docker有三个核心概念: 镜像(image)、容器(container)和仓库(repository) 镜像相关docker镜像类似于虚拟机镜像，可以理解为一个面向docker引擎的只读模板，包含了文件系统。镜像是创建docker容器的基础。通过版本管理和增量的文件系统，docker提供了一套十分简单的机制来创建和更新现有的镜像。 镜像文件一般由若干层组成。层(Layer)是AUFS(Advanced Union File System)中的重要概念，是实现增量保存与更新的基础。 12345docker pull NAME[:TAG] # 拉取镜像 若不显式指定TAG，则默认会选择latest标签docker images # 查看本地镜像docker inspect # 查看镜像信息docker search # 搜索镜像docker rmi [OPTIONS] IMAGE [IMAGE...] # IMAGE可以是tag或ID 当为tag且tag不唯一时，只删除tag 当为ID时 首先删除所有的tag 然后删除镜像文件 镜像删除注意事项 IMAGE可以是tag或ID 为tag且tag不唯一时，只删除该tag 为tag且tag唯一时，删除镜像文件 为ID时，删除所有的tag，然后删除镜像文件 当该镜像有容器运行时，默认是不能删除的，若要删除 需加-f进行强制删除 创建镜像创建镜像有三种方法: 基于已有镜像的容器创建 基于本地模板导入 基于Dockerfile创建 基于已有镜像的容器创建 1docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] # 创建镜像 基于本地模板导入 推荐使用OpenVZ提供的模板来创建 1234567```[模板地址](https://download.openvz.org/template/precreated/)**使用dockerfile创建镜像**dockerfile由一行行命令语句组成，且支持以#开头的注释。 Author: wangbiaoCommand format: Instruction [arguments/command] …第一行必须指定基于的基础镜像FROM ubuntu 维护者信息MAINTAINER wangbiao 841824090@qq.com 镜像的操作指令RUN apt-get update &amp;&amp; apt-get install -y nginx # 在当前镜像基础上添加新的一层并提交为新的镜像 容器启动时执行指令CMD /usr/sbin/nginx123456**指令*** FROM 第一条指令必须是FROM。若在同一个dockerfile中创建多个镜像时可使用多次。 FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; 123* MAINTAINER 维护者信息 MAINTAINER &lt;name&gt; 123* RUN 在当前镜像基础上执行指令，并提交为新的镜像。可使用\\换行 RUN &lt;command&gt; RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 123* CMD 指定容器启动时执行的命令，每个Dockerfile只能有一条CMD命令。如果执行了多条命令，只有最后一条会被执行。如果用户启动容器的时候指定了运行的命令，则会覆盖掉CMD指定的命令。 CMD [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] # 使用exec执行 CMD command param1 param2 # 在/bin/sh中执行，需要交互时使用 CMD [&quot;param1&quot;, &quot;param2&quot;] # 提供给ENTRYPOINT的默认参数 123* EXPOSE 指定docker容器暴露的端口号，供互联系统使用。启动容器时，使用-P参数时，docker会自动分配一个端口转发到指定的端口。使用-p参数时，指定具体映射端口。 EXPOSE &lt;port&gt; [&lt;port&gt;...] 123* ENV 指定一个环境变量，会被后续RUN指令使用，并在容器运行时保持。 ENV &lt;key&gt; &lt;value&gt; 123* ADD 复制指定的&lt;src&gt;到容器中的&lt;dest&gt;。其中&lt;src&gt;可以是Dockerfile所在目录的一个相对路径(文件或目录)；也可以是一个URL；还可以是一个tar文件(自动解压为目录)。 ADD &lt;src&gt; &lt;dest&gt; 123* COPY 复制本地主机的&lt;src&gt;(为Dockerfile所在目录的相对路径，文件或目录)为容器中的&lt;dest&gt;。目标目录不存在时，会自动创建。当使用本地目录为源目录时，推荐使用COPY COPY &lt;src&gt; &lt;dest&gt; 123* ENTRYPOINT 配置容器启动后执行的命令，且不可被docker run提供的参数覆盖。每个Dockerfile只能有一个ENTRYPOINT，当指定多个时，只有最后一个生效。 ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT command param1 param2(shell中执行) 123* VOLUME 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保存的数据等 VOLUME [&quot;/data&quot;] 123* USER 指定运行容器时的用户名或UID，后续的RUN也会使用指定用户。当服务不需要管理员权限时，可以通过该命令指定运行用户。 USER daemon 123* WORKDIR 为后续的RUN，CMD，ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指定，后续命令如果参数是相对的，则会基于之前命令指定路径。 WORKDIR /path/to/workdir 123* ONBUILD 配置当所创建的镜像作为其他新创建镜像的基础镜像时，所执行的操作指令。使用该指令的镜像，推荐在tag中注明。 ONBUILD [INSTRUCTION] 1234 **创建镜像**该命令读取指定路径下的Dockerfile，并将该路径下所有内容发送给服务端，由服务端来创建镜像。因此一般建议放置Dockerfile的目录为空。可使用.dockerignore文件来让docker忽略路径下的目录和文件。 docker build12**存出和载入镜像** docker save -o ubuntu_14.04.tar ubuntu:14.04 # 存出docker load –input ubuntu_14.04.tar # 载入ordocker load &lt; ubuntu_14.04.tar1234#### 容器相关docker容器类似一个轻量级的沙箱，docker利用容器来运行和隔离应用。镜像自身是只读的，容器从镜像启动的时候，docker会在镜像的最上层创建一个可写层，镜像本身将保持不变。 docker create # 从镜像创建容器，此时容器未执行docker start # 启动已存在的容器docker restart # 重启已存在的容器docker run # 运行一个停止状态的容器docker stop # 停止容器docker rm # 删除容器docker ps -a # 查看容器 进入后台运行的容器docker attach #docker exec # 可以执行其他命令 比如重开一个shell 导入和导出 容器迁移时可用docker export # 导出docker import # 导入1234567891011121314151617181920212223242526272829利用docker run来创建并启动容器时，docker会进行如下操作:1. 检查本地是否存在指定的镜像，不存在就从公有仓库下载2. 利用镜像创建并启动一个容器3. 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层4. 从宿主机配置的网桥接口中桥接一个虚拟接口到容器中去5. 从地址池中配置一个IP地址给容器6. 执行用户指定的应用程序7. 执行完毕后容器被终止当应用退出后，容器随即退出(因为容器是为运行应用而存在的)。**容器是用来区分应用的****停止容器注意事项*** 首先向容器发送SIGTERM信号* 等待一段时间(默认10s)后，再发送SIGKILL信号终止容器#### 仓库相关docker仓库类似与代码仓库，是docker集中存放镜像文件的场所。可以使用公有仓库也可以搭建自己的私有仓库。#### 认证相关首先需要登录registry，才能提交镜像文件。 docker login # 登录docker logout # 登出1234567891011121314151617#### 数据管理容器中管理数据主要有两种方式:* 数据卷(data volumes)* 数据卷容器(data volume containers)##### 数据卷数据卷是一个可供容器使用的特殊目录，它绕过文件系统，可以提供很多有用的特性:* 数据卷可以在容器之间共享和重用* 对数据卷的修改会立马生效* 对数据卷的更新，不会影响镜像* 卷会一直存在，直到没有容器使用 docker run -v # 创建数据卷12345##### 数据卷容器本质是启动一个普通的容器，并创建一个数据卷，其他容器可以使用该容器的数据卷。 docker run –volumes-from # 带有数据卷容器启动1234567891011#### 网络基础配置docker目前提供了映射容器端口到宿主主机和容器互联机制来为容器提供网络服务。##### 端口映射实现访问容器**注意事项*** -P，docker会随机映射一个49000~49900的端口至容器内部开放的网络端口* -p，指定要映射的端口，可用的格式: ip:hostPort:containerPort ip::containerPort hostPort:containerPort # 默认会绑定本地所有接口上的所有地址 12 docker port # 查看端口配置1234##### 容器互联实现容器间通信容器的连接系统是除了端口映射外另一种可以与容器中应用进行交互的方式。它会在源和接收容器之间创建一个隧道，接收容器可以看到源容器指定的信息。 docker run –link name:alias # 容器连接``` docker通过两种方式为容器公开连接信息: 环境变量 更新/etc/hosts文件 两个值得深究的技术: SDN(软件定义网络) NFV(网络功能虚拟化)","tags":[{"name":"虚拟化技术","slug":"虚拟化技术","permalink":"http://yoursite.com/tags/虚拟化技术/"}]},{"title":"理论篇-设计模式之简单工厂模式","date":"2017-08-20T11:01:08.000Z","path":"2017/08/20/理论篇-设计模式之简单工厂模式/","text":"12345678UML图继承 三角直线实现 三角虚线合成 实菱形直线箭头组合 空菱形直线箭头关联 直线箭头 (A类是B类的成员，则B类关联A类 强拥有关系)依赖 虚线箭头 (A类是B类某些方法的参数，则B类依赖A类 弱拥有关系)","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"理论篇-协程的本质","date":"2017-08-11T02:21:46.000Z","path":"2017/08/11/理论篇-协程的本质/","text":"协程好像是编程的大趋势，为什么协程会如此火呢？协程有如下几个优势: 用户态控制权转让 与事件机制一起可以实现以同步代码的方式实现异步逻辑 协程都是语言级别提供的编程工具。比如lua里的coroutine，python里的基于生成器的协程。那么协程的本质是什么呢？仔细研读一下下面的代码，你就会体会其中的奥秘！然后，惊叹一声，原来协程的本质是这样的啊！ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;stdio.h&gt;#include &lt;setjmp.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;struct co &#123; char *msg; int size; int index;&#125;;struct co * co_create() &#123; struct co *ttt = (struct co *) malloc(sizeof(struct co)); ttt-&gt;msg = (char *)malloc(10*sizeof(char)); ttt-&gt;size = 10; ttt-&gt;index = 0; return ttt;&#125;void co_free(struct co *ttt) &#123; free(ttt-&gt;msg); free(ttt);&#125;#define START 0#define RUNNING 1#define STOP 2jmp_buf env;jmp_buf env2;struct co *ttt = NULL;int f() &#123; int res=0, res2; ttt = co_create(); while (res != STOP) &#123; res = setjmp(env); if (res == START) break; if (res == RUNNING) printf(&quot;%s\\n&quot;, ttt-&gt;msg); if (res == STOP) &#123; break; &#125; sleep(1); &#125; if (res == STOP) &#123; setjmp(env); &#125; //res2 = setjmp(env2); //if (res2!=0) printf(&quot;-------\\n&quot;); return 0;&#125;void g(int flag) &#123; longjmp(env, flag);&#125;void g2(int flag) &#123; longjmp(env2, flag);&#125;int main() &#123; int i; f(); for (i=0; i&lt;ttt-&gt;size-1; i++) &#123; *(ttt-&gt;msg+i) = &apos;a&apos;; *(ttt-&gt;msg+i+1) = &apos;\\0&apos;; g(1); //g2(1); &#125; g(2); g(2); co_free(ttt); return 0;&#125;","tags":[{"name":"协程","slug":"协程","permalink":"http://yoursite.com/tags/协程/"}]},{"title":"实战篇-C之各种疑难杂症","date":"2017-08-11T01:57:42.000Z","path":"2017/08/11/实战篇-C之各种疑难杂症/","text":"initializer element is not a compile-time constant 123问题还原: 在定义全局变量时，若全局变量需要计算获取，则报此错误。解决方案: 只声明全局变量，在函数内定义。本质: todo","tags":[{"name":"C","slug":"C","permalink":"http://yoursite.com/tags/C/"}]},{"title":"理论篇-网络","date":"2017-08-04T01:18:00.000Z","path":"2017/08/04/理论篇-网络/","text":"TCP/IP分层1234567用户进程1 用户进程2 用户进程3 用户进程4 ... 应用层 | | | | | TCP | UDP 传输层 | \\ | /ICMP ----&gt; IP &lt;---- IGMP 网络层 |ARP ----&gt; 硬件接口 &lt;---- RARP 链路层 重点: ICMP(Internet Control Message Protocol)和IGMP(Internet Group Message Protocol)是IP协议的附属协议。其中，ICMP是ping和traceroute工具的基础。 ARP(Address Resolution Protocol)和RARP(Reverse Address Resolution Protocol)是某些网络(如以太网和令牌环网)使用的特殊协议，用来转换IP层和网络接口层使用的地址。ARP主要用来获取物理地址。 IP(Internet Protocol)是TCP/IP协议族中最核心的协议。所有的ICMP、IGMP、TCP和UDP数据都已IP数据报格式传输。 ICMP报文分为两种类型: 1. 查询报文 2. 差错报文。 ICMP 类型 代码 描述 查询 差错 处理方法 0 0 回显应答(ping) * 用户进程 3 目的不可达 0 网络不可达 * 无路由到达主机 1 主机不可达 * 无路由到达主机 2 协议不可达 * 连接被拒绝 3 端口不可达 * 连接被拒绝 4 需要进行分片但设置了不分片比特 * 无路由到达主机 5 源站选路失败 * 无路由到达主机 6 目的网络不认识 * 无路由到达主机 7 目的主机不认识 * 无路由到达主机 8 源主机被隔离(作废不用) * 无路由到达主机 9 目的网络被强制禁止 * 无路由到达主机 10 目的主机被强制禁止 * 无路由到达主机 11 由于服务类型TOS，网络不可达 * 无路由到达主机 12 由于服务类型TOS，主机不可达 * 无路由到达主机 13 由于过滤，通信被强制禁止 * 忽略 14 主机越权 * 忽略 15 优先权中止生效 * 忽略 4 0 源端被关闭(基本流控制) * TCP由内核处理，UDP则忽略 5 重定向 * 0 对网络重定向 * 内核更新路由表 1 对主机重定向 * 内核更新路由表 2 对服务类型和网络重定向 * 内核更新路由表 3 对服务类型和主机重定向 * 内核更新路由表 8 0 请求回显(ping) * 9 0 路由器通告 * 用户进程 10 0 路由器请求 * 用户进程 11 超时 0 传输期间生存时间为0(traceroute) * 用户进程 1 在数据报组装期间生存时间为0 * 用户进程 12 参数问题 0 坏的IP首部(包括各种差错) * 协议不可用 1 缺少必需的选项 * 协议不可用 13 0 时间戳请求 * 内核产生应答 14 0 时间戳应答 * 用户进程 15 0 信息请求(作废不用) * 16 0 信息应答(作废不用) * 17 0 地址掩码请求 * 内核产生应答 18 0 地址掩码应答 * 用户进程 ICMP规则: ICMP差错报文必须包括生成该差错报文的数据报IP首部(包含任何选项)，还必须包括跟在该IP首部后面的前8个字节(该数据为UDP或TCP协议的源端口号和目的端口号)。这样就可以告知源应用程序，目标应用程序不可达。 TCP状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 client server | | listen | |主动打开 | SYNi |SYN_SENT |------------------&gt;| | SYNj,ACKi+1 | SYN_REVDESTABLISHED|&lt;------------------| | ACKj+1 | |------------------&gt;| ESTABLISHED | | | | | | | |同时打开 | SYNi | 同时打开SYN_SENT |&lt;-----------------&gt;| SYN_SENTSYN_REVD | SYNj | SYN_REVD | | | SYNi,ACKj+1 | |&lt;-----------------&gt;| | SYNj,ACKi+1 |ESTABLISHED| | ESTABLISHED | | | | | | | |主动关闭 | FINs | 被动关闭FIN_WAIT_1 |------------------&gt;| | ACKs+1 | CLOSE_WAITFIN_WAIT_2 |&lt;------------------| | FINt | |&lt;------------------| LAST_ACKTIME_WAIT | ACKt+1 | |------------------&gt;| CLOSED | | | | | | | |被动关闭 | FINs | 主动关闭 |&lt;------------------| FIN_WAIT_1CLOSE_WAIT | ACKs+1 | |------------------&gt;| FIN_WAIT_2 | FINt |LAST_ACK |------------------&gt;| | ACKt+1 | TIME_WAITCLOSED |&lt;------------------| | | | | | |同时关闭 | FINs | 同时关闭FIN_WAIT_1 |&lt;-----------------&gt;| FIN_WAIT_1 | FINt |CLOSING | | CLOSING | ACKs+1 | |&lt;-----------------&gt;|TIME_WAIT | ACKt+1 | TIME_WAIT | | | | TIME_WAIT状态需要等待2MSL(Maximum Segment Lifetime)。原因: 防止消息丢失。如果对方超时未收到ACK消息的话，会再次发送FIN消息。 当出现大量TIME_WAIT状态时的解决方案: 12345678910111213141516171819202122#对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃,不应该大于255，默认值是5，对应于180秒左右时间 net.ipv4.tcp_syn_retries=2 #net.ipv4.tcp_synack_retries=2 #表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为300秒 net.ipv4.tcp_keepalive_time=1200 net.ipv4.tcp_orphan_retries=3 #表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间 net.ipv4.tcp_fin_timeout=30 #表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。 net.ipv4.tcp_max_syn_backlog = 4096 #表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭 net.ipv4.tcp_syncookies = 1 #表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭 net.ipv4.tcp_tw_reuse = 1 #表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 net.ipv4.tcp_tw_recycle = 1 ##减少超时前的探测次数 net.ipv4.tcp_keepalive_probes=5 ##优化网络设备接收队列 net.core.netdev_max_backlog=3000 当出现大量CLOSE_WAIT状态时的解决方案: 程序问题，检查源码 参考 再谈应用环境下的TIME_WAIT和CLOSE_WAIT","tags":[{"name":"网络","slug":"网络","permalink":"http://yoursite.com/tags/网络/"}]},{"title":"面试总结","date":"2017-08-03T07:13:35.000Z","path":"2017/08/03/面试总结/","text":"有关epollepoll与poll、select的区别selectselect使用整数集合中位来存储描述符。所以提供以下宏命令来添加、删除描述符。 12345678#include &lt;sys/select.h&gt;void FD_CLR(fd, fd_set *fdset);void FD_COPY(fd_set *fdset_orig, fd_set *fdset_copy);void FD_ISSET(fd, fd_set *fdset);void FD_SET(fd, fd_set *fdset);void FD_ZERO(fd_set *fdset);int select(int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout); poll1234567int poll(struct pollfd fds[], nfds_t nfds, int timeout);struct pollfd &#123; int fd; /* file descriptor */ short events; /* events to look for */ short revents; /* events returned */&#125;; epoll","tags":[]},{"title":"理论篇-各种题型技巧","date":"2017-07-20T03:53:51.000Z","path":"2017/07/20/理论篇-各种题型技巧/","text":"数组问题 有序数组查找: 二分法 无序数组查找: 借鉴快排的二分查找 链表类题目: 重点考察指针的操作。 注意头结点的特殊处理。 dp问题 做一个决定产生一个子问题 对于一个特定的子问题，已经有了一个最优化的决定 做了决定之后，接着处理新的子问题 最优化问题的变种: 对于原始问题的最优化方案依赖多少个子问题 需要做多少选择来决定哪个子问题被使用 贪心算法","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-异或的威力","date":"2017-07-18T03:51:07.000Z","path":"2017/07/18/理论篇-异或的威力/","text":"0~7 异或 8 1234567(0, &apos; &apos;, 8)(1, &apos; &apos;, 9)(2, &apos; &apos;, 10)(3, &apos; &apos;, 11)(4, &apos; &apos;, 12)(5, &apos; &apos;, 13)(6, &apos; &apos;, 14) 0~7 异或 7 1234567(0, &apos; &apos;, 7)(1, &apos; &apos;, 6)(2, &apos; &apos;, 5)(3, &apos; &apos;, 4)(4, &apos; &apos;, 3)(5, &apos; &apos;, 2)(6, &apos; &apos;, 1)","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-python标准库之导入模块","date":"2017-07-12T09:09:28.000Z","path":"2017/07/12/理论篇-python标准库之导入模块/","text":"importlib","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"总结篇-编程语言中那些关键字","date":"2017-07-11T03:03:09.000Z","path":"2017/07/11/总结篇-编程语言中那些关键字/","text":"static关键字: 在C语言中有两个含义: 表示退出一个块后依然存在的局部变量 表示不能被其他文件访问的全局变量和函数 在C++中又多了一层含义(java沿用该含义): 属于类且不属于类对象的变量和函数 123456789101112131415#include &lt;stdio.h&gt;int f() &#123; //static int count = 0; int count = 0; count++; return count;&#125;int main() &#123; int i=0; for (i=0; i&lt;10; i++) printf(&quot;%d\\n&quot;, f()); return 0;&#125;","tags":[{"name":"C","slug":"C","permalink":"http://yoursite.com/tags/C/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"理论篇-python标准库之数据类型","date":"2017-07-10T11:02:28.000Z","path":"2017/07/10/理论篇-python标准库之数据类型/","text":"copy 类或方法 解释 特殊说明 copy.copy() 浅拷贝 copy.deepcopy() 深拷贝 exception copy.eror 浅拷贝与深拷贝的区别: 浅拷贝只拷贝最外层的对象，而深拷贝会递归的拷贝所有对象。 12__copy____deepcopy__ weakrefweakref允许创建对象的弱引用。 python使用自动垃圾回收机制，当一个对象的引用计数为0或只有弱引用时，执行垃圾回收。所以弱引用不影响对象的回收。 类或方法 解释 特殊说明 class weakref.ref(object[, callback]) weakref.proxy(object[, callback]) weakref.getweakrefcount(object) weakref.getweakrefs(object) class weakref.WeakKeyDictionary([dict]) WeakKeyDictionary.keyrefs() class weakref.WeakValueDictionary([dict]) WeakValueDictionary.valuerefs() class weakref.WeakSet([elements]) class weakref.WeakMethod(method) class weakref.finalize(obj, func, *args, **kwargs) weakref.ReferenceType weakref.ProxyType weakref.CallableProxyType weakref.ProxyTypes exception weakref.ReferenceError","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-C之经典输出格式化","date":"2017-07-10T07:40:19.000Z","path":"2017/07/10/理论篇-C之经典输出格式化/","text":"转换符 类型 d 十进制整数 x 十六进制整数 o 八进制整数 f 定点浮点数 e 指数浮点数 g 通用浮点数 a 十六进制浮点数 s 字符串 c 字符 b 布尔 h 散列码 tx 日期时间 % % n 与平台有关的行分隔符 标志 目的 + 打印正数和负数的符号 空格 在正数之前添加空格 0 数字前补0 - 左对齐 ( 将负数括在括号内","tags":[{"name":"C","slug":"C","permalink":"http://yoursite.com/tags/C/"}]},{"title":"实战篇-java之各种异常","date":"2017-07-10T06:56:21.000Z","path":"2017/07/10/实战篇-java之各种异常/","text":"objc[7997]: Class JavaLaunchHelper is implemented java在mac上的老bug，不影响正常运行。","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"理论篇-java基础","date":"2017-07-10T03:42:53.000Z","path":"2017/07/10/理论篇-java基础/","text":"数据类型8种基本类型: 4种整型 2种浮点型 字符类型char(用于表示Unicode编码的字符单元) boolean类型 整型 存储需求 范围 特殊说明 int 4字节 20亿 short 2字节 long 8字节 后缀L byte 1字节 浮点类型 存储需求 范围 特殊说明 float 4字节 后缀F double 8字节 后缀D 1strictfp关键字 # 可修饰类或方法 将使用严格的浮点计算 char类型 表示单个字符 boolean类型: true false 数组 java中的数据没有指针运算。数组的操作使用java.util库中的Arrays。 12int[] a; # 仅仅是声明 并未真正创建int[] a = new int[10]; 变量java中不区分变量的声明与定义。 使用final关键字定义的为常量，被赋值后不能再修改。 使用static final关键字定义的为类常量。 1C/C++中使用const关键字定义常量 运算符关系运算符: == != &lt; &lt;= &gt; &gt;= 逻辑运算符: &amp;&amp; || 位运算符: &amp;(与) |(或) ~(非) ^(异或) &lt;&lt;(左移，使用符号位填充) &gt;&gt;(右移) &gt;&gt;&gt;(右移，使用0填充) 字符串java中的字符串也是不可变字符串。 字符串的比较用equals方法，千万不要使用==，因为==比较的是引用地址。 12StringBuilder # 非线程安全StringBuffer # 线程安全 控制结构java中有块(block)的概念。形式上就是使用一对花括号括起来的多条语句。块可以嵌套，但是不可以重复定义变量。 1234567891011121314151617181920if (condition1) statement1 else if (condition2) statement2 else statement3while (condition) statementdo statement while(condition);for (variable : collection) statement # collection必须是数组或者实现Iterable接口的对象switch(choice) &#123; case label1: ... case label2: ... default: ...&#125;case标签的取值:* 类型为char、byte、short或int的常量表达式* 枚举常量* 从Java7开始，可以是字符串字面量break [label];continue; 对象与类java不支持运算符重载。 类之间的关系: 依赖(uses-a)、聚合(has-a)和继承(is-a)。 12345678910111213class ClassName &#123; field1 field2 ... constructor1 constructor2 ... method1 method2 ...&#125; 在一个源文件中，只能有一个公有类，但可以有任意数目的非公有类。原文件名必须有公有类类名相同。 有关构造器: 构造器与类同名 每个类可以有一个以上的构造器 构造器可以有0个或多个参数 构造器没有返回值 构造器在new操作时被调用 提供get和set方法的好处: 当修改内部实现时，对外影响最小 可以做合法性检查 警告: 不要编写返回可变引用可变对象的访问器方法 基于类的访问权限:方法可以访问所属类的私有属性，而不仅限于访问隐式参数的私有属性。 final关键字的用途: 使用final修饰的实例域，构建对象时，必须初始化这样的域。且该域后面不能再修改。 使用final修饰的方法，不具备多态性 使用final修饰的类，不可被继承。该类中的所有方法自动成为final，属性不会。 应用于局部变量，实例变量和静态变量。在定义final变量时，不必进行初始化，调用时被初始化一次，如果执行多次调用，则创建多个变量。 static关键字: 使用static修饰的属性或方法为类属性或类方法。 使用static修饰的内部类没有指向外围类对象的引用 方法参数:java中采用按值传递方式。但是参数又分为两种类型: 1. 基本数据类型(数字，布尔值) 2. 对象引用 当参数是对象引用时，传递的是对象引用的副本，调用对象的方法将直接修改对象。 属性若未被初始化，则会执行默认初始化。但是局部变量必须得执行初始化。 在类定义时可以直接初始化属性。 this关键字的用途: 调用属性，比如this.xxx 通过this(…)调用其他构造器。 初始化块在构造器之前执行。初始化块可用static修饰，为静态初始化块，只能初始化静态属性，在类第一次加载的时候执行。 java不支持析构函数，但finalize方法保证在对象回收之前调用。但不能过多依赖该方法。 包的支持: 123packageimportimport static 没有public或private修饰的属性或方法具有包作用域。 类路径: 把类放在一个目录中 把JAR文件放在一个目录中 设置类路径，类路径是所有包含类文件的路径的集合。 javac编译器总是在当前的目录中查找文件，但java虚拟机仅在类路径中有”.”目录的时候才查看当前目录。若类路径中忘记设置当前目录，则程序仍然可以编译通过，但是不能运行。 设置类路径的方法: 12java -classpath环境变量 CLASSPATH 继承extends关键字表示继承关系，java中都是公有继承。 super关键字的用途: 用来调用父类中的方法，比如super.getXXX() 用来调用父类的构造函数，比如super(“xxx”, “xxx”) 若子类的构造器没有显式的调用超类的构造器，则默认调用无参构造器。若父类没有无参构造器，则编译报错。 多态:一个对象变量可以指示多种实际类型的现象 动态绑定:在运行时能够自动选择调用哪个方法的现象 斜变 12345678class Employee &#123; public Employee getBuddy() &#123;&#125;&#125;class Manager extends Employee &#123; public Manager getBuddy() &#123;&#125;&#125;子类覆写父类的方法，且子类的返回值为父类返回值的子类型。在覆写方法时，子类的可见性不能低于父类的可见性。 强制类型转换: 只能在继承层次内进行转换 在将超类转换成子类之前，应该使用instanceof进行检查 abstract关键字: 使用abstract修饰的类为抽象类，抽象类不能被实例化 使用abstract修饰的方法为抽象方法，包含抽象方法的类必须为抽象类 Object类 方法 解释 equales 检测两个对象是否相等 hashCode 对象的存储地址 一个整数值 toString 返回对象所属类名和散列码 对象包装器与自动装箱 装箱与拆箱是编译器认可的，而不是虚拟机。编译器在生成类的字节码时，插入必要的方法调用。虚拟机只是执行这些字节码。 重要:自动装箱规范要求boolean、byte、char&lt;=127、介于-128到127之间的short和int被包装到固定的对象中。 可变参数方法 1234567public static max(double ... values) &#123; double largest = Double.MIN_VALUE; for (dboule v : values) if (v &gt; largest) largest = v; return largest;&#125;double m = max(3.1, 4.2, 5) 枚举类 123456789101112131415161718public enum Size &#123; SMALL(1, &quot;S&quot;), MEDIUM(2, &quot;M&quot;), LARGE(3, &quot;L&quot;), EXTRA_LARGE(4, &quot;XL&quot;); private int num; private String des; Size(int num, String des) &#123; this.num = num; this.des = des; &#125; public String toString() &#123; return des; &#125;&#125; 反射 反射的作用: 在运行中分析类 在运行中查看对象 实现通用的数组操作代码 利用Method对象，这个对象很像C++中的函数指针 虚拟机为每个类型管理着一个Class对象，即每个类只有一个Class对象，该类的对象共享该Class对象。 重点在java.lang.reflect库。 接口与内部类 接口中的方法自动为public 接口中属性自动设为public static final 接口中提供方法签名 接口中不准定义实力属性 接口中不准实现方法 接口不可以被实例化，但可以定义接口变量 接口可以使用instanceof关键字 接口可以继承 java设计者认为多继承会使语言本身变得复杂，效率也会降低。(好像是这么回事) 对象克隆 深拷贝与浅拷贝 Cloneable接口 标记接口 接口与回调 在面向过程的编程语言(比如C)中，通常使用函数实现回调机制。但在像java这种纯面向对象的编程语言中，也可以通过传递Method对象，但由于使用复杂，速度和安全性问题，所以使用接口来实现回调机制。 接口中定义需要被回调的方法，实现回调机制的类实现接口中的方法，然后传递对象。这些接口一般称为标记接口 内部类 内部类是定义在另一个类中的类。 使用内部类的原因如下: 内部类方法可以访问该类定义所在的作用域中的数据，包括私有的数据 内部类可以对同一个包中其他类不可见 当想要定义一个回调函数且不想编写大量代码时，使用匿名内部类比较便捷 匿名内部类 123456789# 实现超类的匿名类new SuperType(construction parameters) &#123; inner class methods and data&#125;# 实现接口的匿名类new InterfaceType() &#123; methods and data&#125; 静态内部类 使用staitc修饰的内部类为静态内部类，静态内部类没有指向外围类的引用。 应用程序的部署JAR文件一个jar文件既可以包含类文件，也可以包含图像和声音这些其他类型的文件。jar文件使用zip压缩格式进行压缩。 jar文件中还包含一个清单文件MANIFEST.MF 12345678910Manifest-Version: 1.0Sealed: true # 密封包Name: Woozle.className: com/mycompany/mypkg/Main-Class: com.mycompany.mypkg.MainAppClass # 程序的入口点 # 最后一行必须以换行符结束 异常机制 java中所有的异常都继承自Throwable类 Throwable类有两个子类，一个是Error，一个是Exception。Error属于系统内部错误或资源耗尽错误。Exception为最常见的异常 Exception下有分为两类: RuntimeException和IOException RuntimeException有如下几种: 错误的类型转换 数组访问越界 访问空指针 unchecked exceptions 和 checked exceptions 断言 1234567891011assert condition;assert condition: expression;# 启动断言java -enableassertions MyAppjava -ea:MyClass MyApp# 禁用断言java -disableassertions MyAppjava -da:MyClass MyApp 泛型程序设计？泛型使程序具有更好的可读性和安全性。 通配符类型(wildcard type) 泛型类 123456789101112131415161718192021public class Pair&lt;T, U&gt; &#123; private T first; private U second; public Pair() &#123;first=null; second=null;&#125; public Pair(T first, U second) &#123; this.first = first; this.second = second; &#125; public T getFirst() &#123;return first&#125; public U getSecond() &#123;return second&#125; public void setFirst(T first) &#123; this.first = first; &#125; public void setSecond(U second) &#123; this.second = second; &#125;&#125; 泛型方法 12345class ArrayAlg &#123; public static &lt;T&gt; T getMiddle(T ... a) &#123; return a[a.length/2]; &#125;&#125; 类型变量的限定 12&lt;T extends BoundingType1 &amp;BoudingType2&gt; # 表明T应该是绑定类型的子类型限定类型可以是接口也可以是类。接口可以多个，类只能有一个，且必须在限定列表中的第一个 对虚拟机来说不存在泛型之说，所有的类都是普通类。 无论何时定义一个泛型类型，都自动提供了一个相应的原始类型。原始类型通过将类型变量替换为限定类型来获得。若类型变量是一个无限定的变量，则直接用Object类替换。若类型变量是一个有限定的变量，则用第一个限定的类型变量来替换。 翻译泛型表达式时编译器插入强制类型转换 翻译泛型方法时会使用桥方法(bridge method)的技巧。其中桥方法的技巧在斜变中也被应用到。 1为了提高效率应该将标签接口(即没有方法的接口)放在边界列表的末尾。 关于泛型的tips: 虚拟机中没有泛型，只有普通的类和方法 所有的类型参数都用它们的限定类型替换 桥方法被合成来保持多态 为保持类型安全性，必要时插入强制类型转换 约束与限制 不能用基本类型实例化类型参数 集合？ 接口与实现分离 Abstract开头的类是为扩展类库准备的 使用的基础数据结构有: 数组、链表、哈希表、堆、红黑树 集合 类 数据结构 List ArrayList 数组 List LinkedList 链表 Set HashSet 哈希表 Set TreeSet 红黑树 Set LinkedHashSet 哈希表 链表 Map HashMap 哈希表 对key进行哈希 Map TreeMap 红黑树 对key进行排序 Map LinkedHashMap 哈希表 链表 Queue ArrayDeque 循环数组 Queue PriorityQueue 堆 集合框架的接口 1234567891011 Iterable | Collection Map Iterable RandomAccess | | | ------------------- | | | | | | |List Set Queue SortedMap ListIterable | | | SortedSet Deque NavigableMap | NavigableSet 集合框架中的类 123456789101112 AbstractCollection | --------------------------------------------- | | | |AbstractList AbstractSet AbstractQueue | AbstractMap | | | | | --------------- -------- | | ----------- | | | | | | | |Abstract |HashSet TreeSet PriorityQueue ArrayDequeue HashMap TreeMapSequentialList | | |LinkedList ArrayList 视图与包装器？？？ 线程创建一个线程的方法: 创建一个类并实现Runnable接口中的run方法 创建一个类对象，使用该对象创建一个Thread对象 调用Thread对象的start方法 线程状态 12345678New --&gt; Runnable --&gt; Blocked/Waiting/Timed waiting --&gt; TerminatedNew: new Thread(r)Runnable: start() 可运行的线程可能处于运行状态也可能没有运行Blocked: 当一个线程试图获取一个内部的对象锁(而不是java.util.concurrent库中的锁)，而该锁被其它线程持有，该线程进入阻塞状态Waiting: 当线程等待另一个线程通知调度器一个条件时，它自己进入等待状态。在调用Object.wait方法或Thread.join方法，或者是等待java.util.concurrent库中的Lock或Condition时，就会出现这种情况。Timed waiting: 调用带有超时参数的方法导致线程进入计时等待状态。Terminated: 正常或异常退出。 线程优先级 当虚拟机依赖于宿主机平台的线程实现机制时，java线程的优先级被映射到宿主机平台的优先级上，优先级个数也许更多，也许更少。比如Windows有7个线程优先级，而Linux没有线程优先级。 守护线程 当只剩下守护线程的时候，虚拟机就退出了。所以，守护线程不应该访问固有资源，如文件，数据库等，因为他们会在任何时候发生中断。 线程同步 java里面提供了两种同步机制: 1. synchronized关键字 2. ReentrantLock和Condition类 可重入锁指的是拥有某个锁的线程可以再次拥有该锁。该机制通过计数器实现。 Lock和Condition: 锁用来保护代码片段，任何时刻只能有一个线程执行被保护的代码 锁可以管理试图进入被保护代码段的线程 锁可以拥有一个或多个相关的条件对象(即条件变量) 每个条件对象管理那些已经进入被保护的代码段但还不能运行的线程 12345678# Locklock()unlock()# Conditionawait()signalAll()signal() synchronized关键字是java语言实现的一种内部机制: 每个对象都有一个内部锁。 123await()notify()notifyAll() 12345678910111213//synchronizedpublic synchronized void method() &#123; method body&#125;// ReentrantLockmyLock = new ReentrantLock();myLock.lock()try &#123; critical section;&#125; finally &#123; myLock.unlock();&#125; 同步阻塞 同步阻塞更像是一种显式利用对象锁的方式。 1234Object obj = new Object()synchronized (obj) &#123; critical section;&#125; 监视器 监视器是一种解决方案，该方案的目标是在程序员不考虑锁的情况下，也能保证多线程的安全性。 监视器必须满足如下特性: 监视器是只包含私有域的类 每个监视器类的对象有一个相关的锁 使用该锁对所有的方法进行加锁 该锁可以有任意多个相关条件 java实现了不严格的监视器。 volatile域 使用锁机制的开销很大，有时候仅仅为了访问一个或两个实例域，就没必要使用锁，所以出现了volatile域，该关键字为实例域的同步访问提供了一种免锁机制。 造成不同步的根源: 多处理器的计算机能够暂时在寄存器或本地内存缓冲区中保存内存中的值。结果是，运行在不同处理器上的线程可能在同一个内存位置取到不同的值 编译器可以改变指令执行的顺序以使吞吐量最大化。这种顺序上的变化不会改变代码语义，但是编译器假定内存的值仅仅在代码中有显式的修改指令时才会改变。然而，内存的值可以被另一个线程改变 使用锁的情况下，不用考虑以上问题。详见(java内存模型和线程规范 JSR133) 如果声明一个域为volatile，那么编译器和虚拟机就知道该域是可能被另一个线程并发更新的。但该关键字并不提供原子性，只对变量的赋值和访问起作用。 final变量 1final Map&lt;String, Double&gt; accounts = new HashMap(); 其他线程会在构造函数完成构造之后才看到这个accounts变量。 死锁死锁产生的条件: 1. 由于逻辑错误导致 2. 由于并发工具使用错误导致(比如notify()) 线程本地数据 ThreadLocal 锁测试与超时 在尝试获取一个锁或等待某个条件时，可以加一个等待时间。该机制可以避免由于并发工具使用错误导致的死锁的发生。 读写锁 12345678910111213141516171819private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();private Lock readLock = rwl.readLock();private Lock writeLock = rwl.writeLock();public double getTotalBalance() &#123; readLock.lock(); try &#123;&#125; finally &#123; readLock.unlock(); &#125;&#125;public void transfer() &#123; writeLock.lock(); try &#123;&#125; finally &#123; writeLock.unlock(); &#125;&#125; 阻塞队列 使用底层的锁机制有很大的灵活性，但是也带来了一定的复杂性。所以，java提供了阻塞队列，程序员不需要关心底层的锁机制，就可以实现多线程的管理。 并发安全的集合 java也提供了一些线程安全的数据结构。在java.util.concurrent包中。 123456ConcurrentHashMapConcurrentSkipListMapConcurrentSkipListSetConcurrentLinkedQueueCopyOnWriteArrayListCopyOnWriteArraySet 同步包装器 java提供的大部分集合不是线程安全的，但是可以通过同步包装器将其变为线程安全的。 1234567List&lt;E&gt; synchArrayList = Collections.synchronizedList(new ArrayList&lt;E&gt;());对于该集合的迭代，需要使用客户端锁定synchronized(synchArrayList) &#123; 迭代代码;&#125; Callable和Future 线程池 使用线程池的步骤: 调用Executors类中的静态的方法newCachedThreadPool或其他方法 调用submit提交Runnable或Callable对象 如果想要取消一个任务，或如果提交Callable对象，那就要保存好返回的Future对象 当不再提交任何任务时，调用shutdown 控制任务组 与python对比:python中没有私有公有属性之分，并且鼓励直接调用属性，因为有其他机制可以控制对属性的访问操作。python中也有类属性或类方法。python中也采用按值传递的方式。python中的super是一个内建函数。 python中的相等性比较: “==”: 比较值得相等性 “is”: 比较引用地址，是否是同一个对象 python中不同类型的比较方法如下: 数字通过相对大小比较 字符串按照字典顺序，逐个字符进行比较 列表和元组从左到右对每部分的内容进行比较 字典通过排序之后的键值列表进行比较(PY3不支持) 与C++的对比:C++中有值传递和引用传递两种方式。 在C++中不能直接初始化属性，所有域必须在构造器中设置。 在C++中一个构造器不能调用另一个构造器。必须将公共初始化代码抽象出来。 在C++中继承分为公有继承，保护继承和私有继承三种。 在C++中为了实现多态，需要显式的将某个方法指定为虚拟方法。","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"理论篇-python之异常","date":"2017-07-10T02:06:54.000Z","path":"2017/07/10/理论篇-python之异常/","text":"123try/except/else/finally # 捕获异常并恢复 没发生异常时执行else 无论是否发生异常都执行finallyraise # 手动在代码中触发异常assert # 有条件的在程序中触发异常 内置异常分类 内置异常 解释 特殊说明 BaseException 异常的顶级根类 Exception 与应用相关的异常顶级根超类 用户定义的异常应该继承此类 ArithmeticError 所有数值错误的超类 Exception的子类 OverflowError 识别特定数值错误的子类","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"总结篇-python","date":"2017-07-09T07:06:37.000Z","path":"2017/07/09/总结篇-python/","text":"数据类型与数据结构python支持的数据类型有Number, String, File python支持的数据结构有list, dict, tuple, set 1234列表推导式[x+1 for x in [1, 2]]字典推导式&#123;x: x+1 for x in range(10)&#125; 由于python是强类型语言，所以类型之间不行互相自动转换。 控制结构python支持的控制结构: 1234567891011121314151617181920if &lt;test&gt; then: &lt;statements&gt;elif &lt;test&gt;: &lt;statements&gt;else: &lt;statements&gt; 三元表达式: A = &quot;x&quot; if True else &quot;y&quot;A = True and &quot;x&quot; or &quot;y&quot;while &lt;test&gt;: &lt;statements&gt;else: # 只有当循环正常离开时才会执行(即没有碰到break语句) &lt;statements&gt; for &lt;target&gt; in &lt;object&gt;: &lt;statements&gt;else: # 只有当循环正常离开时才会执行(即没有碰到break语句) &lt;statements&gt; 相关的内建函数: range zip map 迭代协议: __iter__ __next__ 序列协议: __getitem__ 函数12def &lt;name&gt;(arg1, arg2, arg3,... argN): &lt;statements&gt; 语法 | 解释def func(name) | 常规参数def func(name=value) | 默认参数值def func(*name) | 匹配并收集(在元组中)所有包含位置的参数def func(**name) | 匹配并收集(在字典中)所有包含位置的参数 lambad表达式: 1lambad arg1, arg2,... argN: expression using arguments 作用域LEGB法则: L: 本地作用域E: 嵌套作用域G: 全局作用域B: 内置作用域 global语句的作用, nonlocal(py3.0之后)语句的作用 12345678910111213num = 1def t1(name, count): def t2(): global num nonlocal name, count name = &quot;yyy&quot; count += 1 num += 1 print(name, count, num) return t2t1(&quot;xxx&quot;, 1)() 模块和包import执行过程: 搜索 搜索路径: 程序主目录 PYTHONPATH目录 标准库目录 任何.pth文件的内容 编译 运行 重新导入模块: reload 包含__init__.py文件的目录即是包 123sys.path # 所有的搜索路径内建函数:__import__ 使用时必须显式导入内建库模块属性: __name__ 类1234567内建函数super的理解与使用各种重载运算符descriptor对属性的访问管理类的继承与搜索方式@classmethod@staticmethod多重继承以及实际中的应用 异常环境管理协议: 计算表达式，得到的对象为环境管理器，该管理器必须有__enter__和__exit__方法 环境管理器的__enter__方法会被调用。若存在as子句，其返回值会赋给as子句中的变量，否则丢弃 代码块中嵌套的代码将会执行 发生异常或者代码块执行完毕后，都会调用__exit__(type, value, traceback)方法。若没有发生异常，则参数都为None。若发生异常，则为异常信息。 装饰器实际开发中用的比较多，必须掌握。 元类在写框架代码的时候用的较多。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇之mysql","date":"2017-07-04T13:17:43.000Z","path":"2017/07/04/理论篇之mysql/","text":"","tags":[]},{"title":"理论篇-peewee","date":"2017-07-04T10:38:01.000Z","path":"2017/07/04/理论篇-peewee/","text":"ORM框架的理论基础: python mysql Model class Database table Field instance Column on a table Model instance Row in a database table 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import loggingfrom datetime import dateimport timefrom peewee import *logger = logging.getLogger(&quot;peewee&quot;)logger.setLevel(logging.DEBUG)logger.addHandler(logging.StreamHandler())db = MySQLDatabase(&apos;peewee_test&apos;, host=&apos;192.168.99.110&apos;, port=3306, user=&apos;root&apos;, passwd=&apos;xxx&apos;, charset=&apos;utf8&apos;)class BaseModel(Model): class Meta: database = dbclass Person(BaseModel): name = CharField(max_length=10, null=False, index=True) birthday = DateField(null=False, default=None) is_relative = BooleanField()class Pet(BaseModel): owner = ForeignKeyField(Person, related_name=&apos;pets&apos;) name = CharField() animal_type = CharField()db.connect()# ---- create table ----db.create_tables([Person, Pet])# ---- save ----bob = Person(name=&apos;Bob&apos;, birthday=date(1989, 4, 17))bob.save()foo = Person.create(name=&apos;Foo&apos;, birthday=date(1991, 1, 6))time.sleep(30)foo.name = &apos;Fu&apos;foo.save()# ---- save and delete ----test = Person.create(name=&quot;test&quot;, birthday=date(2017, 1, 1))time.sleep(30)test.delete_instance()uncle_bob = Person.create(name=&apos;Bob&apos;, birthday=date(1960, 1, 15), is_relative=True)grandma = Person.create(name=&apos;Grandma&apos;, birthday=date(1935, 3, 1), is_relative=True)herb = Person.create(name=&apos;Herb&apos;, birthday=date(1950, 5, 5), is_relative=False)bob_kitty = Pet.create(owner=uncle_bob, name=&apos;Kitty&apos;, animal_type=&apos;cat&apos;)herb_fido = Pet.create(owner=herb, name=&apos;Fido&apos;, animal_type=&apos;dog&apos;)herb_mittens = Pet.create(owner=herb, name=&apos;Mittens&apos;, animal_type=&apos;cat&apos;)herb_mittens_jr = Pet.create(owner=herb, name=&apos;Mittens Jr&apos;, animal_type=&apos;cat&apos;)# ---- select ----fu = Person.select().where(Person.name == &apos;Fu&apos;).get()print(fu.birthday)bob = Person.get(Person.name == &apos;Bob&apos;)print(bob.birthday)for person in Person.select(): print(person.name, person.birthday)for person in Person.select().order_by(Person.name): print(person.name, person.birthday)for person in Person.select().order_by(Person.birthday.desc()): print(person.name, person.birthday)for person in Person.select(): print(person.name, person.pets.count(), &apos;pets&apos;) for pet in person.pets: print(&apos; &apos;, pet.name, pet.animal_type)subquery = Pet.select(fn.COUNT(Pet.id)).where(Pet.owner == Person.id)query = (Person.select(Person, Pet, subquery.alias(&apos;pet_count&apos;)).join(Pet, JOIN.LEFT_OUTER).order_by(Person.name))for person in query.aggregate_rows(): print(person.name, person.pet_count, &apos;pets&apos;) for pet in person.pets: print(&apos; &apos;, pet.name, pet.animal_type)db.close() 管理你的数据库多线程应用peewee将连接存储到线程的本地数据上，因此每个线程持有一个数据库连接。如果你想自己管理连接，可以在初始化数据库的时候加上参数threadlocals=False 运行时数据库配置有时候数据的配置直到运行时才知道，因为这些值可能从配置文件中加载。此种情况下，使用如下代码: 1234567database = SqliteDatabase(None) # Un-initialized database.class SomeModel(Model): class Meta: database = databasedatabase.init(database_name, host=&apos;localhost&apos;, user=&apos;postgres&apos;) 动态的定义一个数据库多个数据库使用一个数据模型的场景下，使用Proxy 12345678910111213141516171819database_proxy = Proxy() # Create a proxy for our db.class BaseModel(Model): class Meta: database = database_proxy # Use proxy for our DB.class User(BaseModel): username = CharField()# Based on configuration, use a different database.if app.config[&apos;DEBUG&apos;]: database = SqliteDatabase(&apos;local.db&apos;)elif app.config[&apos;TESTING&apos;]: database = SqliteDatabase(&apos;:memory:&apos;)else: database = PostgresqlDatabase(&apos;mega_production_db&apos;)# Configure our proxy to use the db we specified in config.database_proxy.initialize(database) 连接池在web应用中，为了提高程序的性能，必须使用连接池。连接池提供了如下两个功能: 连接超时时间设置 最大连接数 12345678910db = PooledMySQLDatabase( &apos;peewee_test&apos;, max_connections=4, stale_timeout=300, host=&apos;127.0.0.1&apos;, port=3306, user=&apos;root&apos;, passwd=&apos;xxx&apos;, charset=&apos;utf8&apos;) 从从节点读为了提高数据库的性能，写入主库，但是从从库中读取。 123456789101112131415from peewee import *from playhouse.read_slave import ReadSlaveModel# Declare a master and two read-replicas.master = PostgresqlDatabase(&apos;master&apos;)replica_1 = PostgresqlDatabase(&apos;replica&apos;, host=&apos;192.168.1.2&apos;)replica_2 = PostgresqlDatabase(&apos;replica&apos;, host=&apos;192.168.1.3&apos;)class BaseModel(ReadSlaveModel): class Meta: database = master read_slaves = (replica_1, replica_2)class User(BaseModel): username = CharField() 模式修改1234567891011121314from playhouse.migrate import *my_db = SqliteDatabase(&apos;my_database.db&apos;)migrator = SqliteMigrator(my_db)title_field = CharField(default=&apos;&apos;)status_field = IntegerField(null=True)with my_db.transaction(): migrate( migrator.add_column(&apos;some_table&apos;, &apos;title&apos;, title_field), migrator.add_column(&apos;some_table&apos;, &apos;status&apos;, status_field), migrator.drop_column(&apos;some_table&apos;, &apos;old_column&apos;), ) 从已存在的数据库中创建模型使用pwiz库 增加请求钩子该方法不推荐使用，因为效率极低。 tornado12345678910111213from tornado.web import RequestHandlerdb = SqliteDatabase(&apos;my_db.db&apos;)class PeeweeRequestHandler(RequestHandler): def prepare(self): db.connect() return super(PeeweeRequestHandler, self).prepare() def on_finish(self): if not db.is_closed(): db.close() return super(PeeweeRequestHandler, self).on_finish() 高级连接管理12345678910111213with db.execution_context() as ctx: # A new connection will be opened or, if using a connection pool, # pulled from the pool of available connections. Additionally, a # transaction will be started. user = User.create(username=&apos;charlie&apos;)# When the block ends, the transaction will be committed and the connection# will be closed (or returned to the pool).@db.execution_context(with_transaction=False)def do_something(foo, bar): # When this function is called, a separate connection is made and will # be closed when the function returns. 使用多个数据库使用Using语句 12345678910111213141516171819202122master = PostgresqlDatabase(&apos;master&apos;)read_replica = PostgresqlDatabase(&apos;replica&apos;)class Data(Model): value = IntegerField() class Meta: database = master# By default all queries go to the master, since that is what# is defined on our model.for i in range(10): Data.create(value=i)# But what if we want to explicitly use the read replica?with Using(read_replica, [Data]): # Query is executed against the read replica. Data.get(Data.value == 5) # Since we did not specify this model in the list of overrides # it will use whatever database it was defined with. SomeOtherModel.get(SomeOtherModel.field == 3) 自动重连123456789from peewee import *from playhouse.shortcuts import RetryOperationalErrorclass MyRetryDB(RetryOperationalError, MySQLDatabase): passdb = MyRetryDB(&apos;my_app&apos;) 记录查询12345# Print all queries to stderr.import logginglogger = logging.getLogger(&apos;peewee&apos;)logger.setLevel(logging.DEBUG)logger.addHandler(logging.StreamHandler()) 增加其他数据库驱动目前peewee支持Postgres, MySQL and SQLite，但也可以手动添加其他数据库的支持。 模型与字段","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-tornado之性能测试","date":"2017-07-04T07:43:59.000Z","path":"2017/07/04/实战篇-tornado之性能测试/","text":"cpu 内存 4 4GB 12345678910111213141516171819202122232425processor : 0vendor_id : GenuineIntelcpu family : 6model : 69model name : Intel(R) Core(TM) i3-4010U CPU @ 1.70GHzstepping : 1microcode : 31cpu MHz : 782.000cache size : 3072 KBphysical id : 0siblings : 4core id : 0cpu cores : 2apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 13wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer xsave avx f16c rdrand lahf_lm abm ida arat epb xsaveopt pln pts dtherm tpr_shadow vnmi flexpriority ept vpid fsgsbase bmi1 avx2 smep bmi2 erms invpcidbogomips : 3392.12clflush size : 64cache_alignment : 64address sizes : 39 bits physical, 48 bits virtualpower management: 进程数: 1 请求数 并发数 QPS time(s) 特殊说明 10000 1 796 12 单核cpu: 100% 10000 2 815 12 单核cpu: 100% 10000 4 819 12 单核cpu: 100% 10000 8 817 12 单核cpu: 100% 50000 16 818 61 单核cpu: 100% 50000 32 818 61 单核cpu: 100% 50000 64 813 61 单核cpu: 100% 进程数: 4 请求数 并发数 QPS time(s) 特殊说明 10000 1 386 25 cpu: 40% 10000 2 1295 7 cpu: 70% 10000 4 1683 6 cpu: 100% 10000 8 1681 6 cpu: 100% 50000 16 1677 30 cpu: 100% 50000 32 1675 30 cpu: 100% 50000 64 1675 30 cpu: 100% peewee进程数: 4 连接池: 4 请求数 并发数 QPS time(s) 特殊说明 10000 1 213 46 cpu: 40% 10000 2 631 15 cpu: 60% 10000 4 893 11 cpu: 88% 10000 8 890 11 cpu: 88% 备注: 由于数据库与服务部署在同一台机器上，数据库也占用了部分计算资源，所以整个机器的cpu利用率达到了100%，但是服务占用的只有88%。","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之最简模型","date":"2017-07-04T04:36:27.000Z","path":"2017/07/04/理论篇-tornado之最简模型/","text":"tornado是以事件和协程为基础的服务器。由于python中并未实现真正的协程，所以使用生成器实现协程的功能。 以下代码是tornado框架的核心，读懂了该代码，对tornado框架也应该就清楚了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import randomimport timedef odd_f(): count = 0 while True: count += 1 num = yield &apos;continue&apos; print(&quot;odd: &#123;&#125;&quot;.format(num)) if count &gt;= 10: break yield &apos;quit&apos;def even_f(): count = 0 while True: count += 1 num = yield &apos;continue&apos; print(&quot;even: &#123;&#125;&quot;.format(num)) if count &gt;= 10: break yield &apos;quit&apos;def main(): _callbacks = &#123;&#125; _callbacks[&quot;odd&quot;] = odd_f() _callbacks[&quot;odd&quot;].next() _callbacks[&quot;even&quot;] = even_f() _callbacks[&quot;even&quot;].next() while True: time.sleep(1) n = random.randint(0, 1000000) keys = _callbacks.keys() if n &amp; 1: if &quot;odd&quot; in keys: res = _callbacks[&quot;odd&quot;].send(n) if res == &quot;quit&quot;: del _callbacks[&quot;odd&quot;] else: if &quot;even&quot; in keys: res = _callbacks[&quot;even&quot;].send(n) if res == &quot;quit&quot;: del _callbacks[&quot;even&quot;] if len(_callbacks) == 0: breakif __name__ == &quot;__main__&quot;: main()","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-python标准库之数字与数学模块","date":"2017-07-03T03:32:22.000Z","path":"2017/07/03/理论篇-python标准库之数字与数学模块/","text":"numbersmathcmathdecimalfractionsrandomstatistics","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python标准库之并发执行","date":"2017-07-02T07:47:42.000Z","path":"2017/07/02/理论篇-python标准库之并发执行/","text":"线程 方法 用法 特殊说明 threading.active_count() threading.current_thread() threading.get_ident() threading.enumerate() threading.main_thread() threading.settrace(func) threading.setprofile(func) threading.stack_size([size]) threading.TIMEOUT_MAX Thread-Local Data 方法或类 用法 特殊说明 class threading.local 12mydata = threading.local()mydata.x = 1 Thread Objects创建线程的两种方法: 1. 传递一个可调用的对象给Thread 2. 继承Thread，并覆写__init__和run方法 方法或类 用法 特殊说明 class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None) start() run() join(timeout=None) name setName() getName() ident is_alive() daemon 必须在start()调用之前设置 isDaemon() setDaemon() 线程的几种状态如下图所示 守护线程: 只有当守护线程退出后，整个进程才会完全退出 主线程: 程序启动时的线程 由于GIL的原因，python中的多线程是伪多线程，即同一时刻只有一个线程执行，即使在多核计算机上。 Lock Objects(原始锁)原始锁是一种同步原语。原始锁有两种状态: 锁定和未锁定。当创建时，原始所处于未锁定状态，调用acquire方法时，变为锁定状态，调用release方法时，变为未锁定状态。当一个锁处于锁定状态时，其他线程调用acquire方法时将会阻塞，直到拥有该锁的线程调用release方法。如果尝试释放一个未锁定的锁，则会引发RuntimeError 锁也支持上下文管理协议，既可以使用with语句。 以下所有方法的执行都是原子的 方法或类 用法 特殊说明 class threading.Lock acquire(blocking=True, timeout=-1) 获取锁 release() 释放锁 RLock Objects(可重入锁)可重入锁(a reentrant lock)是另一种同步原语。该锁可被同一线程获取多次。 可重入锁支持的概念: 锁定和未锁定、”owning thread” and “recursion level”。 当锁计数为0时，将锁变为未锁定状态。 方法或类 用法 特殊说明 class threading.RLock 创建锁 acquire(blocking=True, timeout=-1) 获取锁 release() 释放锁 Condition Objects(条件变量)条件变量和某种锁相关。创建的时候可传递，若不传递则自动创建一个RLock。 条件变量也支持上下文管理协议。使用with语句获取相应的锁。 当拥有锁的时候，可以调用其他的方法。wait方法释放锁，随后阻塞，直到其他线程通过调用notify或者notify_all方法来唤醒它。一旦被唤醒，wait方法将重新获取该锁并返回。 notify方法唤醒一个等待的线程。notify_all方法唤醒所有的等待线程。 条件变量一般用来使用锁来同步访问一些共享的状态。 1234567891011# consume one itemwith cv: while not an_item_is_available(): cv.wait() get_an_available_item() # produce one itemwith cv: make_an_item_available() cv.notify() 方法或类 用法 特殊说明 class threading.Condition(lock=None) acquire(*args) 获取锁 release() 释放锁 wait(timeout=None) 等待某个条件成立 wait_for(predicate, timeout=None) 等待某个条件成立 notify(n=1) 唤醒一个等待的线程 notify_all() 唤醒所有等待的线程 Semaphore Objects(信号量)这是最古老的同步原语之一。一个信号量管理一个内部的计数器。该计数器通过acquire递减，通过release增加。计数器从来不会小于0。当acquire发现计数器为0时，该线程将会阻塞，直到等待另一个线程调用release。 信号量也支持上下文管理。 方法或类 用法 特殊说明 class threading.Semaphore(value=1) acquire(blocking=True, timeout=None) release() class threading.BoundedSemaphore(value=1) 边界信号量 信号量一般用来保护某些资源，控制其最大访问并发。 Event Objects这是线程之间通信的最简单的方式之一。 方法或类 用法 特殊说明 class threading.Event is_set() set() clear() wait(timeout=None) Timer ObjectsTimer是Thread的一个子类。 方法或类 用法 特殊说明 class threading.Timer(interval, function, args=None, kwargs=None) cancel() Barrier Objects(屏障)这也是一种同步原语。该机制用于让指定数量的线程等待同一事件的发生，然后同时执行。 方法或类 用法 特殊说明 class threading.Barrier(parties, action=None, timeout=None) wait(timeout=None) reset() 将barrier设置到默认状态，同时处于等待状态的线程将收到BrokenBarrierError abort() 将barrier设置到broken状态，同时处于等待状态的线程将收到BrokenBarrierError parties n_waiting broken 进程multiprocessing是一个支持产生进程的包，该包的api与threading类似。多进程不受GIL的限制，可以充分利用多核资源。 方法或类 用法 特殊说明 multiprocessing.active_children() multiprocessing.cpu_count() multiprocessing.current_process() multiprocessing.freeze_support() multiprocessing.get_all_start_methods() multiprocessing.get_context(method=None) multiprocessing.get_start_method(allow_none=False) multiprocessing.set_executable() multiprocessing.set_start_method(method) Process Class在multiprocessing里，进程通过创建Process对象产生，随后调用start方法。 方法或类 用法 特殊说明 class multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None) run() start() 父进程调用 join([timeout]) 父进程调用 name is_alive() 父进程调用 daemon pid exitcode 父进程调用 authkey sentinel terminate() 父进程调用 1234567891011from multiprocessing import Processimport timedef f(name): time.sleep(10) print(&apos;hello&apos;, name)if __name__ == &quot;__main__&quot;: p = Process(target=f, args=(&apos;bob&apos;,)) p.start() p.join() Contexts and start methods根据平台的不同，multiprocessing支持三种不同的开始方法。这些开始方法是: spawn 父进程开始一个全新的python解释器。子进程只继承与运行run方法相关的资源。该方法相对于下面两种是慢的。 在Unix和Windows上均可用，在Windows上是默认的。 fork 父进程使用os.fork()来创建python解释器。开始的时候，子进程和父进程是一样的。所有的资源被子进程继承。安全的创建一个多线程的进程的子进程是有问题的。 仅在Unix上可用。在Unix上是默认的。 forkserver 该方法会创建一个服务器进程，专门用来创建子进程。 使用set_start_method()方法可用来选择开始方法。该方法仅被使用一次。 123456789101112import multiprocessing as mpdef foo(q): q.put(&apos;hello&apos;)if __name__ == &apos;__main__&apos;: mp.set_start_method(&apos;spawn&apos;) q = mp.Queue() p = mp.Process(target=foo, args=(q,)) p.start() print(q.get()) p.join() 进程之间通信multiprocessing支持两种类型的进程间通信。 方法或类 用法 特殊说明 multiprocessing.Pipe([duplex]) class multiprocessing.Queue([maxsize]) qsize() empty() full() put(obj[, block[, timeout]]) put_nowait(obj) get([block[, timeout]]) get_nowait() close() join_thread() cancel_join_thread() 方法或类 用法 特殊说明 class multiprocessing.SimpleQueue empty() get() put(item) 方法或类 用法 特殊说明 class multiprocessing.JoinableQueue([maxsize]) task_done() join() Queue Queue类是线程和进程安全的。 1234567891011from multiprocessing import Process, Queuedef f(q): q.put([42, None, &apos;hello&apos;])if __name__ == &apos;__main__&apos;: q = Queue() p = Process(target=f, args=(q,)) p.start() print(q.get()) # prints &quot;[42, None, &apos;hello&apos;]&quot; p.join() Pipes Pipe()函数返回一对被管道连接的连接对象。 12345678910111213141516171819202122232425262728293031 from multiprocessing import Process, Pipe def f(conn): conn.send(&quot;hello world&quot;) conn.close() if __name__ == &quot;__main__&quot;: parent_conn, child_conn = Pipe() p = Process(target=f, args=(child_conn,)) p.start() print(parent_conn.recv()) p.join() ``` ##### 进程之间同步multiprocessing包含了所有来自threading的同步原语。方法或类 | 用法 | 特殊说明-------|-------|--------class multiprocessing.Barrier(parties[, action[, timeout]]) | |class multiprocessing.BoundedSemaphore([value]) | |class multiprocessing.Condition([lock]) | |class multiprocessing.Event | |class multiprocessing.Lock | |acquire(block=True, timeout=None) | |release() | |class multiprocessing.RLock | |acquire(block=True, timeout=None) | |release() | |class multiprocessing.Semaphore([value]) | | from multiprocessing import Process, Lock def foo(l, i): time.sleep(random.randint(1, 5)) l.acquire() try: print(“hello, {}”.format(i)) finally: l.release() if name == “main“: lock = Lock() for num in range(10): Process(target=foo, args=(lock, num,)).start() 1234567891011##### 进程之间共享方法或类 | 用法 | 特殊说明-------|-------|--------multiprocessing.Value(typecode_or_type, \\*args, lock=True) | |multiprocessing.Array(typecode_or_type, size_or_initializer, \\*, lock=True) | |* 共享内存 python提供了两种共享内存组件: Value和Array from multiprocessing import Process, Value, Array def f(n, a): n.value = 3.1415927 for i in range(len(a)): a[i] = -a[i] if __name__ == &apos;__main__&apos;: num = Value(&apos;d&apos;, 0.0) arr = Array(&apos;i&apos;, range(10)) p = Process(target=f, args=(num, arr)) p.start() p.join() print(num.value) print(arr[:]) 1234567891011121314151617181920212223242526272829* 服务进程##### 进程池Pool类代表了进程池。该类提供了几种不同的分配任务的方式。方法或类 | 用法 | 特殊说明-------|-------|--------class multiprocessing.pool.Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]]) | |apply(func[, args[, kwds]]) | 同步执行任务 |apply_async(func[, args[, kwds[, callback[, error_callback]]]]) | 异步执行任务 |map(func, iterable[, chunksize]) | |map_async(func, iterable[, chunksize[, callback[, error_callback]]]) | |imap(func, iterable[, chunksize]) | |imap_unordered(func, iterable[, chunksize]) | |starmap(func, iterable[, chunksize]) | |starmap_async(func, iterable[, chunksize[, callback[, error_back]]]) | |close() | |terminate() | |join() | |方法或类 | 用法 | 特殊说明-------|-------|--------class multiprocessing.pool.AsyncResult | |get([timeout]) | |wait([timeout]) | |ready() | |successful() | | from multiprocessing import Pool, TimeoutErrorimport timeimport os def f(x): return x*x if name == “main“: with Pool(processes=4) as pool: print(pool.map(f, range(10))) for i in pool.imap_unordered(f, range(10)): print(i) res = pool.apply_async(f, (20,)) print(res.get(timeout=1)) res = pool.apply_async(os.getpid, ()) print(res.get(timeout=1)) multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)] print([res.get(timeout=1) for res in multiple_results]) res = pool.apply_async(time.sleep, (10, )) try: res.get(timeout=1) except TimeoutError: print(&quot;TimeoutError&quot;) print(&apos;xxx&apos;) print(&apos;end&apos;) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152##### 日志方法或类 | 用法 | 特殊说明-------|-------|--------multiprocessing.get_logger() | |multiprocessing.log_to_stderr() | |#### 并发异步执行可以使用多线程或者是多进程。方法或类 | 用法 | 特殊说明-------|-------|--------class concurrent.futures.Executor | 抽象类 |submit(fn, \\*args, \\*\\*kwargs) | 返回一个Future对象 |map(func, *iterables, timeout=None, chunksize=1) | |shutdown(wait=True) | |##### ThreadPoolExecutorThreadPoolExecutor是Executor的子类，使用线程池来执行异步调用。方法或类 | 用法 | 特殊说明-------|-------|--------class concurrent.futures.ThreadPoolExecutor(max_workers=None) | |##### ProcessPoolExecutorProcessPoolExecutor是Executor的子类，使用进程池来执行异步调用。方法或类 | 用法 | 特殊说明-------|-------|--------class concurrent.futures.ProcessPoolExecutor(max_workers=None) | |##### Future Objects方法或类 | 用法 | 特殊说明-------|-------|--------class concurrent.futures.Future | |cancel() | |cancelled() | |running() | |done() | |result(timeout=None) | |exception(timeout=None) | |add_done_callback(fn) | |concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED) | |concurrent.futures.as_completed(fs, timeout=None) | |并发的威力: import concurrent.futuresimport time def f(num): time.sleep(5) print(num) return “—-{}”.format(num) def process_main(): with concurrent.futures.ProcessPoolExecutor(max_workers=20) as executor: for res in executor.map(f, range(10)): print(res) def thread_main(): with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor: for res in executor.map(f, range(10)): print(res) def main2(): for res in map(f, range(10)): print(res) if name == “main“: start = time.time() thread_main() end = time.time() print(end-start)``` 子进程事件调度器队列","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python标准库之运行时服务","date":"2017-07-02T06:08:40.000Z","path":"2017/07/02/理论篇-python标准库之运行时服务/","text":"syssysconfigbuiltins__main__warningscontextlib 方法 用法 特殊说明 @contextlib.contextmanager 定义上下文管理的工厂方法 contextlib.closing(thing) contextlib.suppress(*exceptions) 排除某些异常 contextlib.redirect_stdout(new_target) 重定向标准输出 contextlib.redirect_stderr(new_target) 重定向错误输出 12345678910111213import contextlib@contextlib.contextmanagerdef tag(name): print(&quot;&lt;%s&gt;&quot; % name) yield print(&quot;&lt;/%s&gt;&quot; % name)with tag(&quot;h1&quot;): print(&quot;foo&quot;) tornado中使用该库管理回调函数执行中产生的异常 abcatexittraceback__future__gcinspectsitefpectl","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python标准库之内建函数","date":"2017-07-01T11:13:31.000Z","path":"2017/07/01/理论篇-python标准库之内建函数/","text":"函数 解释 特别说明 abs(x) 返回一个数的绝对值 all(iterable) 如果所有元素都为真或者迭代器是空的则返回true 否则返回false any(iterable) 如果任意一个元素为真则返回true 否则返回false enumerate(iterable, start=0) 返回一个包含从start开始计数的元组数组 class dict(**kwarg) class dict(mapping, **kwarg) class dict(iterable, **kwarg) 返回一个字典 filter(function, iterable) 返回一个迭代器 过滤元素 getattr(object, name[, default]) 获得对象的属性值 hasattr(object, name) 判断对象是否有该属性 hex(x) 转换一个整数值到一个十六进制值 以”0x”为前缀 int(x=0) int(x=0, base=10) 将一个数字或者字符串转换为整数 base是进制 iter(object[, sentinel]) 返回一个迭代对象， object要么支持迭代协议或序列协议 要么有第二个参数且object是可调用的 len(s) 返回一个对象的长度 map(function, iterable, …) 返回一个迭代器 将function应用到传入的迭代器中的每一项 oct(x) 将一个数字转换为八进制字符串 class list([iterable]) 将一个可迭代对象转换为可变的列表 range(stop) range(start, stop[, step]) 返回一个不可变序列 setattr(object, name, value) 给某个对象设置属性值 sorted 排序 python2 和 python3不同，需要functools.cmp_to_key super 返回一个代理对象，委托方法调用到父类或者兄弟类 zip 聚合n个可迭代的对象为一个可迭代对象 zip([‘A’, ‘B’], [1, 2], [‘a’, ‘b’]) =&gt; ((‘A’, 1, ‘a’), (‘B’, 2, ‘b’)) super的两种主要用法: 在单继承的类结构里，super被用来指向父类，而不用显式声明。这和其他语言中的super功能类似 在多继承的类结构里，这是python独一无二的，在其他编译型语言或者单继承的语言里不可见。 无参的super()调用只能在类中使用，其它方式的调用没有此限制 zip的用途: 用于列表的并行遍历 1234567891011121314151617181920212223242526272829303132333435363738394041424344-------- enumerate --------&gt;&gt;&gt;seasons = [&apos;Spring&apos;, &apos;Summer&apos;, &apos;Fall&apos;, &apos;Winter&apos;]&gt;&gt;&gt;list(enumerate(seasons))[(0, &apos;Spring&apos;), (1, &apos;Summer&apos;), (2, &apos;Fall&apos;), (3, &apos;Winter&apos;)]-------- sorted --------l = [2, 5, 1, 3, 6, 8, 4]def mycmp(x, y): print(x, y) if x&gt;y: return 1 if x&lt;y: return -1 return 0#sorted_l = sorted(l, cmp=mycmp) # 2中可执行 3中不可以sorted_l = sorted(l, key=functools.cmp_to_key(mycmp)) # 3中可执行print(l)print(sorted_l)-------- zip --------list(zip(&apos;ABCD&apos;, &apos;1234&apos;, &apos;abcd&apos;))-------- super --------class A: def test(self): print(&quot;A&quot;)class B: def test(self): print(&quot;B&quot;)class C: def test(self): print(&quot;C&quot;)class D(A, B, C): def test(self): super(B, self).test() print(&quot;D&quot;)d = D()d.test()","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python标准库之函数编程模块","date":"2017-07-01T10:50:14.000Z","path":"2017/07/01/理论篇-python标准库之函数编程模块/","text":"itertoolsfunctoolsfunctools模块为了更高级的函数: 操作或者返回其他函数的函数。 方法 作用 特别说明 functools.cmp_to_key(func) 将一个comparison function 转换到 key function py2到py3的sorted函数中使用 @functools.lru_cache(maxsize=128, typed=False) 根据入参缓存函数的执行结果，以提高程序的效率 @functools.total_ordering 自动填充剩余的比较方法 The class must define one of __lt__(), __le__(), __gt__(), or __ge__(). In addition, the class should supply an __eq__() method. functools.partial(func, *args, **kwargs) 给函数添加默认参数 class functools.partialmethod(func, *args, **keywords) functools.reduce(function, iterable[, initializer]) 与py2中的内建函数reduce功能一样 在py3中删除了reduce内建函数 @functools.singledispatch(default) 使函数具有针对不同类型参数做不同处理的能力 非常有用 functools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES) @functools.wraps(wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES) 这是update_wrapper函数的装饰器版本 更新一个包裹函数 让其更像被包裹的函数 非常有用 特别是写装饰器的时候 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import functools-------- cmp_to_key --------l = [2, 5, 1, 3, 6, 8, 4]def mycmp(x, y): print(x, y) if x&gt;y: return 1 if x&lt;y: return -1 return 0#sorted_l = sorted(l, cmp=mycmp)sorted_l = sorted(l, key=functools.cmp_to_key(mycmp))print(l)print(sorted_l)d = [(&quot;c&quot;, 3), (&quot;a&quot;, 1), (&quot;e&quot;, 6)]sorted_d = sorted(d, key=lambda x: x[1], reverse=True)print(sorted_d)-------- lru_cache --------@functools.lru_cache(maxsize=32)def hehe(num): print(num) return num+10l = [1, 3, 1, 3, 1, 3]print(l)for temp in l: hehe(temp)print(hehe.cache_info())-------- partial --------basetwo = functools.partial(int, base=2)print(basetwo(&apos;1111&apos;))-------- singledispatch --------@functools.singledispatchdef fun(arg, verbose=True): if verbose: print(&quot;hello, &quot;, end=&quot;&quot;) print(arg)@fun.register(list)def _(arg, verbose=True): if verbose: print(&quot;hi, &quot;, end=&quot;&quot;) for temp in arg: print(temp, end=&quot; &quot;) print()fun(1)fun(&quot;world&quot;)fun([1, 2, 3]) operator","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-python升级","date":"2017-07-01T08:53:00.000Z","path":"2017/07/01/实战篇-python升级/","text":"123456wget https://www.python.org/ftp/python/2.7.13/Python-2.7.13.tgz --no-check-certificatetar -xzvf Python-2.7.13.tgzcd Python-2.7.13./configuremakemake install","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python标准库","date":"2017-06-30T10:24:18.000Z","path":"2017/06/30/理论篇-python标准库/","text":"简介 内建函数 内建常量 内建类型 内建异常 文本处理服务 二进制数据服务 数据类型 数字和数学模块 函数编程模块 文件和目录访问 数据持久化 数据压缩与归档 文件格式 密码服务 一般操作系统服务 并发执行 进程间通信与网络 网络数据处理 标记性语言处理工具 网络协议与支持 多媒体服务 国际化 编程框架 图形化界面 开发工具 调试与优化 软件包与发布 运行时服务 定制化python解释器 导入模块 python语言服务","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-redis相关日志","date":"2017-06-17T07:15:56.000Z","path":"2017/06/17/实战篇-redis相关日志/","text":"主从复制一主两从123456789101112131415161718192021222324252627# 主节点3215:M 07 Jun 06:58:47.793 * DB loaded from append only file: 0.000 seconds3215:M 07 Jun 06:58:47.793 * The server is now ready to accept connections on port 6379# 从节点3222:S 07 Jun 06:59:45.630 * DB loaded from append only file: 0.000 seconds3222:S 07 Jun 06:59:45.630 * The server is now ready to accept connections on port 63803222:S 07 Jun 06:59:45.630 * Connecting to MASTER 127.0.0.1:63793222:S 07 Jun 06:59:45.630 * MASTER &lt;-&gt; SLAVE sync started3222:S 07 Jun 06:59:45.630 * Non blocking connect for SYNC fired the event.3222:S 07 Jun 06:59:45.630 * Master replied to PING, replication can continue...3222:S 07 Jun 06:59:45.630 * Partial resynchronization not possible (no cached master)3222:S 07 Jun 06:59:45.632 * Full resync from master: 2fdcd7b48c6db57255a12429a04b7a92e3a06082:13222:S 07 Jun 06:59:45.732 * MASTER &lt;-&gt; SLAVE sync: receiving 149 bytes from master3222:S 07 Jun 06:59:45.732 * MASTER &lt;-&gt; SLAVE sync: Flushing old data3222:S 07 Jun 06:59:45.732 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory3222:S 07 Jun 06:59:45.732 * MASTER &lt;-&gt; SLAVE sync: Finished with success3222:S 07 Jun 06:59:45.734 * Background append only file rewriting started by pid 32263222:S 07 Jun 06:59:45.763 * AOF rewrite child asks to stop sending diffs.3226:C 07 Jun 06:59:45.763 * Parent agreed to stop sending diffs. Finalizing AOF...3226:C 07 Jun 06:59:45.763 * Concatenating 0.00 MB of AOF diff received from parent.3226:C 07 Jun 06:59:45.764 * SYNC append only file rewrite performed3226:C 07 Jun 06:59:45.764 * AOF rewrite: 6 MB of memory used by copy-on-write3222:S 07 Jun 06:59:45.833 * Background AOF rewrite terminated with success3222:S 07 Jun 06:59:45.833 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)3222:S 07 Jun 06:59:45.835 * Background AOF rewrite finished successfully sentinel一主两从 四个sentinel123456789# sentinel节点3428:X 07 Jun 07:35:03.954 # Sentinel ID is 260e9ef949d16eaa2b6f603b45f5eb184ada8a593428:X 07 Jun 07:35:03.954 # +monitor master mymaster 127.0.0.1 6379 quorum 23428:X 07 Jun 07:35:03.955 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:35:03.956 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:35:03.957 * +slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:35:27.318 * +sentinel sentinel 6a33cb60ba555f2f8cc197e248b9d6897203777f 127.0.0.1 26380 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:35:30.691 * +sentinel sentinel 7938ad3e26bd62a523750ed7f22020658b1720c9 127.0.0.1 26381 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:35:33.054 * +sentinel sentinel bb76a725c52efe13742e915b8b9e4b16324d2ccb 127.0.0.1 26382 @ mymaster 127.0.0.1 6379 宕掉一个sentinel节点12# sentinel节点3428:X 07 Jun 07:41:12.726 # +sdown sentinel bb76a725c52efe13742e915b8b9e4b16324d2ccb 127.0.0.1 26382 @ mymaster 127.0.0.1 6379 宕掉一个从节点12345# 主节点3396:M 07 Jun 07:38:50.317 # Connection with slave 127.0.0.1:6382 lost.# sentinel节点3428:X 07 Jun 07:39:20.380 # +sdown slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6379 对sentinel节点和其他redis节点无影响 宕掉主节点12345678910111213141516171819202122232425262728293031323334353637383940#领头sentinel节点3428:X 07 Jun 07:43:28.749 # +sdown master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:28.840 # +odown master mymaster 127.0.0.1 6379 #quorum 2/23428:X 07 Jun 07:43:28.840 # +new-epoch 13428:X 07 Jun 07:43:28.840 # +try-failover master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:28.843 # +vote-for-leader 260e9ef949d16eaa2b6f603b45f5eb184ada8a59 13428:X 07 Jun 07:43:28.849 # 7938ad3e26bd62a523750ed7f22020658b1720c9 voted for 260e9ef949d16eaa2b6f603b45f5eb184ada8a59 13428:X 07 Jun 07:43:28.855 # 6a33cb60ba555f2f8cc197e248b9d6897203777f voted for 260e9ef949d16eaa2b6f603b45f5eb184ada8a59 13428:X 07 Jun 07:43:28.897 # +elected-leader master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:28.897 # +failover-state-select-slave master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:28.970 # +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:28.970 * +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:29.061 * +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:29.067 # +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:29.067 # +failover-state-reconf-slaves master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:29.125 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:29.970 # -odown master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:30.072 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:30.072 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 63793428:X 07 Jun 07:43:30.143 # +failover-end master mymaster 127.0.0.1 63793428:X 07 Jun 07:43:30.144 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 63803428:X 07 Jun 07:43:30.144 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 63803428:X 07 Jun 07:43:30.144 * +slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 63803428:X 07 Jun 07:43:30.144 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 63803428:X 07 Jun 07:44:00.184 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 63803428:X 07 Jun 07:44:00.185 # +sdown slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 6380# 其他sentinel节点3433:X 07 Jun 07:43:28.803 # +sdown master mymaster 127.0.0.1 63793433:X 07 Jun 07:43:28.851 # +new-epoch 13433:X 07 Jun 07:43:28.855 # +vote-for-leader 260e9ef949d16eaa2b6f603b45f5eb184ada8a59 13433:X 07 Jun 07:43:28.862 # +odown master mymaster 127.0.0.1 6379 #quorum 3/23433:X 07 Jun 07:43:28.862 # Next failover delay: I will not start a failover before Wed Jun 7 07:49:28 20173433:X 07 Jun 07:43:29.130 # +config-update-from sentinel 260e9ef949d16eaa2b6f603b45f5eb184ada8a59 127.0.0.1 26379 @ mymaster 127.0.0.1 63793433:X 07 Jun 07:43:29.130 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 63803433:X 07 Jun 07:43:29.130 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 63803433:X 07 Jun 07:43:29.131 * +slave slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 63803433:X 07 Jun 07:43:29.131 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 63803433:X 07 Jun 07:43:59.148 # +sdown slave 127.0.0.1:6382 127.0.0.1 6382 @ mymaster 127.0.0.1 63803433:X 07 Jun 07:43:59.148 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6380","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"理论篇-选举算法","date":"2017-06-15T02:55:11.000Z","path":"2017/06/15/理论篇-选举算法/","text":"选举算法(consensus algorigthm)解决的问题是在一个分布式系统里，让系统中的每个节点对系统状态的改变达成共识。 目前有两个经过实践检验的选举算法: Paxos和Raft。Paxos是莱斯利·兰伯特于1990年提出的，但由于过于复杂，限制了它的发展。Raft是斯坦福的Diego Ongaro、John Ousterhout于2013年提出的，它的目标就是以易理解性取代Paxos。 Paxos算法实现: Chubby libpaxos Keyspace BerkeleyDB Zookeeper Raft算法实现: etcd redis","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"电影片-异性系列","date":"2017-06-14T07:57:48.000Z","path":"2017/06/14/电影片-异性系列/","text":"普罗米修斯该片是异性的前传，讲述的是异性的起源。 影片开头讲述的是一个很像人类的人在地球上喝了一碗药，然后自身开始分解，坠入大海，然后基因进行重组。再后来画面切换到一座漫游在太空中的太空船。此时，只有一个生化人在照看着飞船。当飞船到达目的后，休眠的人类开始苏醒。这些人中，每个人都身怀绝技。随着人们的活动，此行的目的也渐渐显露出来。其中一个科学家通过考古发现，在几个互不联系的古代文明中，人们敬奉着同一种符号。后来他们发现这个符号原来是一个星系，并且另一个科学家又发现这些星系中的一个星球在以一定的频率发送信号。于是就有了此次科学探险活动。随着剧情的发展，这些科学家真的发现了发明人类的人，我们称它为古老人。此时此次科学探险活动的另一个目的也慢慢浮出水面，原来是一个接近死亡的富翁想找到古老人，找到长生不老的秘密。人类的欲望真的是很大啊，特别是有钱人的欲望。后来，科学家们弄清楚了这些古老人的目的，原来他们在这个星球上进行生物武器实验，正在研究一种能够毁灭人类的生物武器，他们发明该武器的目的就是毁灭地球上的人类。古老人创造了人类，又想毁灭掉人类，估计是拿人类当小白鼠了吧。再后来就是人类为了保护地球利用自己的飞船将载满生物武器的即将飞往地球的古老人的飞船给撞毁了。最后从女主肚子里跑出来的怪物寄生在了那个唯一活着的古老人身上，然后异性就诞生了。 异形1影片开头讲述的是一个满载矿石的飞船遨游在太空中，然后，飞船叫醒了飞船上的机组人员。机组人员刚开始醒来的时候，以为自己到达地球了。但是，后来他们才发现，他们的飞行轨迹不是飞向地球，而是宇宙中的一颗小行星。通过电脑分析后得知，原来是一组信号改变了飞船的飞行轨迹。最后，这些人开始登陆小行星，开始了探险之旅。在探险的过程中，其中一个科学家遭遇了扑脸虫的攻击，然后从该科学家的肚子里钻出了一只异形。最后女主力战异形，进入太空舱休眠等待回家。","tags":[{"name":"电影篇","slug":"电影篇","permalink":"http://yoursite.com/tags/电影篇/"}]},{"title":"理论篇-高性能网络IO模型","date":"2017-06-09T05:58:06.000Z","path":"2017/06/09/理论篇-高性能网络IO模型/","text":"C10K问题C10K问题指的是让一台服务器支持1万个并发连接的问题。由于早期的服务器模型基于多进程(或多线程)。当一个新连接到达时，创建一个新的进程(或线程)来处理该连接。当服务器服务一万个连接的时候，就需要创建一万个进程(或线程)。服务器创建进程(或线程)是需要系统开销的，比如创建进程需要占用更多的内存，进程间切换需要占用更多的cpu。而在当时一台服务器同时创建一万个进程(或线程)是不可能实现(随着计算机硬件的升级，现在不知道可不可以，有时间测试下)。于是，C10K问题在当时就是一个很难解决的问题。 IO多路复用技术IO多路复用技术，这个名词给人的第一感觉是很难懂。我们拆开来一点点的分析: IO，大家都知道，输入输出。多路指的是什么呢？什么是路呢？如果我们把一个tcp连接当做一路的话，那么多路也就不难理解了，多路指的是多个tcp连接。复用，从字面上很好理解，就是重复利用的意思。现在整体理解如下:就是让多个tcp连接重复利用输入输出的技术。 我们再举一个例子: 比如在一家餐馆，这家餐馆的老板很精明，懂IO多路复用技术，所以只雇了一个服务员，这个服务员负责记下每位客人的菜单，然后将菜单送到厨房，让厨师开始烧菜。当菜烧好之后，服务员再负责将菜送到相应的客人面前，让客人用餐。其中每个客人相当于一个tcp连接。服务员是什么呢？ 支持IO多路复用技术的操作系统都做了相应的实现。比如linux中epoll，unix中的kqueue，windows中的iocp等。现在有了答案，服务员就相当于这些实现。 两种高性能网络IO模型有了IO多路复用技术，C10K问题就不攻自破了。我们只需要一个单进程单线程的服务，就能处理大量的并发连接请求。就像一个服务员可以同时服务很多客人一样。 目前，利用IO多路复用技术实现高性能网络IO的有两种模型: reactor和proactor。我们还是以服务员的例子来说明。 reactor模式: 服务员收集目前所有未点餐客人的用餐需求， 将菜单送到厨房，等待厨师做好后 将菜一一送到相应的客人面前，再回到1 proactor模式: 服务员收集目前所有未点餐客人的用餐需求和是否有菜做好 将菜单送到厨房(等到厨师做好菜之后，会通知服务员过来上菜)，若有菜做好则执行3否则再回到1 服务员将菜送到客人面前，再回到1 因为reactor模式比较简单，所以实际中用的比较多。但是如果餐馆的生意非常火，一个服务员肯定是忙不过来的，所以即使是reactor模式也有很多种不同的实现方法。 首先，我们先对服务器需要处理的任务进行建模。 当新连接到达时，有接收新连接的任务，acceptor 当连接上有数据到达时，有读数据的任务，read 对读取的数据进行处理，包括解码，业务处理，编码，我们统称为compute 将计算结果发送给客户端，send 单进程单线程reactor模型服务器有一个进程并且该进程只有一个线程，该线程负责所有的任务。如下图所示: 点评:该模型实现简单，性能也不差。但有很明显的缺点: 1. 不能高效得利用多核cpu。2. 如果计算占用过多的cpu，会导致大量的连接处于等待状态，新的连接也不能建立。 单进程多线程reactor模型服务器有一个进程，但是该进程有多个线程，主线程负责acceptor、read和send任务。其他线程负责compute任务。 点评:该模型实现相对简单，而且能高效的利用多核服务器的优势。并且也避免了第一种模型的两个缺点。 多进程的reactor模型多进程的reactor模型也有多种: 1. 每个进程负责所有的任务(未完待续) 也有很多其它变种的实现，这些实现想达到的目的就是有效的利用多核。 (未完待续)","tags":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"实战篇-php之apc","date":"2017-06-08T02:04:31.000Z","path":"2017/06/08/实战篇-php之apc/","text":"centos1234567891011121314yum install php-devel.x86_64#yum install gcc automake php httpd httpd-develyum install php-pearyum install php-devel.x86_64yum install pcre-develyum install nginxyum install php-fpm.x86_64yum install mysql-server.x86_64yum install gityum install php-mysql.x86_64pecl install apcecho &quot;extension=apc.so&quot; &gt;&gt; /etc/php.iniecho &quot;apc.enabled=1&quot; &gt;&gt; /etc/php.ini","tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"}]},{"title":"实战篇-nginx和php-fpm环境搭建","date":"2017-06-07T07:46:25.000Z","path":"2017/06/07/实战篇-nginx和php-fpm环境搭建/","text":"centos安装服务12yum install nginxyum install php-fpm 配置服务123456789101112131415161718192021222324mv /etc/nginx/conf.d/default.conf /etc/nginx/conf.d/xxx.conf将xxx.conf文件内容修改为如下:server &#123; listen 80 default_server; root path/to/home; index index.php; location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 在path/to/home目录下新建index.php文件 123&lt;?php echo &quot;hello world&quot;;?&gt; 启动服务12service php-fpm startservice nginx start","tags":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"理论篇-innodb的架构","date":"2017-06-07T06:31:40.000Z","path":"2017/06/07/理论篇-innodb的架构/","text":"","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"理论篇-LRU","date":"2017-06-07T03:34:47.000Z","path":"2017/06/07/理论篇-LRU/","text":"LRU(Least recently used)，最近最少被使用。该算法根据历史访问记录淘汰缓存数据，其理论依据是最近很少被使用的，以后使用的概率也不会太大。 最简单的LRU实现:底层数据结构采用单链表。查询时，首先检查缓存是否命中，若命中，则将命中的元素插入到链表的头，若未命中，则从原始存储中查找数据，然后将数据插入到链表的头。在将新元素插入到链表的头部时，若此时空间已满，则淘汰末尾的元素。 点评:实现简单，对于热点数据的访问，效果很好，但对于周期性的数据访问，效果很差 LRU-K实现:底层实现采用两个链表，分别是历史队列和缓存队列。查询时，首先查看缓存队列，若命中，则将访问数据插入到缓存队列的头部。若未命中，则查看历史队列，若命中，则增加该数据的访问次数，若达到k，则将该数据从历史队列移到缓存队列(此时若缓存队列已满，则会淘汰末尾数据)。若扔未命中，则从原始存储中查找数据，然后将数据插入到历史队列的头。 点评:实际使用中，k经常被设置为2。实现较复杂，使用两个队列来实现一个优先级队列。 扩展LRU-2使用两个队列来实现，一个历史队列，一个缓存队列，其中历史队列是FIFO，缓存队列是LRU。 LRU算法也可以使用多个队列来实现多优先级的队列。","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-算法总结","date":"2017-06-05T01:23:30.000Z","path":"2017/06/05/理论篇-算法总结/","text":"时间负责度被分为两个级别: 多项式级复杂度和非多项式级复杂度 多项式级复杂度: O(1) O(log(n)) O(n^a) 非多项式级复杂度: O(a^n) O(n!) 当我们在解决一个问题的时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度计算机往往不能承受，除非数据量非常少。 P问题: 一个可以找到在多项式时间内解决它的算法的问题 NP问题: 可以在多项式时间里验证一个解的问题 NPC问题: 是一类特殊的NP问题。需满足如下两个条件: 它得是一个NP问题 所有的NP问题都可约化到它 NPC问题目前没有多项式的有效算法，只能用指数级甚至阶乘级复杂度的搜索。 题目 时间复杂度 在一个无序序列中寻找最大值或最小值 O(n) 在一个无序序列中寻找任意值 O(n) 在一个无需序列中寻找第k大的值 O(n) 在一个有序序列中寻找最大值或最小值 O(1) 在一个有序序列中寻找任意值 O(lgn) 在一个有序序列中寻找第k大的值 O(1) 在两个有序序列中寻找第k大的值 O(lg(m+n)) 经典算法RSA reference什么是P问题、NP问题和NPC问题","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"实战篇-mac下eclipse中gdb配置","date":"2017-06-02T14:34:29.000Z","path":"2017/06/02/实战篇-mac下eclipse中gdb配置/","text":"mac-gdb-install","tags":[{"name":"mac","slug":"mac","permalink":"http://yoursite.com/tags/mac/"}]},{"title":"实战篇-leetcode刷题记录","date":"2017-06-02T02:30:15.000Z","path":"2017/06/02/实战篇-leetcode刷题记录/","text":"题目 难度 思路 答案 Two Sum 简单 参考答案 Add Two Numbers 中等 参考答案 Longest Substring Without Repeating Characters 中等 参考答案 Median of Two Sorted Arrays 困难 掐头去尾中间算 参考答案 Reverse Integer 简单 参考答案","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-python之元类","date":"2017-06-01T00:42:25.000Z","path":"2017/06/01/理论篇-python之元类/","text":"元类在class语句执行完之后自动执行。 元类的主要工作: 通过声明一个元类，我们告诉python路由类对象的创建到我们提供的另一个类。 有人使用元类实现面向切面编程和ORM？ 元类模型类是type的实例。 在3.x里，用户定义的类对象是type对象的实例，type对象自身也是一个类 在2.6里，新式类继承自object，object是type的子类。传统类是type的实例，但是不是从类中创建出来的。 1234567891011121314151617181920212223&gt;&gt;&gt; class C: pass # 2.6中的传统类...&gt;&gt;&gt; c = C()&gt;&gt;&gt; type(c)&lt;type &apos;instance&apos;&gt;&gt;&gt;&gt; type(C)&lt;type &apos;classobj&apos;&gt;&gt;&gt;&gt;&gt;&gt;&gt; class C(object): pass # 2.6中的新式类...&gt;&gt;&gt; c = C()&gt;&gt;&gt; type(c)&lt;class &apos;__main__.C&apos;&gt;&gt;&gt;&gt; type(C)&lt;type &apos;type&apos;&gt;&gt;&gt;&gt; class C(object): pass # 3.x中的类...&gt;&gt;&gt; c = C()&gt;&gt;&gt; type(c)&lt;class &apos;__main__.C&apos;&gt;&gt;&gt;&gt; type(C)&lt;class &apos;type&apos;&gt; 元类是type的子类元类是type的子类，类是type的实例，所以我们可以通过定制化元类来定制化类。 class声明协议class声明协议: 在class语句执行完之后，在执行完所有内嵌代码后，会调用type对象来创建class对象。 1class = type(classname, superclasses, attributedict) type对象定义了一个__call__方法，该方法运行两个其他的方法。 12type.__new__(typeclass, classname, superclasses, attributedict)type.__init__(class, classname, superclasses, attributedict) __new__方法创建和返回新的class对象。__init__初始化新创建的class对象。 举个例子: 123456class Spam(Eggs): data = 1 def meth(self, arg): pass Spam = type(&apos;Spam&apos;, (Eggs,), &#123;&apos;data&apos;: 1, &apos;meth&apos;: meth, &apos;__module__&apos;: &apos;__main__&apos;&#125;) 声明元类12345678910class Spam(Eggs, metaclass=Meta): pass # 3.0及后续版本class Spam(object): # 2.6 版本 __metaclass__ = Meta Spam = Meta(classname, superclasses, attributedict)#后续调用以下方法:Meta.__new__(class, classname, superclasses, attributedict)Meta.__init__(Meta, classname, superclasses, attributedict) python中的高级功能自省属性: __class__ __dict__ 运算符重载方法: __str__ __add__等 属性拦截方法: __getattr__ __setattr__ __getattribute__ 类property和类descriptor 函数和类装饰器 元类","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python中好玩的问题","date":"2017-05-30T09:38:57.000Z","path":"2017/05/30/理论篇-python中好玩的问题/","text":"python为什么不支持函数重载？ 其他语言里的函数重载，需要相同的函数名加不同的参数(要么参数的数量不同，要么参数的类型不同)。但是在python里参数是不区分类型的，所以根据类型不同是行不通了。如果在同一个模块里有两个函数名相同，参数数量不同的函数，最后一个函数会覆盖前一个函数。因为函数的定义本质是创建一个函数对象，然后赋值给一个变量名。 python里类的私有变量？ python中类的私有变量有两种形式: _x和__x。单下划线开头的是一种不正式的约定，双下划线开头的会有一个重命名操作: _class__x。python设计该功能的主要目的是为了防止命名冲突，而不是为了控制访问。 python中有几种可调用的对象? 四种: 简单函数(def 或 lambda)，继承__call__的实例，绑定方法","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-不容易写对的二分查找","date":"2017-05-30T08:27:01.000Z","path":"2017/05/30/理论篇-不容易写对的二分查找/","text":"前面我们介绍了那么多的排序算法，那对数据排序有什么用呢？这篇文章介绍一个专门针对有序序列的效率极高的查找算法: 二分查找。 核心思想: 首先，找到中间元素，将整个序列分为三部分: 小于等于中间元素的子序列+中间元素+大于等于中间元素的子序列。如果中间元素不是要查找的元素，则根据查找元素与中间元素的关系来决定是在哪个子序列中查找。直到找到或子序列不能分为止。 12345678910111213intbinary_search(int *a, int start, int end, int x) &#123; int mid; while (start &lt;= end) &#123; mid = (start+end)/2; if (a[mid] == x) return mid; if (a[mid] &gt; x) end = mid - 1; if (a[mid] &lt; x) start = mid + 1; &#125; return -1;&#125; 备注: 循环截止的条件必须是小于等于，假设数组只有一个元素，此时必须进入循环，判断该元素是不是要查找的值。","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-归并排序","date":"2017-05-30T07:58:50.000Z","path":"2017/05/30/理论篇-归并排序/","text":"归并排序是分而治之的典型应用。 核心思想:将数组递归得拆分到只有一个元素，此时该元素是有序的。然后利用一个临时数组将有序的两个子序列合并成一个更大的有序子序列，直到数组中的所有元素都有序。 源码参考","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-最简单的排序算法","date":"2017-05-29T14:03:38.000Z","path":"2017/05/29/理论篇-最简单的排序算法/","text":"编程入门都会从学习简单的排序算法开始，下面我们介绍两个经典的排序算法: 冒泡排序和插入排序。时间复杂度都是$O(n^2)$，由于复杂度过高，所以实际中应用不多。 冒泡排序冒泡排序得名于其排序过程中大数或小数会慢慢的浮到最上面，就像气泡浮出水面一样。 源码参考 插入排序插入排序的思想: 假设前半部分是有序的，然后将一个数插入到有序的前半部分中。 源码参考 两种排序的比较冒泡排序和插入排序是两种截然不同的排序算法，但是有些人会将这两个排序算法搞混，看着插入排序的有些写法向冒泡，可能是因为没有体会到这两种算法各自的精髓。","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-非比较排序算法","date":"2017-05-29T08:48:29.000Z","path":"2017/05/29/理论篇-非比较排序算法/","text":"在基于比较的排序算法中，归并排序与堆排序在最坏时间复杂度也能达到O(nlgn)，快速排序的平均时间复杂度是O(nlgn)。所以，基于比较的排序算法，O(nlgn)是最好表现。然而，基于非比较的排序算法的时间复杂度能达到O(n)。下面，我们介绍三个非比较的排序算法。 计数排序计数排序是稳定的排序算法，基数排序中使用到了该排序算法。 基数排序基数排序的思想: 首先使用最低关键字排序，然后再使用次低关键字，直到最高关键字。这样经过n次时间复杂度为O(n)的排序得到最后结果。 引用场景: 对于基于n个关键字的排序最有效 相关问题: 对于大数的排序 桶排序桶排序的思想: 首先，分配n个桶，将数据映射到桶中，然后再对桶中的数据进行排序(或继续使用桶排序算法或其他排序算法)。最后，将所有的桶中的数据串联起来，得到最后的结果。 应用场景: 对于海量且范围有限的数据进行排序最有效。 相关问题: 一年的高考人数为500万，分数使用标准分，最低100，最高999，没有小数，要求对所有的分数进行排序。 在一个文件中有10G个整数，乱序排列，要求找出中位数。内存限制为2G。","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-求第k个最大值或最小值","date":"2017-05-29T08:39:11.000Z","path":"2017/05/29/理论篇-求第k个最大值或最小值/","text":"问题描述: 在n个无序的数中，找到最大值或最小值 解题思路: 选择第一个数与剩下的其他n-1个数进行比较，这样经过n-1比较后得到结果。时间复杂度O(n) 问题描述: 在n个无序的数中，同时找到最大值和最小值 解题思路: 两个数为一组将数据分成若干组，首先组内比较一次，然后，最大值与组内最大值比较一次，最小值与组内最小值比较一次。这样每两个数经过3次比较就能得到最大值与最小值。最终比较次数3(n-2)/2。若n为偶数，第一个数即作为最大值也作为最小值，若n为奇数，前两个数比较得到最大值与最小值，除去第一个数之后进行分组比较。时间复杂度为O(n) 问题描述:在n个无序的数中，找到第k个最大或最小的数。 解题思路: 首先进行排序，然后第k个数就是要找的答案。无论使用哪种基于比较的排序算法，最好的时间复杂度也要O(nlgn)。有没有更好的解决方法呢？ 从快速排序中受到启发，每次在数组中寻找支点p时，寻找的支点就是第p个最大或最小的数。我们使用如下算法，就能以接近O(n)的时间复杂度找到答案:","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-快速排序","date":"2017-05-28T13:42:30.000Z","path":"2017/05/28/理论篇-快速排序/","text":"快速排序是生产环境中经常被用到的排序算法。快速排序算法也是一种运用分而治之思想的算法。 在分的过程中有两种不同的实现思想，分别如下图所示: 最近又看到一种实现: 填坑法。该方法比较简单，也比较容易理解。基本思想如下: 将第一个数记下作为key，同时挖出第一个坑 然后从后向前找第一个小于等于key的数，然后将该数填充的之前的坑中，同时又挖出了另一个坑 然后从前向后找第一个大于key的数，然后将该数填充到之前的坑中，此时又挖了一个坑 一直循环过程2和3，直到相遇。最后将之前的key填到最后的坑中。 这样保证了相遇位置之前的所有数都小于等于关键字，之后的数都大于关键字。 源码参考","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-数据结构之堆","date":"2017-05-28T01:58:50.000Z","path":"2017/05/28/理论篇-数据结构之堆/","text":"堆的底层实现一般是数组，堆可以看做是一棵近似完全二叉树。堆中的节点从上到下，从左到右，依次填充(只有最底层不会被填充满)。树的根节点是A[1]，给定任意节点，我们可以很容易得计算它的父节点，左孩子节点和右孩子节点的指针。 给定任意节点i，它的父节点、左孩子节点和右孩子节点的计算方法如下: 123parent: i/2left: 2iright: 2i+1 有两种类型的二叉堆: 大顶堆和小顶堆。 大顶堆的性质如下: 除了跟节点之外，其他任何节点的值都要小于或等于父节点的值。 小顶堆的性质如下: 除了根节点之外，其他任何节点的值都要大于或等于父节点的值。 应用堆的主要应用: 1. 堆排序 2. 实现优先级队列。 堆排序堆排序对于从海量数据中获取最小或最大的k个数特别有效。 思路: 首先建立一个能容纳k个元素的堆。然后遍历海量数据，将合适的值加入到堆中。最后进行一次堆排序，最后，得到已经有序的k个元素。 优先级队列优先级队列一般用于任务的管理。比如最大优先级队列用来管理进程的切换，最小优先级队列用来管理超时任务。 源代码","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"理论篇-innodb的多版本控制","date":"2017-05-27T06:01:48.000Z","path":"2017/05/27/理论篇-innodb的多版本控制/","text":"innodb是一个多版本存储引擎:为了支持事务功能(比如并发和回滚)，它保留已更新数据的一个或多个旧版本。这些信息被存储在表空间的rollback segment数据结构内。innodb使用这些信息来完成事务回滚操作或者为了一致性读而获取某些行的更早版本。 内部实现上，innodb在每行上增加如下三个字段: DB_TRX_ID，6个字节大小，最后插入或更新该行的事务id。删除操作也被当做一种更新操作来处理，本质是更新该行的某一个特定的位来表明该行已被删除。 DB_ROLL_PTR，7字节大小，回滚指针。该指针指向一个被写到rollback segment的undo日志记录。 DB_ROW_ID，6字节大小，行id。该字段是一个单调递增字段。如果innodb自动生成了一个集群索引，该索引会包含该字段的值。否则的话，该字段不会出现在任何索引上。 rollback segment里的undo日志被分为insert undo日志和update undo日志。insert undo日志只在事务回滚的时候需要。事务提交之后，立即删除。update undo日志除了用在事务回滚上，也被用在一致性读上。当没有事务需要利用undate undo日志来构建之前版本的行记录时，这些update undo日志也会被删除。 定期提交你的事务，包括那些一致性读的这些事务。否则的话，innodb不会删除update undo日志。rollback segment可能会越来越大。 rollback segment里的undo日志记录的物理大小比相应的插入的或更新的行要小。你可以使用这些信息来计算rollback segment所需要的空间大小。 在innodb的多版本模式下，当你使用sql语句删除的时候，该行不会被物理的删除。只有当删除操作的update undo日志记录被删除的时候，innodb才会物理上删除相应的行和它的索引。该删除操作被称为purge。 当在一个表中频繁的进行插入和删除操作的时候，purge线程将停止工作并倒计时，表会因为所有的已删除的行而变得越来越大。 1innodb_max_purge_lag # 该选项设置purge线程最大的等待时间，默认是0 Multi-Versioning and Secondary Indexes(待考究)innodb的MVCC对第二索引与集群索引的处理不同。在集群索引中的记录被实地(in-place)更新并且隐藏列指向了undo日志。第二索引没有隐藏列也不会实地(in-place)更新。 当第二索引的列被更新的时候，旧的第二索引记录有一个删除标记，新的记录被插入，被标记删除的记录最终会被清除。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"理论篇-innodb与ACID模型","date":"2017-05-27T05:34:31.000Z","path":"2017/05/27/理论篇-innodb与ACID模型/","text":"ACID模型是一系列数据库设计准则，该准则强调可靠性。InnnDB存储引擎接近于ACID模型，因此不论是软件故障还是硬件故障，数据的可靠性都能得到保障。你能通过调整mysql的设置在可靠性和更高的性能之间做一些取舍。 我们看下InnoDB存储引擎是怎么满足ACID模型的。 Atomicity原子性主要涉及InnoDB的事务。相关的mysql功能如下: autocommit设置 commit语句 rollback语句 表INFORMATION_SCHEMA中的数据 Consistency一致性主要涉及InnoDB用来保护数据的内部处理。相关的mysql功能如下: innodb的doublewrite buffer innodb的crash recovery Isolation隔离性主要涉及InnoDB的事务。相关的mysql功能如下: autocommit设置 SET ISOLATION LEVEL语句 innodb锁的底层实现细节。性能调优时，可参考表INFORMATION_SCHEMA中的数据 Durability持久性涉及到了mysql与特定的硬件。相关的mysql功能如下: innodb的doublewrite buffer。可通过innodb_doublewrite选项配置 配置选项innodb_flush_log_at_trx_commit 配置选项sync_binlog 配置选项innodb_file_per_table 写缓冲到存储设备上，例如普通硬盘，SSD或者RAID磁盘阵列 存储设备上的备用电池 操作系统，特别是支持fsync系统调用 不间断的电力供应 备份策略 对于分布式应用来说，可靠的网络","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"理论篇-innodb的锁与事务","date":"2017-05-26T12:40:03.000Z","path":"2017/05/26/理论篇-innodb的锁与事务/","text":"锁innodb实现了如下几种锁: share and exclusive locks intention locks record locks gap locks next-key locks insert intention locks AUTO-INC locks predicate locks for spatial indexes Shared and Exclusive Locksinnodb实现两种类型的行级锁: shared locks(S) 和 exclusive locks(X)。 S: 允许持有该锁的事务读取一行 X: 允许持有该锁的事务更新或删除一行 如果事务T1在行r上获取了S锁，另一个事务T2也想获取行r上的锁，此时处理如下: 若T2请求的是S锁，则立即获取 若T2请求的是X锁，则不能立即获取，需要等待事务T1上S锁的释放 如果事务T1在行r上获取了X锁，不论事务T2想获取行r的什么类型的锁，都不能立即获取，需要等待事务T1上X锁的释放 Intention Locksinnodb支持多粒度锁定，多粒度锁定允许行级锁和表级锁同时存在。为了实现多粒度锁定，innodb引入了另外一种锁: 意向锁。在innodb里意向锁是一种表锁，表明了一个事务稍后想在某行上加的锁的类型(S锁还是X锁)。有两种类型的共享锁: IS: 事务T想在某些行上设置S锁 IX: 事务T想在某些行上设置X锁 意向锁的协议如下: 在事务在表t的某一行上获取S锁之前，它必须首先获取一个IS锁或更强的锁 在事务获取X锁之前，它必须首先获取一个IX锁 – X IX S IS X 冲突 冲突 冲突 冲突 IX 冲突 不冲突 冲突 不冲突 S 冲突 冲突 不冲突 不冲突 IS 冲突 不冲突 不冲突 不冲突 如果一个正在请求的锁和已经存在的锁是不冲突的，则该锁立即被获取。如果冲突的话，则不能立即被获取。直到已经存在的锁被释放之后，才能获取。如果一直不能获取，那可能是死锁了，会报错。 因此，除了全表请求之外，意向锁不会阻塞任何事情。意向锁的主要目的是表明某人正在锁定某行或想锁定某行。 Record Locksrecord locks是索引记录锁。例如select c1 from t where c1=10 for update;会阻止任何事务插入、更新或删除c1=10的行。 record locks总是锁定索引记录，尽管该表没有定义任何索引。对于这种情况，innodb会创建一个隐藏的集群索引，并使用该索引。 Gap Locksgap locks是加在索引记录之间的间隙上的锁。该间隙包括记录之间、第一条之前、最后一条之后。例如select c1 from t where c1 between 10 and 20 for update;会阻止任何事务插入t.c1=15的数据，因为所有存在的值之间的间隙已经被锁定。 gap locks是性能和并发之间的权衡，被用在一些事务隔离级别里。 select * from child where id = 100;若id是唯一索引，则不触发gap locks。若id没有被索引或者不是唯一索引，则触发gap locks。 事务之间的gap locks永远不冲突。在innodb里的gap locks是”纯粹被禁止的”，那意味着他们仅阻止其他事务向该间隙插入值，他们不会阻止其他事务在同一个间隙上获得间隙锁。 gap locks可以被禁用，比如在read committed事务隔离级别下。 Next-Key Locksnext-key locks是索引记录上的record locks和索引记录之前的间隙上的gap locks的组合。 innodb执行行级别锁定的方式:当innodb搜索表索引时，会在搜索到的所有记录上添加锁。因此行级锁实际上就是索引记录锁。在索引记录上的next-key locks也会影响到在那个索引之前的间隙。比如: 如果一个会话在索引记录R上有一个锁，另一个会话不能立即在索引记录R之前(按照索引顺序)的间隙里插入一条新的索引记录。 假设有一个索引有如下值: 10, 11, 13和20。对于这个索引可能的next-key locks覆盖如下四个间隙。”(“代表不包含该记录 “[“代表包含该记录 12345(negative infinity, 10](10, 11](11, 13](13, 20](20, positive infinity] 默认情况下，innodb工作在repeatable read隔离级别下。在这种情况下，当尽心查找时，innodb使用next-key locks。next-key locks避免了幻读。 Insert Intention Locksinsert intention locks是在行插入之前被insert操作设置的一种gap lock。该锁表明如果多个插入同一索引间隙的事务插入的不是同一间隙内的相同的位置，则不必互相等待。 假设有一个索引，有4和7两个值。有两个事务分别想插入5和6这两个值。每个事务在插入行上获取X锁之前都优先获取了insert intention locks(锁定了4到7之间的间隙)。但是不会互相阻塞，因为行之间没有冲突。 AUTO-INC locksAUTO-INC locks是一个特殊的表级别的锁。当表中有AUTO_INCREMENT列时事务自动使用该锁。当一个事务正在插入一个表，其他想插入该表的事务必须等待。因此，第一个事务插入的自增值是连续的。 innodb_autoinc_lock_mode控制了自增锁使用的算法。它允许你在自增的连续性上和并发插入之间做一个取舍。 Predicate Locks for Spatial Indexes查看123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960show engine innodb status;&gt;select * from t where a=200 lock in share mode;RECORD LOCKS space id 26 page no 3 n bits 96 index PRIMARY of table `lock_test`.`t` trx id 2317 **lock mode S locks rec but not gap waiting**Record lock, heap no 22 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 00000000090c; asc ;; 2: len 7; hex 2b0000014801ca; asc + H ;; 3: len 10; hex 66666620202020202020; asc fff ;;&gt;select * from t where a=200 for update;RECORD LOCKS space id 26 page no 3 n bits 96 index PRIMARY of table `lock_test`.`t` trx id 2317 **lock_mode X locks rec but not gap waiting**Record lock, heap no 22 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 00000000090c; asc ;; 2: len 7; hex 2b0000014801ca; asc + H ;; 3: len 10; hex 66666620202020202020; asc fff ;; &gt;select * from t where a&lt;=200 lock in share mode;RECORD LOCKS space id 26 page no 3 n bits 96 index PRIMARY of table `lock_test`.`t` trx id 2317 **lock mode S waiting**Record lock, heap no 22 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 00000000090c; asc ;; 2: len 7; hex 2b0000014801ca; asc + H ;; 3: len 10; hex 66666620202020202020; asc fff ;; &gt;select * from t where a&lt;=200 for update;RECORD LOCKS space id 26 page no 3 n bits 96 index PRIMARY of table `lock_test`.`t` trx id 2317 **lock_mode X waiting**Record lock, heap no 22 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 00000000090c; asc ;; 2: len 7; hex 2b0000014801ca; asc + H ;; 3: len 10; hex 66666620202020202020; asc fff ;; &gt;update t set b=&quot;ttt&quot; where a=200;RECORD LOCKS space id 26 page no 3 n bits 96 index PRIMARY of table `lock_test`.`t` trx id 2319 **lock_mode X locks rec but not gap waiting**Record lock, heap no 22 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 00000000090c; asc ;; 2: len 7; hex 2b0000014801ca; asc + H ;; 3: len 10; hex 66666620202020202020; asc fff ;; &gt;update t set b=&quot;ttt&quot; where a&lt;=200;RECORD LOCKS space id 26 page no 3 n bits 96 index PRIMARY of table `lock_test`.`t` trx id 2319 **lock_mode X waiting**Record lock, heap no 22 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 00000000090c; asc ;; 2: len 7; hex 2b0000014801ca; asc + H ;; 3: len 10; hex 66666620202020202020; asc fff ;; &gt;select * from t where a&lt;=200 lock in share mode;&gt;insert into t values(20, &quot;aaa&quot;, &quot;aaa&quot;);RECORD LOCKS space id 28 page no 3 n bits 72 index PRIMARY of table `lock_test`.`t` trx id 2345 **lock_mode X locks gap before rec insert intention waiting**Record lock, heap no 3 PHYSICAL RECORD: n_fields 5; compact format; info bits 0 0: len 4; hex 800000c8; asc ;; 1: len 6; hex 000000000928; asc (;; 2: len 7; hex 3d000001340410; asc = 4 ;; 3: len 10; hex 72727220202020202020; asc rrr ;; 4: SQL NULL; 事务模型innodb的事务模型目标是结合多版本控制与传统的两阶段锁的各自的优点。innodb默认情况下，执行行级别的锁定和非锁定的一致性读。这与orcal有点类似。innodb里锁信息的存储是极其节省空间的。 事务隔离级别事务隔离级别的选取是在性能与结果的可靠性、一致性和再现性之间的一种取舍。 innodb提供了SQL:1992标准中所有的隔离级别: READ UNCOMMITED READ COMMITTED REPEATABLE READ SERIALIZABLE innodb默认的隔离级别是REPEATBLE READ。 innodb使用不同的锁策略来支持每一种隔离级别。隔离级别越高，对锁的要求越高。如果对一致性要求比较高，则使用repeatable read隔离级别。若对一致性要求不高，或者为了降低锁的开销，可以使用read committed，甚至是read uncommitted。serializable隔离级别一般不会使用。 下面解释下innodb是怎么支持各个事务隔离级别的。 REPEATABLE READ在同一个事务里的一致性读读取的是第一次读操作产生的快照。这意味着如果你在同一个事务里执行了几次非锁定的select语句，这些select语句是一致的。 对于锁定读(select … for update或者select … lock in share mode)，update和delete操作，锁定依赖于语句是在唯一索引上使用唯一搜索条件还是一种范围类型的搜索条件。 对于在唯一索引上使用唯一搜索条件的，innodb仅锁定发现的行记录。 对于其他的搜索，innodb会锁定被浏览过的索引范围，使用gap locks或者next-key locks来阻止其他会话向索引范围覆盖的间隙内插入。 READ COMMITTED在同一个事务里的每一个一致性读设置和读取最新的快照。 对于锁定读(select … for update和select … lock in share mode)，update和delete操作，innodb只锁定索引记录，没有间隙锁定，因此允许在锁定行的左右自由的插入新的记录。Gap locking is only used for foreign-key constraint checking and duplicate-key checking. 由于gap locks被禁用了，所以当其他会话插入新的记录时，有可能会产生幻读。 如果你使用read committed事务隔离级别，必须使用row-base的二进制日志。 使用read committed有一些其他的影响: 对于update和delete操作，innodb仅在它更新或删除的行上加锁。在mysql执行了where条件匹配后，不匹配的行上的锁会被释放。这减少了死锁发生的可能性，但也会发生。 对于update操作，如果某行已经被锁定，innodb将执行一个伪一致性的读，返回最新被提交的版本，随后mysql使用该行来判断是否匹配update的where条件。如果匹配，mysql再次读取该行，这次innodb将会锁定该行或者是等待锁定该行。 考虑一个例子: 1CREATE TABLE t (a INT NOT NULL, b INT) ENGINE = InnoDB; INSERT INTO t VALUES (1,2),(2,3),(3,2),(4,3),(5,2); COMMIT; 在这个例子里面，表没有索引，因此搜索和索引检查使用隐藏的集群索引来进行锁定。 假设一个客户端执行了如下的update操作: 1SET autocommit = 0; UPDATE t SET b = 5 WHERE b = 3; 另一个客户端随后执行了如下的update操作: 1SET autocommit = 0; UPDATE t SET b = 4 WHERE b = 2; 当innodb执行每个update操作时，首先会在每行上获取一个X锁，随后决定是否更新它。如果innodb不执行修改，则释放锁。否则的话，innodb将持有该锁直到事务结束。 当事务隔离级别是repeatable read时，第一个update操作会获取X锁并且不会释放任何一个锁。 1x-lock(1,2); retain x-lock x-lock(2,3); update(2,3) to (2,5); retain x-lock x-lock(3,2); retain x-lock x-lock(4,3); update(4,3) to (4,5); retain x-lock x-lock(5,2); retain x-lock 当第二个update获取锁时，将会被阻塞(因此第一个更新已经锁定了所有的行)直到第一个update提交或回滚。 1x-lock(1,2); block and wait for first UPDATE to commit or roll back 当事务隔离级别是read committed时，第一个update将会获取锁并且释放那些它不需要修改的行的锁。 1x-lock(1,2); unlock(1,2) x-lock(2,3); update(2,3) to (2,5); retain x-lock x-lock(3,2); unlock(3,2) x-lock(4,3); update(4,3) to (4,5); retain x-lock x-lock(5,2); unlock(5,2) 对于第二个update，innodb执行一个伪一致性读操作，返回每一行最新的被提交的版本到mysql，随后mysql决定哪些行匹配update的where条件。 1x-lock(1,2); update(1,2) to (1,4); retain x-lock x-lock(2,3); unlock(2,3) x-lock(3,2); update(3,2) to (3,4); retain x-lock x-lock(4,3); unlock(4,3) x-lock(5,2); update(5,2) to (5,4); retain x-lock 设置innodb_locks_unsafe_for_binlog等于使用read committed隔离级别。但是一般不要使用该选项。 READ UNCOMMITTED在该事务隔离级别下会导致脏读，即读到其他事务修改但未提交的数据。其他的工作机制与read committed一样。 SERIALIZABLEautocommit, commit和rollback在innodb里，所有的用户活动都发生在事务里。如果autocommit开启的话，每一个sql语句组成一个单独的事务。默认情况下，mysql为每一个新的连接创建一个autocommit开启的会话，因此如果语句执行没有返回错误，mysql将会自动提交该事务。如果语句执行有错误，回滚还是提交依赖于错误的类型。 如果想在autocommit开启的会话里执行多语句事务，需要通过显式的START TRANSACTION或BEGIN语句来开启一个事务，通过COMMIT或ROLLBACK关闭一个事务。 如果autocommit默认是关闭的，若没有显式提交该事务的话，mysql将回滚该事务。 一些语句会隐式结束一个事务，就像在执行那个语句之前执行了COMMIT。 COMMIT意味着在当前事务中做的修改将被持久化和对其他会话可见。ROLLBACK将取消该事务的所有修改。COMMIT和ROLLBACK都会释放掉在当前事务中获取的锁。 使用事务打包DML操作: 在autocommit关闭的会话里，通过显式执行COMMIT或ROLLBACK结束事务。在autocommit开启的事务里，通过显式执行START TRANSACTION或BEGIN开启一个事务，显式执行COMMIT或ROLLBACK结束一个事务。 一致性非锁定读一致性读意味着InnoDB通过多版本给某次查询返回一个数据库在某个时间点的快照。查询将会看到在那个时间点之前提交的事务的修改，不会看到在那个时间点之后提交的或未提交事务的修改。该规则有一个特例: 在同一个事务里查询可以看到之前语句的修改。该特例引发一些反常的事情:如果更新了表中的某些行，查询将会看到被修改行的最新版本，和其他行的旧版本。如果其他事务同时更新了同一张表，反常的事情意味着你看到的表处在一个不存在在数据库中的状态。 如果事务隔离级别是REPEATABLE READ，在同一个事务里的所有一致性读读取的是在该事务中第一次查询所产生的快照。通过提交当前事务然后进行查询能获得一个更新的快照。 在READ COMMITTED事务隔离级别下，在一个事务里的每一个一致性读都会设置和读取最新的快照。 假设你运行在默认的事务隔离级别REPEATABLE READ下，当你触发一致性读的时候，InnoDB会给你的事务设置一个时间点。如果另一个事务在该时间点之后对数据做了一些修改并且提交，这些修改对你来说是不可见的。 注意:数据库状态快照仅应用到事务中的SELECT语句，不会对DML语句产生影响。如果你在一个事务中插入或修改了一些行并且提交，另一个并发事务中的UPDATE或DELETE将会修改这些刚被提交的行，尽管查询不到它们。如果一个事务更新或删除了被不同事务提交的行，这些改变对当前事务变成可见的。 通过将提交事务后进行新的查询来使时间点前进。这叫多版本并发控制。 如果你想看到最新的数据库的状态，使用READ COMMITTED事务隔离级别或锁定读。 在READ COMMITTED事务隔离级别下，在事务里的每一个一致性读将设置和读取最新的快照。在LOCK SHARE IN MODE，一个锁定读被触发: SELECT将会阻塞直到包含最新行的事务结束。 一致性读不能工作在某些DDL语句上: 一致性读不能工作在DROP TABLE上，因为mysql不能使用一个已经被删除的表并且innodb删除了该表。 一致性读不能工作在ALTER TABLE上，因为该语句制作了一个原始表的临时拷贝并且当拷贝完成后会删除原始表。当你在事务中重新触发一致性读的时候，新表里的行是不可见的因为事务的快照被制作的时候这些行是不可见的。在这种情况下，事务返回一个错误: ER_TABLE_DEF_CHANGED 在某些主从语句中，某些读取操作也不会使用一致性读。比如INSERT INTO … SELECT, UPDATE … (SELECT), CREATE TABLE … SELECT。这些SELECT未指定FOR UPDATE或LOCK IN SHARE MODE。 默认情况下，InnoDB使用更强的锁，SELECT更像READ COMMITTED，每个一致性读设置或读取新的快照。 在这些情况下，为了使用一致性读，开启innodb_locks_unsafe_for_binlog选项，设置隔离级别为READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ。在这种情况下，没有锁被设置。 锁定读如果你在一个事务里查询数据随后插入或更新相关的数据，普通的SELECT语句不能提供足够的保护。其它事务可以更新或删除你刚刚查询的行。InnoDB支持两种类型的锁定读，锁定读提供了安全保障。 SELECT … LOCK IN SHARE MODE 在读取的行上设置一个共享锁。其它的会话能读取该行，但是直到该事务提交之后才能修改它们。如果这些行被另一个还未提交的事务修改了，该查询将会阻塞直到事务结束随后使用最新的数据。 SELECT … FOR UPDATE 对于搜索触发的索引记录，在行和任何相关的索引实体上设置一个排它锁。如果你执行了一个UPDATE操作，效果是一样的。如果其它事务执行以下操作，将会被阻塞: 1. 更新这些行 2. SELECT … LOCK IN SHARE MODE 3. 在某些事务隔离级别下的读。 当处理树结构或图结构的数据时，这些语句是非常有用的。 被SELECT … LOCK IN SHARE MODE或SELECT … FOR UPDATE设置的锁在事务提交或回滚之后被释放。 InnoDB里被不同SQL语句设置的锁锁定读、UPDATE、DELETE通常会在浏览的记录上设置record locks。 如果使用辅助索引且索引记录锁是排它的，InnoDB也会获取相应的集群索引记录然后锁定它们。 如果执行全表扫描，每行都会被锁定。 SELECT … LOCK IN SHARE MODE和SELECT … FOR UPDATE只在满足条件的结果上加锁。 InnoDB设置如下不同的锁: SELECT … FROM是一个一致性读，获取数据库的快照，没有锁除非事务隔离级别是SERIALIZABLE。 SELECT … FROM … LOCK IN SHARE MODE在搜索触及的所有索引记录上设置一个共享的next-key locks。然而，对于一个使用唯一索引搜索唯一行的语句，一个record locks被设置 SELECT … FROM … FOR UPDATE在搜索触及的所有索引记录上设置一个排它的next-key locks。然而，对于一个使用唯一索引搜索唯一行的语句，一个record locks被设置 UPDATE … WHERE …在搜索触及的所有索引记录上设置一个排它的next-key locks。然而，对于一个使用唯一索引搜索唯一行的语句，一个record locks被设置 当UPDATE修改一个集群索引记录时，隐式的锁会被设置在辅助索引上。The UPDATE operation also takes shared locks on affected secondary index records when performing duplicate check scans prior to inserting new secondary index records, and when inserting new secondary index records. DELETE FROM … WHERE …在搜索触及的所有索引记录上设置一个排它的next-key locks。然而，对于一个使用唯一索引搜索唯一行的语句，一个record locks被设置 INSERT在被插入的记录上设置一个排它锁。该锁是record locks，不会阻止其他会话在被插入的行之前进行插入 INSERT … ON DUPLICATE KEY UPDATE与简单的INSERT不同，当重复键错误发生时，会获得一个排它锁而不是共享锁 如果在唯一索引上没有冲突的话REPLACE和INSERT一样。否则的话，一个排它的next-key locks将被设置 INSERT INTO T SELECT … FROM S WHERE … AUTO_INCREMENT FOREIGN KEY LOCK TABLES 幻读","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"理论篇-python之运算符重载","date":"2017-05-25T10:18:59.000Z","path":"2017/05/25/理论篇-python之运算符重载/","text":"可重载的运算符: 方法 重载 调用 __new__ 创建 在__init__之前创建对象 __init__ 构造函数 对象建立: x = Class(args) __del__ 析构函数 x对象收回__call__ 函数调用 x(*args, **kwargs) __delete__ __dict__ 属性字典，实例调用时只返回实例属性 类调用时只返回类属性 __slots__ __class__ 实例所属的类的链接 __bases__ 实例超类引用的元组 __getattr__ 获得属性(针对未定义的属性) 点号运算 __setattr__ 属性赋值运算 __delattr__ 属性删除运算 __getattribute__ 获得属性(针对所有属性) __and__ 与运算 1 and 2 __or__ 或运算 1 or 2 __str__ 适合人读取的信息， 当没有实现时，返回repr的内容 pirnt(x) repr(x) str(x) __repr__ 适合机器读取的信息 __getiiem__ 索引运算 x[key], x[i:j], 没iter时的for循环和其他迭代器 __setitem__ 索引赋值语句 x[key]=value x[i:j]=sequence __delitem__ 索引和分片删除 del x[key], del x[i:j] __len__ 长度 len(x), 如果没有__bool__, 真值测试 __bool__ 布尔测试 bool(x), 真测试，在2.6中是__nonzero__ __lt__,__gt__ __le__,__ge__ __eq__,__ne__ 特定的比较 xy, x&lt;=y, x&gt;=y, x==y, x!=y 在2.6中只有__cmp__ __radd__ 右侧加法 other + x __iadd__ 实地加法 x + y __iter__, __next__ 迭代环境 I=iter(x), next(I); for loops __contains__ 成员关系测试 item in x __index__ 整数值 __enter__, __exit__ 环境管理器 with obj as var: __get__, __set__ 描述符属性 x.attr, x.attr=value, del x.attr __index__ 返回某一个实例的整数值 hex(x), bin(x), oct(x) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465__repr__ # repr 适合开发人员阅读的信息__str__ # print str 适合用户阅读的信息本质上，__str__重载了__repr__，若没有__str__，则默认全部调用__repr____add____radd____iadd__class Commuter: def __init__(self, val): self.val = val def __add__(self, other): print(&quot;__add__&quot;, self.val, other) return self.val + other def __radd__(self, other): print(&quot;__radd__&quot;, self.val, other) return other + self.val def __iadd__(self, other): print(&quot;__iadd__&quot;, self.val, other) self.val += other return self x = Commuter(88)y = Commuter(99) print(x+1) # __add__print(1+x) # __radd__print(x+y) # __add__ __radd__x += 1 # __iadd____call__ # 使一个实例可被调用__lt__ # &gt;__le__ # &gt;=__gt__ # &lt;__ge__ # =&lt;__eq__ # ==__ne__ # !=__cmp__ # 返回一个整数值 大于0 小于0 或等于0 2.x中可用 3.x中已删除 优先使用以上六种运算符，若没有，再使用本运算符class C: data = &quot;spam&quot; def __gt__(self, other): return self.data &gt; other def __lt__(self, other): return self.data &lt; other def __cmp__(self, other): return cmp(self.data, other) x = C()print(c &gt; &quot;ham&quot;)print(c &lt; &quot;ham&quot;)__bool__ __len__ # 在boolean环境下，首先尝试__bool__，若没定义，则尝试__len____del__ # 析构函数","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-学习","date":"2017-05-24T02:01:38.000Z","path":"2017/05/24/理论篇-学习/","text":"学习的目的是应用，不是为了学习而学习。 从书本上学知识，有三个过程。 第一个过程，我能理解了 第二个过程，我能消化了 第三个过程，我能应用了 如果只停留在第一个过程，那么学到的知识很快也就会忘记，并不能给自己带来能力上的提升，反而会让自己越来越失望，觉得学的东西怎么都忘记了呢？","tags":[{"name":"xxx","slug":"xxx","permalink":"http://yoursite.com/tags/xxx/"}]},{"title":"理论篇-python之属性管理","date":"2017-05-23T08:38:28.000Z","path":"2017/05/23/理论篇-python之属性管理/","text":"python提供了两大类属性管理的方法，分别是:1. 基于运算符重载 2. 基于descriptor协议 基于运算符重载的属性管理方法123456__getattr__ # 拦截所有未定义属性的访问__getattribute__ # 拦截所有属性的访问(只能在新式类中使用)__setattr__ # 拦截所有属性的赋值__delattr__ # 拦截所有属性的删除getattr(object, name[, default]) -&gt; value # object.name 防止循环调用的方法: 1. 使用属性字典 2. 调用父类的方法 3. 调用其他对象的方法 __getattr__和__getattribute__一般用在实现委托器模式的代码中。 1234567891011121314151617181920212223242526272829303132class Person: def __init__(self, name): self.name = name def __getattr__(self, name): print(&quot;__getattr__&quot;) return &quot;undefined&quot; def __setattr__(self, name, value): print(&quot;__setattr__&quot;) self.__dict__[name] = value # important!!! def __delattr__(self, name): print(&quot;__delattr__&quot;) del self.name class Person(object): def __init__(self, name): self.name = name def __getattribute__(self, name): print(&quot;__getattribute__&quot;) return object.__getattribute__(self, name) def __setattr__(self, name, value): object.__setattr__(self, name, value) person = Person(&quot;xxx&quot;)print(person.name)person.age = 20print(person.age)print(person.sex) 基于descriptor协议的属性管理方法基于descriptor的属性管理方法必须在新式类中使用。 1234567891011121314151617181920212223242526class Name(object): def __get__(self, instance, owner): print(&quot;__get__&quot;) return instance._name def __set__(self, instance, name): print(&quot;__set__&quot;) instance._name = name def __delete__(self): print(&quot;__delete__&quot;) del self._name class Person(object): def __init__(self, name): self._name = name name = Name() person = Person(&quot;xxx&quot;)print(person.name)person.name = &quot;yyy&quot;print(person.name)del person.nameperson.age = 10print(person.age) 基于property的属性管理方法property是descriptor协议的一种特例，基于property的属性管理方法必须在新式类中使用。 12345678910111213141516171819202122232425class Person(object): def __init__(self, name): self._name = name def getName(self): print(&quot;getName&quot;) return self._name def setName(self, name): print(&quot;setName&quot;) self._name = name def delName(self): print(&quot;delName&quot;) del self._name name = property(getName, setName, delName, None) person = Person(&quot;xxx&quot;)print(person.name)person.name = &quot;yyy&quot;print(person.name)del person.nameperson.age = 10print(person.age) 使用装饰器的property 123456789101112131415161718192021222324class Person(object): def __init__(self, name): self._name = name @property def name(self): print(&quot;getName&quot;) return self._name @name.setter def name(self, name): print(&quot;setName&quot;) self._name = name @name.deleter def name(self): print(&quot;delName&quot;) del self._name person = Person(&quot;xxx&quot;)print(person.name)person.name = &quot;yyy&quot;print(person.name)del person.nameperson.age = 10print(person.age) 进阶篇__getattr__和__getattribute__需注意的点正常的函数调用，会按照之前的规则拦截，但是对于重载函数的调用，拦截规则如下: 在3.x里，对于重载函数的隐式调用，__getattr__和__getattribute__不会拦截，显式调用会拦截 在2.6里，对于重载函数，无论显式调用还是隐式调用，若没有在类中定义，则__getattr__会拦截 在2.6里，对于重载函数的隐式调用，__getattribute__不会拦截，显式调用会拦截 2.6 类别 隐式调用 显式调用 __getattr__ 若没定义则拦截 若没定义则拦截 __getattribute__ 不拦截 拦截 3.0 类别 隐式调用 显式调用 __getattr__ 不拦截 若没定义则拦截 __getattribute__ 不拦截 拦截 property与descriptor的关系既然property是descriptor的一种特例，那么它们之间是什么关系？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081class Property(object): def __init__(self, fget=None, fset=None, fdel=None, fdoc=None): self.fget = fget self.fset = fset self.fdel = fdel self.__doc__ = fdoc def __get__(self, instance, instanceType=None): if instance is None: return self if (self.fget is None): raise AttributeError(&quot;can&apos;t get attribute&quot;) return self.fget(instance) def __set__(self, instance, value): if (self.fset is None): raise AttributeError(&quot;can&apos;t set attribute&quot;) self.fset(instance, value) def __delete__(self, instance): if (self.fdel is None): raise AttributeError(&quot;can&apos;t delete attribute&quot;) self.fdel(instance) def setter(self, fset): self.fset = fset return self def deleter(self, fdel): self.fdel = fdel return selfclass Person(object): def __init__(self, name): self._name = name def getName(self): print(&quot;getName&quot;) return self._name def setName(self, name): print(&quot;setName&quot;) self._name = name def delName(self): print(&quot;delName&quot;) del self._name name = Property(getName, setName, delName, None) person = Person(&quot;xxx&quot;)print(person.name)person.name = &quot;yyy&quot;print(person.name)del person.nameperson.age = 10print(person.age)class NewPerson(object): def __init__(self, name): self._name = name @Property def name(self): print(&quot;getName&quot;) return self._name @name.setter def name(self, name): print(&quot;setName&quot;) self._name = name @name.deleter def name(self): print(&quot;delName&quot;) del self._name person = NewPerson(&quot;xxx&quot;)print(person.name)person.name = &quot;yyy&quot;print(person.name)del person.nameperson.age = 10print(person.age) __slots__也是基于descriptor协议实现的。 三者之间的关系 __getattr__和__getattribute__一般用在实现委托器模式的代码中。一般用来管理内嵌对象的属性访问 property和descriptor一般用来管理某个类的特定属性。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-lua","date":"2017-05-21T12:40:38.000Z","path":"2017/05/21/实战篇-lua/","text":"安装","tags":[{"name":"lua","slug":"lua","permalink":"http://yoursite.com/tags/lua/"}]},{"title":"理论篇-lua","date":"2017-05-21T12:30:28.000Z","path":"2017/05/21/理论篇-lua/","text":"language A chunk is simply a sequence of commands(or statements) lua里面的语句分隔符没有实际意义，只是让人看上去比较清楚。 1dofile(&quot;xxx.lua&quot;) # 执行一个lua文件 lua里面的变量名可以除数字开头的字母、数字、下划线的任意组合，但是以下划线开头后跟大写字母的变量是lua语言保留的。lua是大小写敏感的。以下关键字也是lua语言保留的。 12and break do else elseif end false goto for function if inlocal nil not or repeat return then true until while 注释 1234567--xxx # 行注释--[[xxx]] # 块注释# 小技巧--[[ # 当取消该块注释时只需在前面加-xxx--]] 全局变量 lua里面的全局变量不需要显式声明。如果没有声明就使用，将得到nil。 当将一个变量赋值为nil时，意思是告诉lua编译器回收这个变量占用的内存。 解释器 1234567891011121314#!/usr/bin/env lua#!/usr/local/bin/lua # 指定lua解释器bogon:lua fenghui2013$ lua -hlua: unrecognized option &apos;-h&apos;usage: lua [options] [script [args]]Available options are: -e stat execute string &apos;stat&apos; -i enter interactive mode after executing &apos;script&apos; -l name require library &apos;name&apos; -v show version information -E ignore environment variables -- stop handling options - stop handling options and execute stdin 解释器在执行之前会寻找LUA_INIT_5_2或LUA_INIT全局变量，若内容是@filename，则执行该文件，否则执行全局变量的内容。","tags":[{"name":"lua","slug":"lua","permalink":"http://yoursite.com/tags/lua/"}]},{"title":"实战篇-linux之优化","date":"2017-05-21T07:18:47.000Z","path":"2017/05/21/实战篇-linux之优化/","text":"12# 对tcp各个状态的连接进行统计netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos; 12# somaxconnecho 2048 &gt; /proc/sys/net/core/somaxconn # 临时修改最大连接数 12345678910111213141516171819202122232425262728# /etc/sysctl.conf# corenet.core.somaxconn = 2048 # 最大连接数 listen的backlog# tcp# 开启syn cookies。当出现syn等待队列溢出时，启用cookies来处理，可防范少量syn攻击，默认为0net.ipv4.tcp_syncookies=1# 开启重用。允许将TIME-WAIT sockets重新用于新的连接，默认为0net.ipv4.tcp_tw_reuse=1# 开启快速回收，默认为0net.ipv4.tcp_tw_recycle=1# 修改系统默认的timeoutnet.ipv4.tcp_fin_timeout=30# 建议在流量非常大的服务器上开启# tcp发送keepalive消息的频率，默认为2小时net.ipv4.tcp_keepalive_time=1200# 可用的建立连接的端口范围 默认为32768~61000net.ipv4.ip_local_port_range=10000 65000# syn队列的长度，默认为1024net.ipv4.tcp_max_syn_backlog=8192# time wait的最大数量，默认为18000net.ipv4.tcp_max_tw_buckets=6000#net.core.netdev_max_backlog = 32768sysctl -p # 使配置生效","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"实战篇-redis","date":"2017-05-21T05:44:46.000Z","path":"2017/05/21/实战篇-redis/","text":"安装官方传送门 12345wget http://download.redis.io/releases/redis-3.2.9.tar.gztar xzf redis-3.2.9.tar.gzcd redis-3.2.9makemake install 123456redis-server path/to/redis.conf # 服务启动程序redis-sentinel path/to/sentinel.conf # 启动一个哨兵节点redis-cli # 客户端程序 -c # 集群模式redis-benchmark # 性能测试工具redis-trib.rb # ruby编写的集群管理工具 redis.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768bind 127.0.0.1 # 监听某些接口protected-mode yes # 如果想让其他主机访问，则设为noport 6379 # 监听端口tcp-backlog 511 # # 配置redis可用的最大内存数及对应的内存回收算法maxmemory # 可占用的最大内存maxmemory-policy # 内存回收算法 volatile-lru allkeys-lru# 服务器中数据库的数量databases = 16notify-keyspace-events &quot;K$&quot; # 发布订阅配置######## SNAPSHOTTING ######### 异步RDB持久化配置 格式:save &lt;seconds&gt; &lt;changes&gt;save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yes # RDB后台保存失败后拒绝所有的写操作rdbcompression yes # 启用压缩功能# AOF持久化配置appendonly yes # 开启AOF持久化功能appendfilename &quot;appendonly.aof&quot; # 持久化文件名# no: don&apos;t fsync, just let the OS flush the data when it wants. Faster.# always: fsync after every write to the append only log. Slow, Safest.# everysec: fsync only one time every second. Compromise.appendfsync always # 持久化模式######## SECURITY ########requirepass password # 开启身份验证rename-command CONFIG &quot;&quot; # 重命名命令的名字 ######## REPLICATION ########slaveof &lt;masterip&gt; &lt;masterport&gt; # 配置该从节点的主节点masterauth &lt;master-password&gt; # 从节点向主节点发起验证slave-serve-stale-data yes # slave-read-only yes # 从节点只读# 当使用diskless同步策略时，在转换开始后，新到达的从节点将会被排队并等待下一次新的转换，为了提高传输的效率(同时向多个从节点传输)，主节点在开始传输之前会等待一段时间，期望获得更多的从节点repl-diskless-sync no # 主从同步的RDB文件是否写到磁盘上repl-diskless-sync-delay 5 # 主节点开始传输之前等待的时间(秒)# repl-ping-slave-period 10# repl-timeout 60repl-disable-tcp-nodelay no # tcpnodelay 40毫秒延迟repl-backlog-size 1mb # 主从部分同步中积压缓冲区的大小# repl-backlog-ttl 3600 # 最后一个从节点断开后多长时间后积压缓冲区被释放slave-priority 100 # 从节点优先级 选举为主节点时使用min-slaves-to-write 3 # 可用的slave最小数量min-slaves-max-lag 10 # slave最大的交互时间间隔# slave-announce-ip 5.5.5.5 # slave-announce-port 1234 # 防止端口转发和NAT######## REDIS CLUSER ######### cluster-enabled yes # 是否开启集群模式# cluster-node-timeout 15000 # 节点超时时间######## ADVANCED CONFIG ########client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60 # 客户端输出缓冲区的限制hz 10 # serverCron函数 每秒执行次数 sentinel.conf 123456789101112131415# bind 127.0.0.1 192.168.1.1# protected-mode no # 默认设置下只能对内访问，通过以上两个选项可设置port 26379 # 端口# sentinel announce-ip &lt;ip&gt;# sentinel announce-port &lt;port&gt; # 防止端口转发和NATdir /tmp # 工作目录sentinel monitor mymaster 127.0.0.1 6379 2 # 客观下线的判断标准# sentinel auth-pass &lt;master-name&gt; &lt;password&gt; # 验证sentinel down-after-milliseconds mymaster 30000 # 主观下线的判断标准sentinel parallel-syncs mymaster 1 # sentinel failover-timeout mymaster 180000 # # sentinel notification-script mymaster /var/redis/notify.sh# sentinel client-reconfig-script mymaster /var/redis/reconfig.sh # 自动化脚本配置","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"理论篇-数据结构之跳跃表","date":"2017-05-20T12:48:46.000Z","path":"2017/05/20/理论篇-数据结构之跳跃表/","text":"跳跃表 跳跃表是一种有序链表，其中的每个节点包含数量可变的链接，并且节点中的第i个链接单独实现链表，它跳过少于i个链接的节点。 跳跃表支持平均O(lgN)，最坏O(N)的时间复杂度。大部分情况下，跳跃表的性能可以和平衡树相媲美，又因为跳跃表的实现比平衡树简单，所以很多程序使用跳跃表来代替平衡树。 技术要点插入节点时，首要任务是确定该节点有多少个链接。确定方法: 每$t^{j}$个节点中一个至少有j+1个链接。 跳跃表层数的期望值约为$log^{N}_{t}$。 实现时可以使用以1/$t^{j}$为概率返回j+1的函数来随机化节点的层数。","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"理论篇-redis之各种命令","date":"2017-05-20T10:55:48.000Z","path":"2017/05/20/理论篇-redis之各种命令/","text":"命令redis总共200个命令，其中字符串对象相关命令24个、列表对象相关命令17个、哈希对象相关命令15个、集合对象相关命令15个、有序集合对象相关命令21个。 字符串对象相关命令 命令 解释 时间复杂度 特别说明 SET key value [EX seconds] [PX milliseconds] [NX &#124; XX] O(1) 覆写之前的值，若有过期时间，则删除 SETEX key seconds value O(1) 原子操作 SETNX key value O(1) GET key O(1) APPEND key value O(1) STRLEN key 返回key指定的字符串的长度 SETRANGE key offset value 覆写字符串的一部分 O(1) GETRANGE key start end 获取字符串的一部分 O(N) INC key O(1) INCBY key increment O(1) INCBYFLOAT key increment O(1) DECR key O(1) DECRBY key decrement O(1) Pattern: Rate limiter Pattern: Time series Design pattern: Locking with SETNX 列表对象相关命令 命令 解释 时间复杂度 特别说明 BLPOP key [key …] timeout LPOP的阻塞版本 O(1) BRPOP key [key …] timeout RPOP的阻塞版本 O(1) BRPOPLPUSH source destination RPOPLPUSH的阻塞版本 O(1) LINDEX key index 返回指定索引处的值 O(N) 表头从0开始 表尾从-1开始 LINSERT key BEFORE &#124; AFTER pivot value 在列表某一项之前或之后添加元素 O(N) LLEN key 获取一个key指定的列表的长度 O(1) LPOP 移除并返回列表的第一个元素 O(1) LPUSH key value [value …] 插入一个或多个值到表头 O(1) 若key指定的列表不存在，则创建一个空的列表 LPUSHX key value 插入一个值到表头 O(1) 若key指定的列表不存在，则什么也不做 LRANGE key start stop 获取key指定的列表里的指定范围的元素 LREM key count value 删除列表中的元素 O(N) count&gt;0 从表开始 count&lt;0从表尾开始 count=0 删除所有 LSET key index value 设置索引处的值 LTRIM key start stop 截断列表 O(N) RPOP 移除并返回列表的最后一个元素 O(1) RPOPLPUSH source destination 移除并返回source指定的列表的最后一个节点并且将该节点放入destination指定的列表的表头 O(1) 原子操作 RPUSH key value [value …] 插入一个或多个值到表尾 O(1) 若key指定的列表不存在，则创建一个空的列表 RPUSHX key value 追加一个值到列表 O(1) 若key指定的列表不存在，则什么也不做 Pattern: Reliable queue 哈希对象相关命令 命令 解释 时间复杂度 特别说明 HDEL key field [field …] 删除指定的field O(N) HEXISTS key field 检查field是否存在 O(1) HGET key field 获取值 O(1) HGETALL key 获取key指定的哈希表中所有的field和value O(N) HINCBY key field increment 递增值 O(1) 若没有则创建 HINCBYFLOAT key field increment 递增值 O(1) 若没有则创建 HKEYS key 返回哈希对象中的所有键 O(N) HLEN key 获取key指定的哈希表中field的数量 O(1) HMGET key field [field …] 返回多个指定的field的值 O(N) HMSET key field value [field value …] 设置多个指定的键值对 O(N) HSCAN key cursor [MATCH pattern] [COUNT count] HSET key field value 存储键值对 O(1) HSETNX key field value 设置键值对 O(1) 若存在则什么也不做 HSTRLEN key field 返回field指定的值的长度 O(1) HVALS key 获取哈希对象中的所有值 O(N) 集合对象相关命令 命令 解释 时间复杂度 特别说明 SADD key member [member …] 增加多个成员到集合中 O(1) SCARD key 返回集合中的元素数量 O(1) SDIFF key [key …] 返回第一个key指定的集合里有的而其他key指定的集合里没有的所有元素 O(N) 差集 SDIFFSTORE destination key [key …] 将第一个key指定的集合里有的而其他key指定的集合里没有的所有元素存入destination指定的集合 O(N) SINTER key [key …] 返回所有key指定的集合的交集 O(N*M) 交集 SINTERSTORE destination key [key …] 将所有key指定的集合的交集存到destination集合 O(N*M) SISMEMBER key member 检查member是否是在key指定的集合里 O(1) SMEMBERS key 返回所有成员 O(N) SMOVE source destination member 从source指定的集合移动member到destination指定的集合 O(1) SPOP key [count] 移除并返回一个或多个随机元素 O(1) SRANDMEMBER key [count] O(1) 当count&gt;0时返回count个不同的元素，当count&lt;0时，可以返回多个相同的元素 SREM key member [member …] O(N) SSCAN key cursor [MATCH pattern] [COUNT count] SUNION key [key …] 返回所有key指定的所有不同的元素 O(N) 并集 SUNIONSTORE destination key [key …] 将所有key指定的所有不同的元素添加到destination O(N) 有序集合对象相关命令 命令 解释 时间复杂度 特别说明 ZADD key [NX &#124; XX] [CH] [INCR] score member [score member …] 向key指定的有序集合中添加带有分值的字段 O(lg(N)) ZCARD key 获取key指定的有序集合里的元素数量 O(1) ZCOUNT key min max 返回分值在min和max之间的元素的数量 O(lgN) ZINCBY key increment member 增加指定成员的分值 O(lnN) ZINTERSCORE destination numkeys key [key …][WEIGHTS weight [weight …]][AGGREGATE SUM &#124; MIN &#124; MAX] 交集 O(N*K)+O(M*lgM) N是最小的有序集合的数量 K是有序集合的个数 M是结果有序集合的数量 ZLEXCOUNT key min max 返回值在min到max之间的元素的数量 O(lgN) ZRANGE key start stop [WITHSCORES] 获取key指定的有序集合里的指定范围的元素 O(lg(N)+M) ZRANGEBYLEX key min max [LIMIT offset count] 返回值在min和max之间的元素 O(lg(N)+M) 元素的分值必须相等 ZRANGEBYSTORE key min max [WITHSCORES] [LIMIT offset count] 返回分值在min和max之间的元素 O(lg(N)+M) ZRANK key member 返回元素的排名 O(lgN) ZREM key member [member …] 删除指定的元素 O(M*lgN) N是有序集合元素的数量 M是要删除的元素的数量 ZREMRANGEBYLEX key min max 按照值删除指定范围的元素 O(lg(N)+M) ZREMRANGEBYRANK key start stop 按照排名删除指定范围的元素 O(lg(N)+M) N是有序集合元素的数量 M是要删除的元素的数量 ZREMRANGEBYSCORE key min max 按照分值删除指定范围的元素 O(lg(N)+M) ZREVRANGE key start stop [WITHSCORES] 以相反的顺序返回指定范围的元素 O(lg(N)+M) N是有序集合元素的数量 M是要返回的元素的数量 ZREVRANGEBYLEX key max min [LIMIT offset count] 按照值以相反的顺序返回指定范围的元素 O(lg(N)+M) N有序集合元素的数量 M是返回的元素的数量 所有元素分值必须相等 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] 按照分值以相反的顺序返回指定范围的元素 O(lg(N)+M) ZREVRANK key member 以相反的顺序返回元素的排名 O(lgN) ZSCAN key cursor [MATCH pattern] [COUNT count] ZSCORE key member 返回元素的分值 O(1) ZUNIONSTORE destination numkeys key [key …][WEIGHTS weight [weight …]][AGGREGATE SUM &#124; MIN &#124; MAX] 并集 O(N)+O(MlgM) N是所有有序集合的元素之和 M是结果有序集合的元素总数 超时时间相关命令 命令 解释 时间复杂度 特别说明 EXPIRE key seconds 设置key的超时时间 O(1) 对key指定的值得修改操作不会影响到超时时间 PEXPIRE key milliseconds 设置key的超时时间 O(1) 毫秒单位 EXPIREAT key timestamp 设置key的超时时间 O(1) 设置秒级时间戳 PEXPIREAT key milliseconds-timestamp 设置key的超时时间 O(1) 设置毫秒级时间戳 PERSISIT key 删除key上的超时时间 O(1) TTL key 返回有超时时间的关键字的剩余时间 O(1) 单位为秒 PTTL key 返回有超时时间的关键字的剩余时间 O(1) 单位为毫秒 TIME 返回服务器当前时间 O(1) 秒级时间戳+毫秒数 数据库相关命令 命令 解释 时间复杂度 特别说明 SELECT index 选择某个数据库 默认从0开始 DEL key [key …] 删除指定的键 O(N) RANDOMKEY 从当前数据库中随机选择一个key O(1) EXISTS key [key …] 判断是否存在关键字 O(1) DBSIZE 返回当前数据库关键字的数量 FLUSHALL [ASYNC] 清空所有数据库 O(N) FLUSHDB [ASYNC] 清空当前数据库 O(N) 持久化命令 命令 解释 时间复杂度 特别说明 SAVE 以RDB文件的形式同步持久化数据库 该命令会阻塞所有其他客户端的操作 BGSAVE 以RDB文件的形式异步持久化数据库 LASTSAVE 返回上次数据库执行保存的时间戳 客户端可以通过该命令来判断BGSAVE是否执行成功 BGREWRITEAOF 启动一个AOF重写进程 客户端相关的命令 命令 解释 时间复杂度 特别说明 CLIENT KILL [ip:port] [ID client-id] [TYPE noral &#124; master &#124; slave &#124; pubsub] [ADDR ip:port] [SKIPME yes/no] 关闭客户端连接 CLIENT LIST 返回客户端的信息 O(N) CLIENT PAUSE timeout 暂定所有的客户端(内部交互客户端除外) 单位为毫秒 CLIENT REPLY ON &#124; OFF &#124; SKIP 服务器是否响应客户端 CLIENT SETNAME 设置当前连接的名字 O(1) CLIENT GETNAME 返回当前连接的名字 O(1) 事务相关命令 命令 解释 时间复杂度 特别说明 DISCARD EXEC 开始执行命令 MULTI 事务的开始 UNWATCH WATCH 事务开始的另一种方式 主从复制相关命令 命令 解释 时间复杂度 特别说明 SLAVEOF host port 使该服务器成为host:port服务器的从节点 内部相关命令 命令 解释 时间复杂度 特别说明 SYNC 从节点从主节点同步数据 PSYNC runid offset 从节点从主节点同步数据 集群相关命令 命令 解释 时间复杂度 特别说明 CLUSTER ADDSLOTS CLUSTER COUNT-FAILURE-REPORTS node-id CLUSTER COUNTKEYSINSLOT slot CLUSTER DELSLOTS slot [slot …] CLUSTER FAILOVER [FORCE &#124; TAKEOVER] CLUSTER FORGET node-id CLUSTER GETKEYSINSLOT slot count 返回count个指定槽里的关键字的数量 CLUSTER INFO CLUSTER KEYSLOT key 返回key对应的槽值 O(N) CLUSTER MEET ip port 将其它节点加入到集群中 O(1) CLUSTER NODES CLUSTER REPLICATE node-id 设置从节点 CLUSTER RESET [HARD &#124; SOFT] CLUSTER SAVECONFIG CLUSTER SET-CONFIG-EPOCH config-epoch CLUSTER SETSLOT slot IMPORTING &#124; MIGRATING &#124; STABLE &#124; NODE [node-id] 用于重新分片 CLUSTER SLAVES node-id CLUSTER SLOTS MIGRATE host port key &#124; “” destination-db timeout [COPY] [REPLACE] [KEYS key [key …]] 原子操作 将key从一个数据库转移到另一个数据库 O(N) 在源数据库上执行DUMP+DEL 在目标数据库上执行RESTORE 性能优化相关 命令 解释 时间复杂度 特别说明 INFO [section] 返回服务器的信息 发布订阅 命令 解释 时间复杂度 特别说明 PSUBSCRIBE pattern [pattern …] 使客户端订阅一个或多个模式 O(N) PUBLISH channel message 在某个频道上发布一条消息 O(N+M) PUBSUB 自省命令，监测发布订阅系统的状态 PUNSUBSCRIBE [pattern [pattern …]] 使客户端退订一个或多个模式 O(N+M) SUBSCRIBE channel [channel …] 使客户端订阅一个或多个频道 O(N) UNSUBSCRIBE [channel [channel …]] 使客户端退订一个或多个频道 O(N) 其它命令 命令 解释 时间复杂度 特别说明 DUMP key 序列化关键字指定的值 RESTORE key ttl serialized-value [REPLACE] 使用序列化的值创建key SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern]] [ASC &#124; DESC] [ALPHA] [STORE destination] 排序 TYPE key 返回key指定的值的类型，可能是string, list, set, zset, hash O(1) OBJECT sumcommand [arguments [arguments …]] 查看与key相关的redis对象的内部 O(1)","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"源码篇-innodb之数据页结构解析","date":"2017-05-19T03:22:53.000Z","path":"2017/05/19/源码篇-innodb之数据页结构解析/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748数据页开始的地方:16KB*3=0xc000file header(38):47 71 e9 33 # 该页的checksum值00 00 00 03 # 该页的偏移量，从0开始ff ff ff ff # 前一页，因为只有当前页所有为0xffffffffff ff ff ff # 后一页，因为只有当前页所以为0xffffffff00 00 00 00 00 01 d7 42 # 该页的LSN45 bf # 页类型，该页为数据页00 00 00 00 00 00 00 00 #00 00 00 05 # 表空间的space idindex header(36):00 02 # page directory 占用2个槽，每个槽占用2个字节01 9c # 空闲空间开始位置的偏移量 0xc000+0x019c=0xc19c80 09 # 初始值为0x8002，0x8009-0x8002=0x0007 代表共有7条记录00 00 # 删除的记录数00 00 # 删除记录的字节数总和01 79 # 最后插入位置的偏移量00 02 # 插入方向00 06 # 一个方向连续插入的记录数00 07 # 该页的行记录数00 00 00 00 00 00 00 0000 00 # 该页在B+树中的层数00 00 00 00 00 00 00 17 # 索引idFSEG header(20):00 00 00 05 00 00 00 02 00 f200 00 00 05 00 00 00 02 00 32system records:0xc05e~0xc07701 00 02 00 1e # record header69 6e 66 69 6d 75 6d 00 # infimum 0xc063+0x001e=0xc081 第一条记录开始的位置08 00 0b 00 00 # record header73 75 70 72 65 6d 75 6d # supremumuser records:page directory:(逆序存放)00 70 00 630x0063是第一条记录的相对位置0x0070是最后一条记录的相对位置file trailer(8):35 bb de bd # checksum值，该值通过checksum函数和file header部分的checksum值进行比较00 01 d7 42 # 注意到该值与file header页中的后lsn后四位相等","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"源码篇-innodb之行记录格式解析","date":"2017-05-18T09:22:12.000Z","path":"2017/05/18/源码篇-innodb之行记录格式解析/","text":"故事背景最近在学mysql，看的是《Mysql技术内幕: InnoDB存储引擎》，在读到行记录格式时，发现一个让自己无法理解的事情。于是就揪出了innodb的源码仔细研究一番，最后发现书中的语言确实会将人带入一种认识的误区，也可能是个人理解能力有问题，不说这个了，我们直接说问题。 测试用例1234567891011121314create table mytest ( t1 varchar(10), t2 varchar(10), t3 char(10), t4 varchar(10)) engine=innodb charset=latin1 row_format=compact;insert into mytest values(&quot;a&quot;, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;);insert into mytest values(NULL, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;);insert into mytest values(&quot;a&quot;, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;);insert into mytest values(NULL, NULL, &quot;bb&quot;, &quot;ccc&quot;);insert into mytest values(&quot;a&quot;, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;);insert into mytest values(NULL, &quot;bb&quot;, NULL, NULL);insert into mytest values(&quot;a&quot;, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;); 物理文件中的内容如下: 1234567891011121314151617181920212223242526270000bff0 00 00 00 00 00 00 00 00 95 17 2a 17 00 01 d3 70 |..........*....p|0000c000 47 71 e9 33 00 00 00 03 ff ff ff ff ff ff ff ff |Gq.3............|0000c010 00 00 00 00 00 01 d7 42 45 bf 00 00 00 00 00 00 |.......BE.......|0000c020 00 00 00 00 00 05 00 02 01 9c 80 09 00 00 00 00 |................|0000c030 01 79 00 02 00 06 00 07 00 00 00 00 00 00 00 00 |.y..............|0000c040 00 00 00 00 00 00 00 00 00 17 00 00 00 05 00 00 |................|0000c050 00 02 00 f2 00 00 00 05 00 00 00 02 00 32 01 00 |.............2..|0000c060 02 00 1e 69 6e 66 69 6d 75 6d 00 08 00 0b 00 00 |...infimum......|0000c070 73 75 70 72 65 6d 75 6d 03 02 01 00 00 00 10 00 |supremum........|0000c080 2b 00 00 00 00 08 05 00 00 00 00 11 0c 80 00 00 |+...............|0000c090 00 2d 01 10 61 62 62 62 62 20 20 20 20 20 20 20 |.-..abbbb |0000c0a0 20 63 63 63 03 02 01 00 00 18 00 2b 00 00 00 00 | ccc.......+....|0000c0b0 08 06 00 00 00 00 11 0d 80 00 00 00 2d 01 10 62 |............-..b|0000c0c0 62 62 62 20 20 20 20 20 20 20 20 63 63 63 03 02 |bbb ccc..|0000c0d0 01 00 00 00 20 00 2a 00 00 00 00 08 07 00 00 00 |.... .*.........|0000c0e0 00 11 0e 80 00 00 00 2d 01 10 61 62 62 62 62 20 |.......-..abbbb |0000c0f0 20 20 20 20 20 20 20 63 63 63 03 03 00 00 28 00 | ccc....(.|0000c100 29 00 00 00 00 08 08 00 00 00 00 11 0f 80 00 00 |)...............|0000c110 00 2d 01 10 62 62 20 20 20 20 20 20 20 20 63 63 |.-..bb cc|0000c120 63 03 02 01 00 00 00 30 00 29 00 00 00 00 08 09 |c......0.)......|0000c130 00 00 00 00 11 10 80 00 00 00 2d 01 10 61 62 62 |..........-..abb|0000c140 62 62 20 20 20 20 20 20 20 20 63 63 63 0b 00 00 |bb ccc...|0000c150 38 00 26 00 00 00 00 08 0a 00 00 00 00 11 11 80 |8.&amp;.............|0000c160 00 00 00 2d 01 10 62 62 20 20 20 20 20 20 20 20 |...-..bb |0000c170 03 02 01 00 00 00 40 fe f7 00 00 00 00 08 0b 00 |......@.........|0000c180 00 00 00 11 12 80 00 00 00 2d 01 10 61 62 62 62 |.........-..abbb|0000c190 62 20 20 20 20 20 20 20 20 63 63 63 00 00 00 00 |b ccc....| 按照书中所说，我们按照协议格式解析第一条及第二条记录如下: 12345678910111213141516171819202122第一条记录从0xc078开始: &quot;a&quot;, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;03 02 01 # 变长字段长度列表，逆序，分别代表ccc bb a的实际长度为3 2 100 # NULL标志位00 00 10 00 2b # 头信息，固定长度 5字节 0x002b代表下一个记录的偏移量00 00 00 00 08 05 # rowId00 00 00 00 11 0c # transactionId80 00 00 00 2d 01 10 # rollback pointer61 # &apos;a&apos;62 62 # &apos;bb&apos;62 62 20 20 20 20 20 20 20 20 # &apos;bb&apos; 固定长度其后用20补充63 63 63 # &apos;ccc&apos;第二条记录从0xc0a4开始: NULL, &quot;bb&quot;, &quot;bb&quot;, &quot;ccc&quot;03 02 # 变长字段长度列表，逆序，分别代表ccc bb a的实际长度为3 2 101 # NULL标志位, 0000 0001，表示第一个字段为NULL00 00 18 00 2b # 头信息，固定长度 5字节 0x002b代表下一个记录的偏移量00 00 00 00 08 06 # rowId00 00 00 00 11 0d # transactionId80 00 00 00 2d 01 10 # rollback pointer62 62 # &apos;bb&apos;62 62 20 20 20 20 20 20 20 20 # &apos;bb&apos; 固定长度其后用20补充63 63 63 # &apos;ccc&apos; 源码解析但是，问题来了，0xc078+0x002b=0xc0a3，与实际的开始地址0xc0a4不符，怎么回事呢？通过看代码，原来每行记录的开始地址是从第一列数据开始，通过下面的代码依次获得后面的记录。 1234567891011121314151617181920212223242526272829303132333435363738#为了简单，将许多无关的代码删除掉了#define UNIV_PAGE_SIZE 0x4000 # 16KB#define REC_NEXT 2# 第一条记录的开始地址是0xc081，返回值0xc0acpage_rec_get_next(rec)&#123; return((rec_t*) page_rec_get_next_low(rec, page_rec_is_comp(rec)));&#125;page_rec_get_next_low(rec)&#123; page = page_align(rec); # page: 0xc000 offs = rec_get_next_offs(rec); # offs: 0xac return(page + offs);&#125;page_align(rec)&#123; return((page_t*) ut_align_down(ptr, UNIV_PAGE_SIZE));&#125;ut_align_down(rec)&#123; return((void*)((((ulint) ptr)) &amp; ~(align_no - 1)));&#125;rec_get_next_offs(rec) # return: 0x00ac&#123; field_value = mach_read_from_2(rec - REC_NEXT); # field_value: 0x002b return(ut_align_offset(rec + field_value, UNIV_PAGE_SIZE));&#125;ut_align_offset(ptr, align_no)&#123; return(((ulint) ptr) &amp; (align_no - 1)); # ptr: 0xc0ac align_no: 0x4000 return:0x00ac&#125;mach_read_from_2(b) # b: 0xc07f b[0]:00 b[1]: 2b return: 0x002b&#123; return(((ulint)(b[0]) &lt;&lt; 8) | (ulint)(b[1]));&#125; 通过上面的分析，原来第一条记录的开始地址是0xc081，第二条记录的开始地址是0xc0ac。 innodb通过一个单链表将页内的所有记录串联起来，如上图所示。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"实战篇-ruby","date":"2017-05-17T09:55:38.000Z","path":"2017/05/17/实战篇-ruby/","text":"123456789yum install ruby # 默认系统安装 版本1.8.7# 升级到1.9.3# 首先安装rvm(ruby的多环境管理工具)rvm install 1.9.3rvm use 1.9.3 --default# gem是ruby库的管理工具","tags":[{"name":"ruby","slug":"ruby","permalink":"http://yoursite.com/tags/ruby/"}]},{"title":"实战篇-mysql之性能调优","date":"2017-05-15T11:02:21.000Z","path":"2017/05/15/实战篇-mysql之性能调优/","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879mysql&gt; show engine innodb status \\G*************************** 1. row *************************** Type: InnoDB Name:Status:=====================================170515 18:57:08 INNODB MONITOR OUTPUT=====================================Per second averages calculated from the last 55 seconds----------SEMAPHORES----------OS WAIT ARRAY INFO: reservation count 7, signal count 7Mutex spin waits 0, rounds 0, OS waits 0RW-shared spins 14, OS waits 7; RW-excl spins 0, OS waits 0------------TRANSACTIONS------------Trx id counter 0 769Purge done for trx&apos;s n:o &lt; 0 0 undo n:o &lt; 0 0History list length 0LIST OF TRANSACTIONS FOR EACH SESSION:---TRANSACTION 0 0, not started, process no 1588, OS thread id 140663937918720MySQL thread id 2, query id 47 localhost rootshow engine innodb status--------FILE I/O--------I/O thread 0 state: waiting for i/o request (insert buffer thread)I/O thread 1 state: waiting for i/o request (log thread)I/O thread 2 state: waiting for i/o request (read thread)I/O thread 3 state: waiting for i/o request (write thread)Pending normal aio reads: 0, aio writes: 0, ibuf aio reads: 0, log i/o&apos;s: 0, sync i/o&apos;s: 0Pending flushes (fsync) log: 0; buffer pool: 00 OS file reads, 38 OS file writes, 16 OS fsyncs0.00 reads/s, 0 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s-------------------------------------INSERT BUFFER AND ADAPTIVE HASH INDEX # 插入缓冲和自适应哈希索引-------------------------------------Ibuf: size 1(已经合并记录页的数量), free list len 0(空闲列表的长度), seg size 2(当前插入缓冲的大小:2*16KB),0 inserts(插入的记录数), 0 merged recs(合并的页的数量), 0 merges(合并的次数)Hash table size 17393(哈希表槽的数量), node heap has 1 buffer(s)0.00 hash searches/s(每秒多少次哈希查找), 0.00 non-hash searches/s(每秒多少次非哈希查找)---LOG---Log sequence number 0 44233 # 当前的LSNLog flushed up to 0 44233 # 刷新到重做日志文件的LSNLast checkpoint at 0 44233 # 刷新到磁盘的LSN0 pending log writes, 0 pending chkp writes11 log i/o&apos;s done, 0.00 log i/o&apos;s/second----------------------BUFFER POOL AND MEMORY----------------------Total memory allocated 20375354; in additional pool allocated 652800Dictionary memory allocated 33320Buffer pool size 512 # 缓冲的总大小，每个代表一个数据页(16K) 512*16/1024=8MFree buffers 333 # 空闲的数量Database pages 178 # 已使用的数量Modified db pages 0 # 脏页的数量Pending reads 0Pending writes: LRU 0, flush list 0, single page 0Pages read 0, created 178, written 1890.00 reads/s, 0.00 creates/s, 0.00 writes/sNo buffer pool page gets since the last printout--------------ROW OPERATIONS--------------0 queries inside InnoDB, 0 queries in queue1 read views open inside InnoDBMain thread process no. 1588, id 140663815362304, state: waiting for server activityNumber of rows inserted 0, updated 0, deleted 0, read 00.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 0.00 reads/s----------------------------END OF INNODB MONITOR OUTPUT============================1 row in set (0.00 sec) 123456789101112131415161718mysql&gt; show index from ab \\G*************************** 1. row *************************** Table: ab # 表名 Non_unique: 1 # 非唯一 Key_name: idx_a # 索引名Seq_in_index: 1 # 索引列的位置(联合索引中使用) Column_name: a # 索引的列 Collation: A # 列以什么方式存放在索引中 A(有序)或NULL(无序) Cardinality: 2 # 索引中唯一值的估值，非常关键，评判一个索引是否有必要 Sub_part: NULL # 是否列的一部分 Packed: NULL # 是否被压缩 Null: # 索引的列是否还有NULL Index_type: BTREE # 索引类型 Comment: # 注释1 row in set (0.00 sec)优化器会根据cardinality的值来判断是否使用索引。analyze table tbl_name; # 会更新cardianlity的值 123456789101112131415mysql&gt; explain select * from ab where a = 1 \\G*************************** 1. row *************************** id: 1 select_type: SIMPLE # 选择类型 table: ab # 表名 type: ref # possible_keys: idx_a # 可使用的索引 key: idx_a # 使用的索引 key_len: 4 # 索引的长度 ref: const # rows: 1 # 行数 Extra:1 row in set (0.00 sec)查询优化器根据rows来判断是否使用索引，或执行全表扫描。","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"理论篇-mysql之innodb","date":"2017-05-15T02:51:20.000Z","path":"2017/05/15/理论篇-mysql之innodb/","text":"简介innodb是第一个完整支持ACID事物的mysql存储引擎，行锁设计，支持MVCC，提供类似oracle风格的一致性非锁定读，支持外键，被设计用来最有效的利用内存和CPU。 内存innodb有许多内存块，其中包括buffer pool、redo log buffer、additional memory pool。这些内存块组成了一个大的内存池，负责如下工作: 维护所有进程/线程需要访问的多个内部数据结构 缓存磁盘上的数据，方便快速读取，并且对磁盘上的文件进行修改之前在这里缓存 重做日志缓冲 … 123innodb_buffer_pool_size # buffer poolinnodb_log_buffer_size # log bufferinnodb_additional_mem_pool_size # additonal mem pool 使用内存的方法: 将数据库文件按页(每页16K)读取到内存池，然后按照最近最少使用算法(LRU)来保留在内存池中的数据。对数据的修改，首先修改内存池中的数据，此时该数据为脏数据，然后再以一定的频率将脏数据刷新到磁盘。 buffer pool里的数据页类型: index page、data page、undo page、insert buffer、自适应哈希索引(adaptive hash index)、lock info、data dictionary等 redo log buffer记录重做日志信息，然后以一定的频率(每秒)将其刷新到重做日志文件。 additional mem pool记录一些其他对象的信息。 线程innodb也有许多后台线程，默认情况下有4个IO线程、1个主线程、1个锁监控线程、1个错误监控线程。主要负责如下工作: 刷新内存中的数据，保证内存池中的内存缓存的是最近的数据 将已修改的数据刷新到磁盘文件，同时保证数据库发生异常的情况下innodb能恢复到正常运行状态 4个IO线程分别为insert buffer thread、log thread、read thread、write thread。 1innodb_file_io_threads=4 # IO thread数量(linux下不可调整) master thread 待看 关键特性插入缓冲(insert buffer)插入缓冲是为了提高对非聚集索引的操作的，首先判断非聚集索引页是否在缓冲池中，如果在，则直接插入。否则将数据放入插入缓冲区中，然后以一定的频率执行插入缓冲和非聚集索引叶子节点的合并操作。需满足如下两个条件: 索引是非聚集索引 不是唯一索引 1IBUF_POOL_SIZE_PRE_MAX_SIZE 2 # 插入缓冲占总缓冲区的多少 为了插入速度的提升 双写(double write)double write由两部分组成: 1. 内存中的doublewrite buffer，大小为2MB；另一部分是物理磁盘上共享表空间中连续的128个页，即两个区，大小同样为2M。 运行原理:当缓冲池中的脏页刷新时，并不直接写磁盘，而是通过memcpy函数将脏页先拷贝到内存中的doublewrite buffer，之后通过两次磁盘写操作将数据持久化到硬盘，每次写入数据量1M。第一次写到共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘，由于页是连续的，所以执行速度很快。第二次写到各个表空间文件中，此时的写入则是离散的。 12345innodb_doublewrite=ON # 双写的开关show global status like &quot;innodb%&quot;;Innodb_dblwr_pages_written # 写入的页的数量Innodb_dblwr_writes # 写磁盘的次数 如果数据库在将页写入磁盘的过程中崩溃了，在恢复过程中，innodb引擎可以从共享表空间的doublewrite中找到该页的副本，将其拷贝到表空间里，再应用重做日志。 为了数据的安全 自适应哈希索引自适应哈希索引不需要将整个表都建索引，innodb会自动根据访问的频率和模式来为某些页建立哈希索引。 1innodb_adaptive_hash_index=ON # 自适应哈希索引的开关 为了查询速度的提升 启动、关闭和恢复innodb_fast_shutdown参数决定了innodb关闭时执行的操作，默认为0。 innodb_fast_shutdown 含义 0 完成所有的full purge和merge insert buffer操作 1 不做如上操作，只刷新缓冲池中的脏数据到磁盘 2 不做如上操作，只将日志写入到日志文件 innodb_force_recovery参数决定了innodb启动时执行的操作，默认为0。 innodb_force_recovery 含义 0 执行所有的恢复操作 1 忽略检查到的corrupt页 2 阻止主线程的执行，如主线程需要执行full purge操作，会导致crash 3 不执行事务回滚操作 4 不执行插入缓冲的合并操作 5 不查看撤销日志，会将未提交的事务视为已提交 6 不执行回滚的操作 文件参数文件123SET| [global | session] system_var_name=expr| [@@global. | @@session. | @@]system_var_name=expr # 设置参数 日志文件错误日志对mysql的启动、运行、关闭过程进行了记录。 1show variables like &quot;log_error&quot;; # 查看错误日志的路径 二进制日志待看 12log_bin=OFF # 二进制日志开关show variables like &quot;datadir&quot;; # 日志路径 慢查询日志主要用来优化sql查询。 123456789long_query_time=10 # 慢查询的阈值(单位:微妙)log_output=FILE # 指定慢查询的记录格式 FILE TABLElog_queries_not_using_indexes=OFF # 没有使用索引的查询也被当做慢查询log_slow_queries=OFF # 慢查询的开关slow_query_log=OFF # 慢查询日志开关slow_query_log_file=&quot;&quot; # 慢查询日志路径mysqldumpslow # 该工具可以帮助解析慢查询日志 表结构定义文件以frm为后缀名结尾的文件记录了表的结构定义。该文件还用来存放试图的定义。 innodb存储引擎文件重做日志文件ib_logile0和ib_logfile1是innodb存储引擎的重做日志文件，主要用来记录innodb引擎的事务日志。 如图所示，重做日志首先写入重做日志缓冲区中，然后以一定的频率刷新到磁盘。主线程每秒将重做日志缓冲写入到磁盘的重做日志文件，不论事务是否已提交。innodb_flush_log_at_trx_commit参数决定了在事务提交时，对重做日志的处理。 innodb_flush_log_at_trx_commit 含义 0 等待主线程每秒的刷新 1 commit时将重做日志缓冲同步到磁盘 2 commit时将重做日志异步写到磁盘 1234innodb_log_file_size # 重做日志文件的大小innodb_log_files_in_group # 日志文件组中重做日志文件的数量 默认为2innodb_mirrored_log_groups # 日志镜像文件组的数量，默认为1innodb_log_group_home_dir # 日志文件组所在路径 表空间文件ibdata1即为默认的表空间文件。innodb_file_per_table参数可设置每张表一个表空间文件，单独的表空间文件以ibd为后缀，这些文件只记录了该表的数据、索引和插入缓冲等信息，其他信息还是要存放到默认的表空间文件中。 12345innodb_file_per_table=0 # 每张表一个文件的开关[mysqld]innodb_data_file_path=datafile_spec1[;datafile_spec2]...innodb_data_file_path=/db/ibdata1:2000M;/db2/ibdata2:2000M:autoextend 表innodb存储引擎表中，每张表都有个主键，如果在创建表时没有显式的定义主键(primary key)，则会按如下方式选择或创建主键: 表中是否有非空的且为唯一的列，若有，则该列即为主键 不符合上述条件，则自动创建一个6个字节大小的指针 逻辑存储结构所有数据被逻辑的存放在一个空间中，该空间被称为表空间(tablespace)。表空间又由段(segment)、区(extent)、页(page)组成。如下图所示: 常见的段有数据段、索引段、回滚段等，其中数据段即为B+树的叶节点，索引段即为B+树的非叶节点。 区是由64个连续的页组成的，每个页的大小为16KB，即每个区的大小为1MB。 每页可容纳的记录数(即行数)为200~16KB/2之间。 物理存储结构若将innodb_file_per_table设置为on，则每个表将独立的产生一个表空间文件，以ibd结尾，数据、索引、表的内部数据字典信息都将保存在这个单独的表空间文件中。表结构定义文件后缀为frm。 InnoDB行记录格式mysql5.1之后，有两种存放行记录的格式: Compact和Redundant，其中Compact是新格式。 1show table status \\G # 查看表信息 123456789Compact格式如下:变长字段实际长度列表|NULL标志位|头信息|列1数据|列2数据|...变长字段实际长度列表，当列的长度小于255时，用1字节表示，若大于255时，用2字节表示，最大不可超过2个字节(这就是为什么varchar不能超过65535的原因)。NULL标志位，该位表示了该行数据中是否有NULL标志位 根据需要，可能为多字节头信息，固定占用5字节，每位的如下表所示最后是每列的数据，NULL不占用列数据每行还有两个隐藏列: 事务ID列和回滚指针列，分别占用6字节和7字节，若没有primary key，则每行还会增加一个6字节的rowId列。 名称 大小(bit) 含义 () 1 未知 () 1 未知 deleted_flag 1 该行是否已被删除 min_rec_flag 1 若该记录是预先被定义为最小记录则为1 n_owned 4 该记录拥有的记录数 heap_no 13 索引堆中该记录的排序记录 record_type 3 记录类型 000:普通 001:B+树节点指针 002:Infinum 003: Supermum 1xx=保留 next_recorder 16 页中下一条记录的相对位置 123varchar(N) # 其中varchar最大长度为65535个字节，其中N指的是字符个数，且为所有varchar列的总和char(N) # 在多字节字符集的情况下，char也被当做变长类型来处理 InnoDB数据页结构InnoDB数据页格式如下图所示: File Header包含如下字段: 字段 大小(字节) 含义 FIL_FILE_PAGE_OR_CHKSUM 4 目前为checksum值 FIL_PAGE_OFFSET 4 页的偏移值? FIL_PAGE_PREV 4 上一页 FIL_PAGE_NEXT 4 下一页 FIL_PAGE_LSN 8 该页最后被修改的日志序列位置LSN(Log Sequence Number) FIL_PAGE_TYPE 2 页的类型 FIL_PAGE_FILE_FLUSH_LSN 8 该值只在数据文件的一个页中定义，代表文件至少被更新到了该LSN值 FIL_PAGE_ARCH_LOG_ON_OR_SPACE_ID 4 该页属于哪个表空间 页类型有如下几种: 名称 十六进制 解释 FIL_PAGE_INDEX 0x45BF B+树叶子节点 FIL_PAGE_UNDO_LOG 0x0002 Undo Log 页 FIL_PAGE_INODE 0x0003 索引节点 FIL_PAGE_IBUF_FREE_LIST 0x0004 Insert Buffer 空闲列表 FIL_PAGE_TYPE_ALLOCATED 0x0000 该页为最新分配 FIL_PAGE_IBUF_BITMAP 0x0005 Insert Buffer位图 FIL_PAGE_TYPE_SYS 0x0006 系统页 FIL_PAGE_TYPE_TRX_SYS 0x0007 事务系统数据 FIL_PAGE_TYPE_FSP_HDR 0x0008 File Space Header FIL_PAGE_TYPE_XDES 0x0009 扩展描述页 FIL_PAGE_TYPE_BLOB 0x000A BLOB页 Index Header包含字段如下: 字段 大小(字节) 解释 PAGE_N_DIR_SLOTS 2 在page directory中的slots数 PAGE_HEAP_TOP 2 空闲空间开始位置的偏移量 PAGE_N_HEAP 2 堆中的记录数 PAGE_FREE 2 指向空闲列表的首指针 PAGE_GARBAGE 2 已删除记录的字节数 即行记录中，delete flag为1的记录大小的总和 PAGE_LAST_INSERT 2 最后插入记录的位置 PAGE_DIRECTION 2 最后插入的方向 PAGE_N_DIRECTION 2 一个方向连续插入记录的数量 PAGE_N_RECS 2 该页中记录的数量 PAGE_MAX_TRX_ID 8 修改当前页的最大事务ID，注意该值仅在secondary index中定义 PAGE_LEVEL 2 当前页在索引树中的位置 0x00代表页节点 PAGE_INDEX_ID 8 当前页属于哪个索引ID FSEG Header包含字段如下: 字段 大小(字节) 解释 PAGE_BTR_SEG_LEAF 10 B+树的叶节点中，文件段的首指针位置 PAGE_BTR_SEG_TOP 10 B+树的非叶节点中，文件段的首指针位置 System records中包含的字段: infimum和supremum记录？ User records即实际存储行记录的内容。 FreeSpace空闲链表，同样是链表数据结构，当一条记录被删除后会被加入空闲链表中。 File Traier的作用是保证页的完整性，其中包含的字段如下: 字段 大小(字节) 解释 FIL_PAGE_END_LSN 8 前4个字节代表该页的checksum值，后4个字节与File Header中的FIL_PAGE_LSN相同 索引innodb支持两种索引: B+树索引和哈希索引。 哈希索引innodb引擎支持的哈希索引是自适应的，会根据表的使用情况自动生成哈希索引，不能人工干预。最终目的是加速对内存数据即缓存的查找。 1innodb_adaptive_hash_index=ON # 自适应哈希索引启用开关 B+树索引B+树索引能找到的只是被查找数据行所在的页，将页加载到内存后再通过二分查找，最后得到查找的数据。最终目的是加速对磁盘即数据库文件的查找。 插入操作插入操作的三种情况 leaf page full index page full operations No No 直接将记录插入页节点 Yes No 1. 拆分leaf page2. 将中间节点放入index page中3. 小于中间节点的记录放左边4. 大于等于中间节点的记录放右边 Yes Yes 1. 拆分leaf page2. 小于中间节点的记录放左边3. 大于中间节点的记录放右边4. 拆分index page5. 小于中间节点的记录放左边6. 大于中间节点的记录放右边7. 中间节点放入上一层index page 页的拆分意味着磁盘的操作，为了尽量避免磁盘操作，使用旋转来避免页拆分。 删除操作B+树使用填充因子(fill factor)控制树的删除变化，50%是填充因子的最小值。 leaf page below fill factor index page below fill factor oprations No No 直接将记录从叶节点删除，如果该节点还是index page节点，则用该节点的右节点替代 Yes No 合并页节点及其兄弟节点，同时更新index page Yes Yes 1. 合并叶节点机器兄弟节点2. 更新index page3. 合并index page及其兄弟节点 聚集索引和非聚集索引innodb存储引擎表中数据按照主键顺序存放。 聚集索引(clustered index)就是按照表中主键构造一个B+树，并且叶节点中存放着整张表的行记录数据，因此叶节点也是数据页。 数据页通过双向链表维护，页中的记录也通过双向链表维护。 非聚集索引(secondary index)是按照指定的关键字构造的一个B+树，并且叶节点存放的是行记录的主键。 如果在一个高度为3的非聚集索引树上查找数据，那么首先需要通过3次磁盘IO从非聚集索引找到指定主键。如果聚集索引高度同样为3，那么还需要通过3次磁盘IO从聚集索引找到要查找的数据。 预读取顺序预读取: 一个区(由64个页组成)中多少页被顺序访问时，innodb引擎会读取下一个区的所有页。 1innodb_read_ahead_threshold=56 # 预读取阈值配置 辅助索引联合索引值得关注的地方 对于索引的添加和删除操作，mysql数据库先创建一张临时表，然后把数据导入临时表，删除原表，然后将临时表重命名为原来的表名，所以对于大表，此操作极为耗时。 从版本innodb plugin开始，支持一种称为快速索引创建方法，仅限于非聚集索引。 索引的使用原则: 高选择性和取出表中少部分数据。 即使访问的是高选择性字段，但是由于查询命中的数据占表中大部分(经验值20%)数据时，此时查询优化器也会不走索引，而执行全表扫描。 锁mysql提供了表级锁，表级锁并发性不高，表级锁分为两类: 共享锁(S Lock) 允许事务读该表 排它锁(X Lock) 允许操作该表 为了提高并发性，innodb存储引擎提供了行级锁，行级锁分两种: 共享锁(S Lock) 允许事务读一行数据 排它锁(X Lock) 允许事务删除或更新一行数据 innnodb引擎支持多粒度锁定，即在一个表上可以加表锁也可以加行锁。 假设现在有两个事务t1和t2，其中t1在x表的某一行上加锁，这时，t2想对x表加锁，在加锁之前，t2需要遍历所有的行，检查有没有行锁，很明显，这样效率是不高的。 为了支持这种多粒度锁定，又为了提高程序的速度，引擎引入了另一种锁，叫意向锁。意向锁是表级别的锁。支持两种意向锁: 意向共享锁(IS Lock) 事务想要获得一个表中某几行的共享锁 意向排它锁(IX Lock) 事务想要获得一个表中某几行的排它锁 还是刚才的事例，有了意向锁之后，t1在x表的某一行加锁之前，需要对x表加一个意向共享锁，然后才能在某一行加锁。这样当t2想对x表加锁时，只要检查该表有没有意向锁就好了，性能得到明显的提高。 查看当前数据库的请求和锁的情况 123456show processlist \\Gshow engine innodb status \\Ginformation_schema.INNODB_TRXinformation_schema.INNODB_LOCKSinformation_schema.INNODB_LOCK_WAITS 多版本并发控制(MVCC) 1select @@tx_isolation; # 查看事务隔离级别 锁定算法: Record Lock: 单个行记录上的锁 Gap Lock: 间隙锁，锁定一个范围，但不包含记录本身 Next-key Lock: Record Lock + Gap Lock，锁定一个范围，并且包含记录本身 事务隔离级别 非锁定的一致性读 锁定算法 Read Uncommitted Read Committed 总是读取被锁定行的最新一份快照数据 Repeatable Read(默认) 总是读取事务开始时的行快照数据 Next-key Lock 123# 这些语句必须在事务中执行，当事务提交的时候，锁也就释放了select ... for update; # 给读取的行加一个X锁select ... lock in share mode; # 给读取的行加一个S锁 自增长与锁自增长插入分为三类: Simple Inserts: 能确定插入行数的插入 Bulk Inserts: 不能确定插入行数的插入 Mixed-mode Inserts: 插入的数据中一部分值是自增长的，一部分是确定的 1innodb_autoinc_lock_mode=1; # 自增长锁的模式 innodb_autoinc_lock_mode 解释 0 通过表锁的AUTO-INC Locking方式 1 对于Simple Inserts通过互斥量对于Bulk Inserts通过表锁的AUTO-INC Locking方式 2 通过互斥量 使用锁的问题丢失更新故事如下: 事务T1查询一行数据 事务T2查询一行数据 事务T1修改这行记录，更新数据库并提交 事务T2修改这行记录，更新数据库并提交 这样，事务T1的修改被事务T2的修改给覆盖了，事务T1的更新丢失了。 解决方案: 在查询的时候使用”select … for update”这样的查询语句，这样就会对该行记录加一个排它锁，其他的所有操作都会被阻塞。 脏读脏读值得是在不同的事务下，可以读到另外事务未提交的数据。 不可重复读不可重复读(幻读)指由于别的事务的修改，导致同一事务内对同一数据的多次读取结果不一致，一般是插入了新的数据。 阻塞12innodb_lock_wait_timeout=50; # 设置锁等待时间innodb_rollback_on_timeout=OFF; # 在等待超时时，是否对事务进行回滚操作 死锁死锁发生时会回滚一个事务。 心得体会在事务隔离级别为Read Committed下 读取的时候，使用多版本并发控制，不涉及锁的操作，每个事务读取该读取的版本，事务之间不存在同步问题，除非显式加锁。 更新的时候，会在该行显式加X锁，其他事务对该行的操作需要等待该锁的释放。 插入的时候，会导致幻读。 删除的时候，没有next-key lock锁保护。 在事务隔离级别为Repeatable Read下 读取的时候，使用多版本并发控制，不涉及锁的操作，每个事务读取该读取的版本，事务之间不存在同步问题，除非显式加锁。 更新的时候，会在该行显式加X锁，其他事务对该行的操作需要等待该锁的释放。 插入的时候，不会导致幻读。 删除的时候，会有next-key lock锁保护。 事务ACID特性: 原子性(atomicity) 整个事务不可分割，要么成功，要么回到原始状态 一致性(consistency) 事务开始前和结束后，完整性约束不被破坏? 隔离性(isolation) 事务之间互不影响 持久性(durability) 结果的持久化保存 innodb的隔离性通过锁实现，其它三个属性原子性、一致性、持久性通过redo和undo来实现。 redo事务日志通过redo日志文件和日志缓冲来实现。 当事务开始时，会记录该事务的一个LSN(Log Sequence Number) 当事务执行时，会往日志缓冲里插入事务日志 当事务提交时，必须将日志缓冲写入文件(innodb_flush_log_at_trx_commit=1) undo当事务需要回滚时，利用的就是这个日志。 事务控制语句 语句 含义 start transaction or begin 显式的开启一个事务 commit or commit work 提交一个事务 rollback or rollback work 回滚一个事务 savepoint identifier 在事务中创建一个保存点 release savepoint identifier 删除一个事务的保存点 rollback to identifier 回滚到一个保存点 set transaction 设置事务隔离级别 备注: commit work在不同设置下的含义: completion_type 等价于 含义 0 commit 简单提交一个事务 1 commit and chain 完成后会开启另一个事务 2 commit and release 事务提交后会自动断开与服务器的连接 rollback work与commit work类似。 隐式提交的sql语句自动提交模式下，执行一条sql语句后会立即执行commit动作。其他一些DDL语句也会自动提交。 事务隔离级别 read uncommitted read committed repeatable read serializable innodb在repeatable read隔离级别下，通过next-key lock锁的算法，避免了幻读的产生，与serializable隔离级别等效。 在seriablizable隔离级别下，innodb引擎会对每个select语句后自动加上lock in share mode，即给每个读取加一个共享锁。 二进制日志格式有两种: statement和row。statement格式的是sql语句的记录，row格式的是对行的记录。 分布式事务备份与恢复性能调优参考 MySQL技术内幕: InnoDB存储引擎","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"实战篇-vim","date":"2017-05-14T11:42:34.000Z","path":"2017/05/14/实战篇-vim/","text":"1234567:%! xxd # 切换到十六进制方式:%! xxd -r # 切换到文本方式hexdump -C -v xxx &gt; xxx # 导出文件的十六进制表示start, end s/old/new/g # 替换从start到end之前的行%s/old/new/g # 全局替换","tags":[{"name":"vim","slug":"vim","permalink":"http://yoursite.com/tags/vim/"}]},{"title":"理论篇-python之字符串","date":"2017-05-13T08:44:05.000Z","path":"2017/05/13/理论篇-python之字符串/","text":"编码与解码ASCII标准首先被创建，该标准使用一个字节来表示一个字符，其中0-127表示普通字符，128-255没有使用，比如字符’a’的字节整数值是97。 随着计算机的发展，一些其他发达国家也开始使用了，比如欧洲的一些国家。但是他们发现一些字符ASCII标准里是没有的，于是他们拓展了ASCII标准，利用128-255来表示那些字符，发明了一个新的标准Latin-1标准。 计算机更普及了，世界上的一些发展中国家也开始使用计算机了。他们也发现他们的符号在ASCII中没有，并且也无法通过简单的扩展ASCII来容纳所有的符号。于是各个国家发明了自己的编码规则。 随着计算机的更加普及，国家之间通过计算机的交互也越来越多，由于各个国家之间的编码规则不统一，所以需要一套统一的编码规则。Unicode编码规则诞生了。Unicode字符串是一个宽字符的字符串，即一个文字可能由多个字节表示。 utf-8是Unicode编码规则的一种实现。0-127是单字节的，128-0x7ff是双字节的(每个字节的值的范围是128-255)，0x7ff以上是三个或四个字节(每个字节的值的范围是128-255)。这样既兼容了ASCII编码规则，也解决了字节的顺序问题。 ASCII、Latin-1、utf-8等其他多字节编码都是Unicode编码。 为了真正在计算机中存储这些文字，我们需要一套编码规则，将我们的文字编码为计算机可表示的字节序列以及当我们需要查看时将字节序列解码为文字。世界上不仅仅只有这两种编码规则，还有许多其他的编码规则，同一个符号，使用不同的编码规则将得到不同的字节序列。 编码: 依据编码规则，将文字转换成字节序列。解码: 依据编码规则，将字节序列转换成文字。 python中的字符串123456789101112131415161718192021# 2.xstr # 8位的文本和二进制数据unicode # 宽字节的unicode文本# 3.x&quot;xxx&quot;str # unicode文本(单字节和宽字节)b&quot;xxx&quot;bytes # 二进制数据(ASCII或者大于127的值进行转义后的十六进制值)bytearray # 可变的bytes类型的数组str.encode() # 编码类型可选，若不指定，则使用系统默认编码bytes(&quot;xxx&quot;, encoding) # 将str转换为bytes， 编码类型必选bytes.decode() # 编码类型可选，若不指定，则使用系统默认编码str(b&quot;xxx&quot;, encoding) # 将bytes转换为str， 编码类型必选\\x # 十六进制转义符\\u \\U # unicode转义符&quot;\\xNN&quot; &quot;\\uNNNN&quot; &quot;\\UNNNNNNNN&quot; # 字符串支持len(s) # 针对\\u字符串，返回的是字符数 3.x里，str本质是一个不可变的字符序列，bytes本质是一个不可变的8位整数序列，bytesarray本质是一个可变的8位整数序列。 在3.x里，打开文件的模式至关重要，决定了文件的处理方式和使用的python对象类型。 文本模式: 使用str对象，读写文件时，对内容进行编解码。 二进制模式: 使用bytes对象，读写文件时，不对内容做任何处理。 12&gt;&gt;&gt;b_s = b&apos;spam&apos; # make a bytes object&gt;&gt;&gt;s_s = &apos;spam&apos; # make a str object 1234&gt;&gt;&gt;s = &quot;XYZ&quot;&gt;&gt;&gt;s.encode(&quot;ascii&quot;) # values 0-127 in 1 byte(7 bits)&gt;&gt;&gt;s.encode(&quot;latin-1&quot;) # values 0-255 in 1 byte(8 bits)&gt;&gt;&gt;s.encode(&quot;utf-8&quot;) # values 0-127 in 1 byte, 128-2047 in 2 others 3 or 4 源文件字符集编码声明1234567891011121314# -*- coding: latin-1 -*-s = u&quot;中国&quot;print(list(s))----output----[u&apos;a&apos;, u&apos;b&apos;, u&apos;c&apos;, u&apos;\\xe4&apos;, u&apos;\\xb8&apos;, u&apos;\\xad&apos;, u&apos;\\xe5&apos;, u&apos;\\x9b&apos;, u&apos;\\xbd&apos;]# -*- coding: utf-8 -*-s = u&quot;中国&quot;print(list(s))----output----[u&apos;a&apos;, u&apos;b&apos;, u&apos;c&apos;, u&apos;\\u4e2d&apos;, u&apos;\\u56fd&apos;] 源文件字符集编码声明决定了源文件里的非ASCII的字符编码。 系统默认编码2.x的系统默认编码是ascii，3.x的系统默认编码是utf-8。系统默认编码最大的用途: 作为中间层。 12s = u&quot;abc中国&quot;s.decode(&quot;utf-8&quot;) # 本质是s.encode(sysdefaultencoding).decode(&quot;utf-8&quot;) 文件读写12345678# 3.xopen(&quot;filename&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;).write(&quot;xxx&quot;) # 以utf-8编码写入文件open(&quot;filename&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;).read() # 以utf-8编码读取文件# 2.ximport codecscodecs.open(&quot;filename&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;).write(&quot;xxx&quot;)codecs.open(&quot;filename&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;).read() 对BOM(Byte Order Marker)的处理 123```#### 待看 Chapter 36. Other String Tool Changes in 3.0```","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python之函数","date":"2017-05-13T08:40:48.000Z","path":"2017/05/13/理论篇-python之函数/","text":"","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-python之虚拟环境","date":"2017-05-13T01:44:51.000Z","path":"2017/05/13/实战篇-python之虚拟环境/","text":"实际工作中，我们经常会遇到这样的场景: 维护多个python项目，每个项目依赖的第三方库又不同。在一台机器上面，很难应对这样的场景。但是，今天我们介绍一款应对此场景的利器: virtualenv。 virtualenv是创建python虚拟环境的工具。 安装123456# pip源码安装wget https://bootstrap.pypa.io/get-pip.pysudo python get-pip.py# virtualenv安装sudo pip install virtualenv 使用12345# 创建python3.6版本的虚拟环境virtualenv --python=python3.6 python3_6# 进入虚拟环境source python3_6/bin/activate 1234virtualevn ENV # 创建一个虚拟环境 --no-site-packages # 不实用系统环境中的第三方库deactivate # 退出当前环境 参考pip官网","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python之包","date":"2017-05-12T07:42:16.000Z","path":"2017/05/12/理论篇-python之包/","text":"python将操作系统中的目录变成了包，本质也是一种命名空间，主要为了防止命名冲突。 包含__init__.py文件的目录就是python的包。 包初始化: 包第一次被初始化的时候会执行__init__.py的代码 模块命名空间初始化: __init__.py里的变量会变成模块对象的属性 from *: 加载__all__列表里的内容 123__all__ # from *需加载的内容from xxx1.xxx2 import mod # 导入模块import xxx1.xxx2 as mod # 给模块起个别名 相对导入 相对导入只针对包内搜索 目的是解决包导入时的歧义性 2.6及以后的搜索方式: 先相对后绝对。3.x及以后搜索绝对路径(sys.path)，除非显式指定相对搜索 123456. .. # 相对导入符号from string import name # 从绝对路径搜索 from .string import test # 2.x 3.x 从当前包路径搜索import test # 2.x首先搜索当前包，然后搜索绝对路径 3.x搜索绝对路径from __future__ import absolute_import # 2.x搜索绝对路径 模块的私有属性1_name # 一种约定，只对from *有效 最新功能的使用1from __future__ import featurename","tags":[]},{"title":"理论篇-python之模块","date":"2017-05-11T13:51:34.000Z","path":"2017/05/11/理论篇-python之模块/","text":"模块是一种代码组织的单元，是一种命名空间，本质是一个字典。 import的工作原理: 发现模块文件 程序的home目录(即可执行文件所在的目录) PYTHONPATH目录(如果设置了的话，是一个列表) 标准库目录 任何.pth文件的内容(如果有的话，位置/usr/local/lib/python3.0/site-packages or /usr/local/lib/site-python) 编译到字节码(需要的时候) 通过比较.py文件和.pyc文件的时间戳来判断是否需要重新编译。编译只有在导入的时候发生，.pyc是编译产生的字节码文件。 运行字节码来构建对象 文件里的所有语句从上到下执行，赋值语句将生成模块的属性。 只有当第一次import一个模块的时候才会执行以上步骤。随后的import仅仅是获取已经在内存中的对象。被导入的模块被存在sys.modules表里。 “import b”该语句执行的时候将会搜索如下文件或目录: 源文件b.py 字节码文件b.pyc 目录b C或C++编写的被编译的扩展模块，当导入的时候通常被动态链接(例如b.so或者 b.dll) 一个用C编写的被编译的内置模块，静态链接到python 一个zip文件组件，当被导入时自动解压 An in-memory image, for frozen executables A java class, in the Jython version of python A .net component, in the IronPython version of python 12345678910sys.modules # 已导入的所有的模块sys.path # 所有的搜索目录，包括以上四个搜索路径的列表import # 整体导入一个模块from # 将对象从被加载的模块中拷贝到当前模块中reload # reload只对python编写的源码有效且只对当前文件 (3.x里是imp.reload)__dict__ # 模块的命名空间__name__ # 若文件被当做主文件执行，则为&quot;__main__&quot;, 若作为模块，则为文件名python -O 生成优化的字节码文件distutils # 第三方软件 12345678# small.pyx = 1y = [1, 2]from small import *x = 42 # change local x onlyy[0] = 42 # change shared mutalbe in-place import导入时通常会运行__import__钩子函数来执行一些定制化的操作。本质是一个赋值语句。from的本质是建立一个共享对象的引用。 12345from module import name1, name2is equal to import modulename1 = module.name1name2 = module.name2 利用import钩子函数统计各个模块的调用时间 123456789101112131415161718import __builtin__import timebuiltin_import = __builtin__.__import__def myimport(name, globals=&#123;&#125;, locals=&#123;&#125;, fromlist=[], level=-1): start = time.time() * 1000 res = builtin_import(name, globals, locals, fromlist, level) end = time.time() * 1000 print(&quot;%s: %s&quot; % (name, end-start)) return res__builtin__.__import__ = myimportimport module_1import sys 模块的命名必须遵守变量的命名规范，因为模块名称之后会变成一个变量。 不管使用import还是from，加载的对象只有一个。 一个函数不能访问另一个函数的变量，除非是闭包。一个模块不能访问另一个模块的变量，除非是显式的导入。 1234567891011# a.pyX = 88def f(): global X X = 99# b.py X = 11import aa.f()print(X, a.X) # 11, 99 reload是一个in-place的改变，会影响所有的import，但不会影响from。 123456789# a.pydef test(): print(&quot;......&quot;)&gt;&gt;&gt;from a import test&gt;&gt;&gt;test() # output: .......&gt;&gt;&gt;import a&gt;&gt;&gt;reload(a) # 对a做一些修改后重新加载&gt;&gt;&gt;test() # 任然引用的是之前的对象 自省以下四个表达式效果一样 1234M.nameM.__dict__[&apos;name&apos;]sys.modules[&apos;M&apos;].namegetattr(M, &apos;name&apos;) 从字符串中加载模块1234modname = &quot;string&quot;exec(&quot;import &quot; + modname) # 每次必须得编译import语句string = __import__(modname) 声明顺序 模块文件里的声明从上到下一个一个的执行，不允许提前引用 函数体内的代码直到函数运行时才执行，所以引用无限制 题外话C语言的#include仅仅是文本的替换","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-python之mixin模式","date":"2017-05-11T09:46:14.000Z","path":"2017/05/11/实战篇-python之mixin模式/","text":"实现功能组合的方式有多种，比如继承、组合等，但是如果代码结构比较复杂，相应的继承结构也会比较混乱。Mixin模式是一种简单有效的功能组合方式。实现的方法是: 每个类实现单一的功能，然后利用多继承机制，将单一功能组合起来，实现一个新类。 先看下代码 123456789101112class AMixin: def getA(): return &quot;a&quot; class BMixin: def getB(): return &quot;b&quot; class C(AMixin, BMixin): passc = C()c.getA()c.getB() mixin模式好处是可以简化继承树，使结构更加清楚。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"读书篇-learning python","date":"2017-05-11T06:48:38.000Z","path":"2017/05/11/读书篇-learning-python/","text":"21章 模块概览该章主要讲解了模块的各种概念以及运行原理，很值得一看。 22章 模块编码基础该章讲解了代码层面的模块 23章 包32章 高级类主题扩展内置类型讲解通过内嵌和子类的方式来扩展内置类型。 新式类模型引入新式类，之后重点讲解新式类与传统类的不同点。 在python2.2之后包含了一种新式类，3.x里类得到了统一，都是新式类。 12345class C: # classic class ... class C(object): # new-style class ... 不同点: __getattr__和__getattribute__不支持隐式的内置属性的访问 对于内建类型属性的获取跳过实例，从类开始 原因: 为了效率考虑，对于内建类型的访问直接从类开始，省去了从实例搜索的步骤 从整个模型的一致性考虑，类是元类的实例，实例是类的实例。元类可以定义自己的内建属性来处理类，类可以定义自己的内建属性来处理实例。 影响: 基于委托模式实现的代码 解决方案: 即实现__getattr__为了正常属性的访问，也实现那些需要访问的内建属性 123456class C: def __getitem(self, i): ... c = C()c[&quot;name&quot;] # 在传统类中等价于c.__getitem__(&quot;name&quot;),在新式类中等价于C.__getitem__(c, &quot;name&quot;) type模型的改变: class是type的实例，它的类型是type。实例是class的实例，它的类型是class 12345class C: passprint(type(C), type(C())) # (&lt;type &apos;classobj&apos;&gt;, &lt;type &apos;instance&apos;&gt;)class C(object): passprint(type(C), type(C())) # (&lt;type &apos;type&apos;&gt;, &lt;class &apos;__main__.C&apos;&gt;) 所有的类派生自object 传统类的搜索方式: 深度优先，从左到右，简称DFLR 新式类的搜索方式: 广度优先，从左到右，简称MBR 123456789101112131415class A: attr = 1class B(A): passclass C(A): attr = 2class D(B, C): passx = D()x.attr # search order: x D B A Cclass A(object): attr = 1class B(A): passclass C(A): attr = 2class D(B, C): passx = D()x.attr # search order: x D B C A","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-tornado之concurrent","date":"2017-05-10T10:03:02.000Z","path":"2017/05/10/理论篇-tornado之concurrent/","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#### ioloop.py ####class IOLoop(Configurable): passclass PollIOLoop(IOLoop): def start(self): while True: event_pairs = self._impl.poll(poll_timeout) # 1 self._events.update(event_pairs) while self._events: fd, events = self._events.popitem() fd_obj, handler_func = self._handlers[fd] # 2 handler_func(fd_obj, events) # 3 这里执行的回调函数通过add_handler方法设置 def add_handler(self, fd, handler, events): fd, obj = self.split_fd(fd) self._handlers[fd] = (obj, stack_context.wrap(handler)) self._impl.register(fd, events | self.ERROR) #### iostream.py ####class BaseIOStream(object): def __init__(self, io_loop=None, max_buffer_size=None, read_chunk_size=None, max_write_buffer_size=None): pass def _handle_events(self, fd, events): # 处理读写事件, 我们只关注读事件 if events &amp; self.io_loop.READ: self._handle_read() # 5 对读事件进行处理 def _handle_read(self): pos = self._read_to_buffer_loop() # 6 将数据从fd读到读缓冲区 self._read_from_buffer(pos) # 7 从读缓冲区读取数据并调用预先设置好的回调函数 def _read_from_buffer(self, pos): self._run_read_callback(pos, False) # 8 运行回调函数 def _run_read_callback(self, pos, streaming): callback = self._read_callback callback(*args) # 9 真正执行回调函数 # 解析http协议时需要用到的几种读取方法 def read_until_regex(self, regex, callback=None, max_bytes=None): future = self._set_read_callback(callback) def read_until(self, delimiter, callback=None, max_bytes=None): future = self._set_read_callback(callback) def read_bytes(self, num_bytes, callback=None, streaming_callback=None, partial=False): future = self._set_read_callback(callback) def read_until_close(self, callback=None, streaming_callback=None): future = self._set_read_callback(callback) def _set_read_callback(self, callback): self._read_callback = stack_context.wrap(callback) # 预先设置9中执行的回调函数 def _add_io_state(self, state): self.io_loop.add_handler(self.fileno(), self._handle_events, self._state) # 4 调用add_handler方法设置fd对应的handler 12345678910#### httpserver.py ####class HTTPServer(TCPServer, Configurable, httputil.HTTPServerConnectionDelegate): def handle_stream(self, stream, address): context = _HTTPRequestContext(stream, address, self.protocol, self.trusted_downstream) conn = HTTP1ServerConnection( stream, self.conn_params, context) self._connections.add(conn) conn.start_serving(self) 12345678910111213141516171819202122232425262728293031323334353637383940#### web.py ####class RequestHandler(object): SUPPORTED_METHODS = (&quot;GET&quot;, &quot;HEAD&quot;, &quot;POST&quot;, &quot;DELETE&quot;, &quot;PATCH&quot;, &quot;PUT&quot;, &quot;OPTIONS&quot;) def head(self, *args, **kwargs): raise HTTPError(405) def get(self, *args, **kwargs): raise HTTPError(405) def post(self, *args, **kwargs): raise HTTPError(405) def delete(self, *args, **kwargs): raise HTTPError(405) def patch(self, *args, **kwargs): raise HTTPError(405) def put(self, *args, **kwargs): raise HTTPError(405) def options(self, *args, **kwargs): raise HTTPError(405) @gen.coroutine def _execute(self, transforms, *args, **kwargs): method = getattr(self, self.request.method.lower()) result = method(*self.path_args, **self.path_kwargs) result = yield result class _HandlerDelegate(httputil.HTTPMessageDelegate): def headers_received(self, start_line, headers): pass def def data_received(self, data): pass def finish(self): self.request.body = b&apos;&apos;.join(self.chunks) self.request._parse_body() self.execute() def execute(self): self.handler = self.handler_class(self.application, self.request, **self.handler_kwargs) self.handler._execute(transforms, *self.path_args, **self.path_kwargs) 12345678910111213141516171819202122232425262728293031323334#### http1connection.py ####class HTTP1Connection(httputil.HTTPConnection): def read_response(self, delegate): return self._read_message(delegate) # 解析http协议 @gen.coroutine def _read_message(self, delegate): # 读取header body等 self.stream.read_until_regex() header_future = delegate.headers_received(start_line, headers) elegate.finish() class HTTP1ServerConnection(object): def start_serving(self, delegate): self._serving_future = self._server_request_loop(delegate) self.stream.io_loop.add_future(self._serving_future, lambda f: f.result()) @gen.coroutine def _server_request_loop(self, delegate): try: while True: conn = HTTP1Connection(self.stream, False, self.params, self.context) request_delegate = delegate.start_request(self, conn) ret = yield conn.read_response(request_delegate) if not ret: return yield gen.moment finally: delegate.on_close(self)","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之gen","date":"2017-05-10T06:09:40.000Z","path":"2017/05/10/理论篇-tornado之gen/","text":"tornado.gen是一个基于生成器的接口，使开发在异步环境下更加容易。简单点说就是，该包是一个协程的实现。 仔细对比如下两段代码 12345678910111213141516171819202122232425262728class AsyncHandler(RequestHandler): @asynchronous def get(self): http_client = AsynchHTTPClient() http_client.fetch(&quot;http://example.com&quot;, callback=self.on_fetch) def on_fetch(self, response): do_something_with_response(response) self.render(&quot;template.html&quot;) class GenAsyncHandler(RequestHandler): @gen.coroutine def get(self): http_client = AsyncHTTPClient() response = yield http_client.fetch(&quot;http://example.com&quot;) do_something_with_response(response) self.render(&quot;template.html&quot;) @gen.coroutine def get(self): http_client = AsyncHTTPClient() response1, response2 = yield [http_client.fetch(url1), http_client.fetch(url2)] response_dict = yield dict(response3=http_client.fetch(url3), response4=http_client.fetch(url4)) response3 = response_dict[&apos;response3&apos;] response4 = response_dict[&apos;response4&apos;] 提供的接口 接口 功能 特殊说明 coroutine(func, replace_callback=True) 异步生成器的装饰器 engine(func) 基于回调的异步生成器的装饰器 Return(value=None) 特殊的异常，从coroutine中返回一个值 with_timeout(timeout, future, io_loop=None, quiet_exceptions=()) 为future设置超时时间 exception TimeoutError sleep(duration) 非阻塞的睡眠 monent 允许被yield的一个特殊对象，为了让IOLoop执行一个迭代 WaitIterator(*args, **kwargs) multi(children, quiet_exceptions=()) 允许多个异步操作并行执行 multi_future(children, quite_exception=()) Task(func, *args, **kwargs) 调整一个基于回调的异步函数，为了在协程中使用 class Arguments covert_yielded(yielded) 将一个yield对象转换为Future maybe_future(x) 转换x为Future is_coroutine_function(func) 检测函数是否是协程函数 预备知识在看tornado代码之前，先了解下python里的生成器是怎么样的。 1234567891011121314151617def f(): count = 0 while True: res = yield count, &quot;xxx&quot; print(res) if res == &quot;quit&quot;: break count += 1 yield &quot;quit&quot;g = f()print(g.next())print(g.send(&quot;xxx&quot;))print(g.send(&quot;xxx&quot;))print(g.send(&quot;quit&quot;)) 源码分析123456789101112131415161718192021222324252627282930313233343536373839def coroutine(func, replace_callback=True): return _make_coroutine_wrapper(func, replace_callback=True)_futures_to_runners = weakref.WeakKeyDictionary()def _make_coroutine_wrapper(func, replace_callback): ... wrapped = func @functools.wraps(wrapped) def wrapper(*args, **kwargs): ... try: result = func(*args, **kwargs) # 执行被包装的函数, 返回一个生成器result except (Return, StopIteration) as e: result = _value_from_stopiteration(e) except Exception: future.set_exc_info(sys.exc_info()) return future else: if (result, GeneratorType): try: ... yielded = next(result) ... except (StopIteration, Return) as e: future.set_result(_value_from_stopiteration(e)) except Exception: future.set_exc_info(sys.exc_info()) else: _futures_to_runners[future] = Runner(result, future, yielded) # 将生成器result传入Runner yielded = None try: return future finally: future = None future.set_result(result) return future ... return wrapper 看下Runner 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Runner(object): def __init__(self, gen, result_future, first_yielded): self.gen = gen self.result_future = result_future self.future = _null_future self.yield_point = None self.pending_callbacks = None self.results = None self.running = False self.finished = False self.had_exception = False self.io_loop = IOLoop.current() self.stack_context_deactivate = None if self.handle_yield(first_yielded): gen = result_future = first_yielded = None self.run() def run(self): # starts or resumes the generator, running until it reaches a yield point that is not ready. if self.running or self.finished: return try: self.running = True while True: future = self.future if not future.done: return self.future = None try: orig_stack_contexts = stack_context._state.contexts exc_info = None try: value = future.result() except Exception: self.had_exception = True exc_info = sys.exc_info() future = None if exc_info is not None: try: yielded = self.gen.throw(*exc_info) finally: exc_info = None else: yielded = self.gen.send(value) # 重点, resume生成器 ... except (StopIteration, Return) as e: ... return except Exception: ... return if not self.handle_yield(yielded): return yielded = None finally: self.running = False def handle_yield(self, yielded): pass","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之httpserver","date":"2017-05-10T01:50:07.000Z","path":"2017/05/10/理论篇-tornado之httpserver/","text":"一个非阻塞的单线程的HTTP服务器。 数据结构123456789101112131415161718192021222324252627282930313233343536373839404142class HTTPServer(TcpServer, Configurable, httputil.HTTPServerConnectionDelegate): def __init__(self, *args, **kwargs): pass def initialize( self, request_callback, no_keep_alive=False, io_loop=None, xheaders=False, ssl_options=None, protocol=None, decompress_request=False, chunk_size=None, max_header_size=None, idle_connection_timeout=None, body_timeout=None, max_body_size=None, max_buffer_size=None, trusted_downstream=None): self.request_callback = request_callback self.no_keep_alive = no_keep_alive self.xheaders = xheaders self.protocol = protocol self.conn_params = HTTP1ConnectionParameters( decompress = decompress_request, chunk_size = chunk_size, max_header_size = max_header_size, header_timeout=idle_connection_timeout or 3600, max_body_size = max_body_size, body_timeout = body_timeout, no_keep_alive = no_keep_alive ) TCPServer.__init__( self, io_loop = io_loop, ssl_options = ssl_options, max_buffer_size = max_buffer_size, read_chunk_size = chunk_size ) self._connections = set() self.trusted_downstream = trsuted_downstream","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之netutil","date":"2017-05-10T01:07:26.000Z","path":"2017/05/10/理论篇-tornado之netutil/","text":"网络工具包 函数 功能 特别说明 bind_sockets(port, address=None, family=, backlog=128, flags=None, reuse_port=Flase) 创建监听socket bind_unix_socket(file, mode=384, backlog=128) 创建一个监听的unix socket add_accept_handler(sock, callback, io_loop=None) 增加一个IOLoop的事件处理器来接收新的连接 is_valid_ip(ip) 检测ip地址合法性 Resolver 异步dns解析接口","tags":[]},{"title":"理论篇-tornado之iostream","date":"2017-05-09T12:52:50.000Z","path":"2017/05/09/理论篇-tornado之iostream/","text":"BaseIOStream数据结构1234567891011121314151617181920212223242526272829303132333435class BaseIOStream(object): def __init__(self, io_loop=None, max_buffer_size=None, read_chunk_size=None, max_write_buffer_size=None): self.io_loop = io_loop or ioloop.IOLoop.current() self.max_buffer_size = max_buffer_size or 104857600 #100MB self.read_chunk_size = min(read_chunk_size or 65536, self.max_buffer_size // 2) self.max_write_buffer_size = max_write_buffer_size self.error = None self.read_buffer = bytearray() self._read_buffer_pos = 0 self._read_buffer_size = 0 # 已经读取的数据的大小 self._write_buffer = bytearray() self._write_buffer_pos = 0 self._write_buffer_size = 0 self._write_buffer_frozen = False self._total_write_index = 0 self._total_write_done_index = 0 self._pending_writes_while_frozen = [] self._read_delimiter = None self._read_regex = None self._read_max_bytes = None self._read_bytes = None self._read_partial = False self._read_until_close = False self._read_callback = None self._read_future = None self._streaming_callback = None self._write_callback = None self._write_futures = collections.deque() self._close_callback = None self._connect_callback = None self._connect_future = None self._connecting = False self._state = None self._pending_callbacks = 0 self._closed = False 接口 接口 功能 特别说明 write(data, callback=None) read_bytes(num_bytes, callback=None, streaming_callback=None, partial=False) read_util(delimiter, callback=None, max_bytes=None) read_until_regex(regex, callback=None, max_bytes=None) read_until_close(callback=None, streaming_callback=None) close(exc_info=False) set_close_callback(callback) closed() reading() writing() set_nodelay() fileno() close_fd() write_to_fd(data) read_from_fd() get_fd_error() IOStreamsocket的读写接口 数据结构12345class IOStream(BaseIOStream): def __init__(self, socket, *args, **kargs): self.socket = socket self.socket.setblocking(False) super(IOStream, self).__init__(*args, **kargs) 接口 接口 功能 特别说明 connect(address, callback=None, server_hostname=None) SSLIOStreamPipeIOStream","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之tcpserver","date":"2017-05-09T12:18:19.000Z","path":"2017/05/09/理论篇-tornado之tcpserver/","text":"数据结构12345678910class TCPServer(object): def __init__(self, io_loop=None, ssl_options=None, max_buffer_size=None, read_chunk_size=None): self.io_loop = io_loop self.ssl_options = ssl_options self._sockets = &#123;&#125; # fd-&gt;socket object self._pending_sockets = [] self._started = False self._stoped = False self.max_buffer_size = max_buffer_size self.read_chunk_size = read_chunk_size 提供的方法 方法 功能 特别说明 listen(port, address=’’) add_sockets(sockets) add_socket(socket) bind(port, address=None, family=, backlog=128, reuse_port=False) start(num_processs=1) stop() handle_stream(stream, address) 处理某一连接上的新的IO流 该方法需要子类实现 TCPServer有以下几种初始化方式 listen: 简单的单进程 123server = TCPServer()server.listen(8888)IOLoop.current().start() bind/start: 简单的多进程 1234server = TCPServer()server.bind(8888)server.start(0) # fork processesIOLoop.current().start() add_sockets: 高级的多进程 12345sockets = bind_socket(8888)tornado.process.fork_processes(0) # fork processesserver = TCPServer()server.add_sockets(sockets)IOLoop.current().start() 使用12345678910111213from tornado.tcpserver import TCPServerfrom tornado.iostream import StreamClosedErrorfrom tornado import genclass EchoServer(TCPServer): @gen.coroutine def handle_stream(self, stream, address): while True: try: data = yield stream.read_until(b&quot;\\n&quot;) yield stream.write(data) except StreamClosedError: break","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之概览","date":"2017-05-09T11:37:58.000Z","path":"2017/05/09/理论篇-tornado之概览/","text":"异步和非阻塞IO实时的web功能需要每个用户与服务器保持一个长连接，对于服务器来说，大部分连接是处于空转状态的。传统的同步模式的web服务器需要使用一个线程来服务一个连接。 为了最小化并发连接的数量，tornado使用了一个单线程的事件循环。这对编程来说是一个很大的挑战，需要让所有的操作保持异步和非阻塞。因为同一时间只能有一个操作执行，若该操作阻塞，其他操作也将被阻塞，整个服务处于不可用状态。 异步与非阻塞是相关的，但是不是一个事情。现实中，这两个概念经常被混用，下面我们区分一下。 阻塞当一个函数返回之前一直再等待一些事情的发生我们就说该函数被阻塞了。一般用来描述操作系统提供的接口，比如read write等 异步一个函数在完成之前就返回，通常会在触发后续操作之前在后台执行一些其他操作。这个概念不好理解，我们举个例子。比如发起一个网络请求，同步模式下，该函数发起一个请求，然后一直等待，直到返回结果，然后对结果进行处理，返回给调用者。异步模式下，该函数发起一个请求，并注册一个回调函数，然后返回，等请求返回结果的时候，会自动触发回调函数的执行。异步需要一些底层机制的支持才能实现。一般用来描述完成一件事的两种不用的方式。 实现异步接口的方式有如下几种: 回调参数 返回一个占位符 发送到队列 回调注册(比如POSIX signals) 如果还是不明白，仔细体会下面的代码: 123456789101112131415161718192021222324252627282930313233343536# 同步模式from tornado.httpclient import HTTPClientdef synchronous_fetch(url): http_client = HTTPClient() response = http_client.fetch(url) return response.body # 异步模式from tornado.httpclient import AsyncHTTPClientdef asynchronous_fetch(url): http_client = AsynchHTTPClient() def handle_response(response): callback(response.body) http_client.fetch(url, callback=handler_response) # 使用协程实现的以写同步代码的方式实现异步from tornado.concurrent import Futuredef async_fetch_future(url): http_client = AsyncHTTPClient() my_future = Future() fetch_future = http_client.fetch(url) fetch_future.add_done_callback( lambda f: my_future.set_result(f.result()) ) return my_future from tornado import gen@gen.coroutinedef fetch_coroutine(url): http_client = AysnchHTTPClient() response = yield http_client.fetch(url) raise gen.Return(response.body) 备注:”raise gen.Return(response.body)”是python2的一个特有实现。原因是在python2里生成器不允许返回值，为了让生成器返回值，tornado的协程触发一个叫做Return的异常，协程捕获到该异常后，将其作为一个返回值。在3.3之后，”return response.body”获得同样的结果。 协程协程使用python里的yield关键字来挂起和恢复执行序列，从而替代了回调链。协程像同步代码一样简单，并且不像线程代价巨大(比如上下文切换)。 python3.5新特性: async和await框架异步网络 tornado.ioloop 主要的事件循环 tornado.iostream 读写接口的封装 tornado.netutil 网络相关工具 tornado.tcpclient tcp客户端 tornado.tcpserver tcp服务器 HTTP服务器和客户端 tornado.httpserver 非阻塞的HTTP服务器 tornado.httpclient 阻塞的HTTP客户端 tornado.httputil 操作HTTP headers和urls tornado.http1connection HTTP/1.x 客户端和服务器实现 协程和并发 tornado.gen 简化异步代码 tornado.concurrent 使用threads和futures工作 tornado.locks 同步原语 tornado.queues 协程队列 tornado.process 多进程工具","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"理论篇-tornado之ioloop","date":"2017-05-09T09:26:43.000Z","path":"2017/05/09/理论篇-tornado之ioloop/","text":"tornado.ioloop是tornado的主事件循环。 IOLoop提供的接口 接口 功能 特别说明 static current() 返回当前线程的IOLoop实例 make_current() 将当前IOLoop实例标记为当前线程的 static instance() 创建并返回一个新的IOLoop实例 使用了线程锁,防止并发 static initialized() 检查实例是否被创建 install() 安装IOLoop实例为单例 在IOLoop的子类里使用 static clear_instance() 清除全局的IOLoop实例 start() 开始事件循环 未实现 stop() 停止事件循环 未实现 run_sync(func, timeout=None) 运行一个给定的函数 close(all_fds=False) 关闭IOLoop, 释放所有的资源 add_handler(fd, handler, events) 注册接收fd事件的处理器 未实现 update_handler(fd, events) 改变fd的监听事件 未实现 remove_handler(fd) 停止监听fd的事件 未实现 add_callback(callback, *args, **kargs) 增加回调函数 add_callback_from_signal(callback, *args, **kargs) add_future(future, callback) add_timeout(deadline, callback, *args, **kargs) call_at(when, callback, *args, **kargs) call_later(delay, callback, *args, **kargs) remove_timeout(timeout) spawn_callback(callback, *args, **kargs) 适用于不关心返回值的回调 time() 返回当前时间 PeriodicCallback(callback, callback_time, io_loop=None) 周期性的调用回调函数 1234567891011class IOLoop(): _instance_lock = threading.Lock() _current = threading.local() @staticmethod def instance(): if not hasattr(IOLoop, &quot;_instance&quot;): with IOLoop._instance_lock: if not hasattr(IOLoop, &quot;_instance&quot;): IOLoop.__instance = IOLoop() return IOLoop._instance","tags":[{"name":"tornado","slug":"tornado","permalink":"http://yoursite.com/tags/tornado/"}]},{"title":"实战篇-tornado之使用","date":"2017-05-09T09:22:25.000Z","path":"2017/05/09/实战篇-tornado之使用/","text":"","tags":[]},{"title":"理论篇-python之遍历","date":"2017-05-09T05:29:10.000Z","path":"2017/05/09/理论篇-python之遍历/","text":"python为我们提供了两种遍历对象的协议: 1. 索引协议 2. 迭代协议 索引协议: 迭代协议: 12for temp in xxx: do something 当我们使用for循环遍历某一个对象时，python的处理过程如下: 寻找迭代协议的实现 若没有找到迭代协议的实现，则寻找索引协议的实现 若没有找到索引协议的实现，则报错 迭代协议的实现当一个对象实现了__iter__和next方法，我们就说这个对象实现了迭代协议。 12345678910111213141516171819class OperatorOverloadTest: def __init__(self, val_l): self.val_l = val_l def __iter__(self): self._index = 0 return self def next(self): if self._index == len(self.val_l): raise StopIteration temp = self.val_l[self._index] self._index += 1 return temp l = [temp for temp in &quot;abcdefghijklmnopqrstuvwxyz&quot;]oot = OperatorOverloadTest(l)for temp in oot: print temp 索引协议的实现当一个对象实现了__getitem__和__settiem__方法，我们就说这个对象实现了索引协议。 1234567891011121314class OperatorOverloadTest: def __init__(self, val_l): self.val_l = val_l def __getitem__(self, index): return self.val_l[index] def __setitem__(self, index, value): self.val_l[index] = value l = [temp for temp in &quot;abcdefghijklmnopqrstuvwxyz&quot;]oot = OperatorOverloadTest(l)for temp in oot: print temp 两个协议都实现了当我们两个协议都实现了的情况下，python又是怎么处理的呢？ 123456789101112131415161718192021222324252627class OperatorOverloadTest: def __init__(self, val_l): self.val_l = val_l def __iter__(self): print(&quot;__iter__&quot;) self._index = 0 return self def next(self): if self._index == len(self.val_l): raise StopIteration temp = self.val_l[self._index] self._index += 1 return temp def __getitem__(self, index): print(&quot;__getitem__&quot;) return self.val_l[index] def __setitem__(self, index, value): self.val_l[index] = value l = [temp for temp in &quot;abcdefghijklmnopqrstuvwxyz&quot;]oot = OperatorOverloadTest(l)for temp in oot: print temp 运行上面的测试用例可以看到，python实际使用的是迭代协议的实现。 进阶篇迭代协议实现的问题当我们对实现迭代协议的对象进行多次遍历时，会出现什么情况呢？结果是只有第一次遍历有结果，其他的遍历都没有任何结果。该问题的解决方案是__iter__返回一个实现迭代协议的对象。 123456789101112131415161718192021222324252627class OperatorOverloadTest: def __init__(self, val_l): self.val_l = val_l def __iter__(self): return OperatorOverloadTest.MyIterator(self.val_l) class MyIterator: def __init__(self, wrapped): self.wrapped = wrapped self._index = 0 def next(self): if self._index == len(self.wrapped): raise StopIteration temp = self.wrapped[self._index] self._index += 1 return temp l = [temp for temp in &quot;abcdefghijklmnopqrstuvwxyz&quot;]oot = OperatorOverloadTest(l)for temp in oot: print temp,print for temp in oot: print temp, 扩展篇对于in操作，python提供了三种方式: 1. __contains__ 2. 迭代协议 3. 索引协议 当我们使用in运算符时，python的处理过程如下: 寻找__contains__的实现 若没有找到__contains__的实现，则寻找迭代协议的实现 若没有找到迭代协议的实现，则寻找索引协议的实现 若没有找到索引协议的实现，则报错","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python之命名空间","date":"2017-05-08T12:47:12.000Z","path":"2017/05/08/理论篇-python之命名空间/","text":"global与nonlocal nonlocal是3.0以后加入的 global是全局的变量 nonlocal是非本地的最近的一个作用域内的变量(待验证) 12345678910111213141516171819202122232425# 2.xx = 1def f(): x = 10 def g(): global x x += 1 print(x) return gf()()# 3.xx = 1def f(): x = 10 def g(): nonlocal x x += 1 print(x) return gf()() 个人感悟 命名空间本质是字典 实例有实例的命名空间，类有类的命名空间","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python之类","date":"2017-05-07T06:34:15.000Z","path":"2017/05/07/理论篇-python之类/","text":"类 By and large, OOP is about looking up attributes in trees with a special first argument in functions. design patterns, common OOP structures 类声明是在类所在的模块文件被加载时执行的。 继承树的结构与类声明时父类出现的顺序有关，属性的查找顺序是由下至上，从左到右。 运算符重载函数(比如__init__)不是内建函数或保留字，它们仅是当对象出现在各种上下文时python寻找的属性。运算符重载应该与内置运算符实现工作一致。 命名空间对象的属性通常使用字典实现，类继承树仅仅是链接到其他字典的字典。 类的主要特性: class语句创建了一个class对象，并且分配了一个名字 class内的赋值语句创造了类属性 类属性提供了对象状态和行为 实例的主要特性: 像函数一样调用类对象将创建一个实例 每个实例对象继承了类属性并得到了自己的命名空间 方法里对self属性的赋值创造了每个实例的属性 继承的关键点: 超类写在class语句的括号里 类继承它们超类的属性 实例从所有可访问的类中继承属性 每个属性的引用将触发一个新的独立的搜索 子类里的实现不会影响到父类 运算符重载的关键点: 带有双下划线的方法名是特殊的钩子(python定义了一个固定的操作符到特殊方法名之间的映射关系) 当实例出现在内建的操作中时，相应的操作被自动调用 类可以覆盖大多数内建类型的操作 There are no defaults for operator overloading methods, and none are required. New-style classes have some defaults, but not for common operations. Operations allow classes to integrate with Python’s object model. 私有方法或变量单下划线开头的变量或方法只是一种约定，双下划线开头的变量或方法会将类信息加入到函数名中，是一种真正的私有化。 1234_name_method # 约定__name__method # 等价于class_name class_method 静态方法和类方法静态方法主要用来操作类属性。 类方法主要用来处理各自类的属性。 12345678910111213class C(object): @staticmethod def test(name): # 静态方法 3.0中不再需要staticmethod装饰器 print(name) C.test(&quot;xxx&quot;)3.xclass C(object): def test(name): # 3.x中不再需要staticmethod print(name) C.test(&quot;xxx&quot;) 12345678910class A(object): count = 0 # 创建的实例个数 class B(A): count = 0 # 创建的实例个数 class C(B): count = 0 # 创建的实例个数 # 统计各个类创建的实例个数(提示:通过类方法) 方法的两种调用方式: 绑定与未绑定类中的方法有两种调用方法:1. 绑定实例调用 2. 未绑定实例调用 12345678910111213141516171819202122class C: def test(self, name): print(name) c = C()x = c.testx(&quot;xxx&quot;) # 绑定实例调用x = C.testx(c, &quot;xxx&quot;) # 未绑定实例调用3.x中取消了未绑定方法，统一为函数:class C: def test1(self, name): print(name) def test2(name): print(name) c = C()C.test2(&quot;xxx&quot;) # 函数调用 fail in 2.6 抽象超类抽象超类的含义如下: 1234567891011121314151617class Super: # Super是抽象超类 def method(self): print(&quot;in Super.method&quot;) def delegate(self): self.action() # expected to be defined def action(self): #assert False, &quot;action must be defined&quot; raise NotImplementedError(&quot;action must be defined&quot;) class Provider(Super): def action(self): print(&quot;in Provider.action&quot;)p = Provider()p.delegate() python提供的抽象超类的定义: 1234567891011121314151617181920# 2.6from abc import ABCMeta, abstractmethodclass Super(): __metaclass__ = ABCMeta @abstractmethod def method(self): passs = Super()# 3.0from abc import ABCMeta, abstractmethodclass Super(metaclass = ABCMeta): @abstractmethod def method(self): passs = Super() 1234567891011121314151617181920# 属性class T(): a = &quot;hello&quot; # 类属性 def setB(self, b): self.b = b # 实例属性 # 方法 instance.method(args...) == class.method(instance, args...)# 子类调用父类的构造函数class Super: def __init__(self, x): self.x = xclass Sub(Super): def __init__(self, x, y): Super.__init__(self, x) self.y = yx = Sub(1, 2) 123456789101112131415161718192021222324# 使用自省机制实现通用的功能class AttrDisplay: def gatherAttrs(self): attrs = [] for key in sorted(self.__dict__): attrs.append(&quot;%s=%s&quot; % (key, getattr(self, key))) return &apos;, &apos;.join(attrs) def __str__(self): return &quot;[%s: %s]&quot; % (self.__class__.__name__, self.gatherAttrs())if __name__ == &quot;__main__&quot;: class TopTest(AttrDisplay): count = 0 def __init__(self): self.attr1 = TopTest.count self.attr2 = TopTest.count + 1 TopTest.count += 2 class SubTest(TopTest): pass x, y = TopTest(), SubTest() print(x) print(y) 旧式类12class C: # classic class ... 传统类的搜索方式: 深度优先，从左到右，简称DFLR 新式类在python2.2之后包含了一种新式类，3.x里类得到了统一，都是新式类。 12class C(object): # new-style class ... 不同点: __getattr__和__getattribute__不支持隐式的内置属性的访问 对于内建类型属性的获取跳过实例，从类开始 原因: 为了效率考虑，对于内建类型的访问直接从类开始，省去了从实例搜索的步骤 从整个模型的一致性考虑，类是元类的实例，实例是类的实例。元类可以定义自己的内建属性来处理类，类可以定义自己的内建属性来处理实例。 影响: 基于委托模式实现的代码 解决方案: 即实现__getattr__为了正常属性的访问，也实现那些需要访问的内建属性 123456class C: def __getitem(self, i): ... c = C()c[&quot;name&quot;] # 在传统类中等价于c.__getitem__(&quot;name&quot;),在新式类中等价于C.__getitem__(c, &quot;name&quot;) type模型的改变: class是type的实例，它的类型是type。实例是class的实例，它的类型是class 12345class C: passprint(type(C), type(C())) # (&lt;type &apos;classobj&apos;&gt;, &lt;type &apos;instance&apos;&gt;)class C(object): passprint(type(C), type(C())) # (&lt;type &apos;type&apos;&gt;, &lt;class &apos;__main__.C&apos;&gt;) 所有的类派生自object 传统类的搜索方式: 深度优先，从左到右，简称DFLR 新式类的搜索方式: 广度优先，从左到右，简称MBR 123456789101112131415class A: attr = 1class B(A): passclass C(A): attr = 2class D(B, C): passx = D()x.attr # search order: x D B A Cclass A(object): attr = 1class B(A): passclass C(A): attr = 2class D(B, C): passx = D()x.attr # search order: x D B C A 新式类的扩展功能slots该功能可以优化内存和访问速度。 拥有__slots__属性的类默认没有__dict__属性，其他基于__dict__属性的方法使用__slots__代替。 123456789101112class Person(object): __slots__ = [&apos;name&apos;, &apos;age&apos;, &apos;job&apos;] # 限制实例拥有的属性p = Person()p.sex = &quot;xxx&quot; # error # 增加__dict__class Person(object): __slots__ = [&apos;name&apos;, &apos;age&apos;, &apos;job&apos;, &apos;__dict__&apos;] p = Person()p.sex = &quot;xxx&quot; # ok 备注: 只能限制实例属性，不能限制类属性 个人感悟 类的本质是字典 方法调用的本质是类作用域下的函数的调用 点号引用变量会触发python的树搜索机制 python中的类只是通过class关键字声明了一个类对象。通过类对象可以创建实例对象。类对象和实例对象本质都是命名空间。通过树搜索机制实现继承，通过内部的分发机制实现运算符重载。 待研究python中，type继承自object，object继承自type，尽管这两个是两个不同的对象。type是生成class的类型。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-python之装饰器","date":"2017-05-05T12:47:09.000Z","path":"2017/05/05/理论篇-python之装饰器/","text":"装饰器装饰器提供了一种插入自动运行代码(在函数和类定义完成之后)的方法。python里面装饰器有两种: 1.函数装饰器 2.类装饰器。装饰器共有两种用途: 1. 管理函数调用和实例创建 2. 管理函数和类 装饰器使代码更易维护和美观，如果不使用装饰器，这些功能也可实现。 函数装饰器函数装饰器:装饰函数的装饰器 函数装饰器其本质是在函数定义完成之后自动运行另一个函数，把原函数重新绑定到其他可调用对象上。主要用途: 1. 装饰函数或方法, 2. 管理函数。 1234567891011121314151617181920212223242526272829303132333435# 管理函数def decorator(F): # process functions F return F@decoratordef func(): ... # func = decorator(func)# 管理函数调用def decorator(F): # save or use function F # return a different callable: nested def, class with __call__ etc def wrapper(*args): # use F and args # F(*args) calls original function return wrapper @decoratordef func(x, y): ...func(6, 7)本质: func = decorator(func) 此时func指向wrapper。class decorator: def __init__(self, f): self.f = f def __call__(self, *args): self.f(*args) @decoratordef func(x, y): ...func(6, 7)本质: func = decorator(func) 此时func是decorator的一个实例，该实例又是可被调用的 类装饰器类装饰器:装饰类的装饰器主要用途: 1. 管理实例的创建 2. 管理类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 管理类def decorator(C): # process class C return C @decoratorclass C: ... # C = decorator(C)# 管理实例创建def decorator(C): # save or use class C # return a different callable: nested def, class with __call__ etc@decoratorclass C: ... # C = decorator(C)def decorator(cls): class Wrapper: def __init__(self, *args): self.wrapped = cls(*args) def __getattr__(self, name): return getattr(self.wrapped, name) return Wrapper@decoratorclass C: def __init__(self, x, y): self.attr = &apos;spam&apos;c = C(6, 7)print(c.attr)#有问题的写法class Decorator: def __init__(self, C): self.C = C def __call__(self, *args): self.wrapped = self.C(*args) return self def __getattr__(self, attrname): return getattr(self.wrapped, attrname)@Decoratorclass C: ...x = C()y = C() 装饰器嵌套1234567891011121314@A@B@Cdef f(): passf = A(B(C(f)))@A@Bclass C: pass C = A(B(C)) 装饰器参数本质是首先执行一个函数，该函数返回一个装饰器。 12345678910111213141516def decorator(A, B): # save or use A, B def actualDecorator(F): # save or use function F # return a callable, nested def, class with __call__ etc return callable return actualDecorator @decorator(A, B)def F(arg): ...等价于F = decorator(A, B)(F) F(99) 保持状态信息的地方 类实例属性 全局作用域 封闭作用域 nonlocal(3.x) 函数属性 待深究 使用描述符装饰方法(38章 类错误之一:装饰类方法) 函数装饰器VS类装饰器仔细分析一下代码，一个retry是类装饰器，一个是函数装饰器，都能成功吗？为什么？ 结论: 基于函数的装饰器既可以装饰函数也可以装饰方法，基于类的装饰器只能装饰函数 123456789101112131415161718192021222324252627282930313233343536373839class retry(): def __init__(self, f): print(&quot;init before&quot;) self.f = f print(&quot;init after&quot;) def __call__(self, *args): print(&quot;call before&quot;) self.f(*args) print(&quot;call after&quot;)#def retry(f):# def _f(*args):# f(*args)# return _f@retrydef f(x, y): print(&quot;function:x + y = %s&quot; % (x+y))class T: @retry def f(self, x, y): print(&quot;method:x + y = %s&quot; % (x+y))f(1, 2)f(2, 3)t = T()t.f(1, 2)t.f(2, 3)# 给点提示def f2(x, *args): print(len(args))f2(1)f2(1, 2)f2(1, 2, 3) 进阶篇使用装饰器有很多优点，但是也带来了一个很让人头痛的问题，就是debug。比如看下面的代码 123456789101112131415161718def decorator(func): #@wraps(func) def _wrapper(*args): func(*args) #_wrapper.__name__ = func.__name__ return _wrapper@decoratordef f(): print(&quot;hello world&quot;)print(f.__name__)----output----1. 不使用装饰器的情况下，输出f2. 使用装饰器的情况下，输出_wrapper3. 使用@wraps的情况下，输出fwraps将被包装函数的属性赋值给了包装函数，给调试带来了便利。 注意点 装饰器只执行一次，在函数或类定义的时候，记住不是调用的时候 装饰函数的装饰器是函数装饰器，装饰类的装饰器是类装饰器。函数和类装饰器有两种形式:基于函数的装饰器和基于类的装饰器 装饰器的本质是接收一个被包装的函数，返回一个接收参数的可调用对象。 带参数的装饰器的本质是首先执行一个函数，然后返回一个装饰器","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"理论篇-操作系统中的各种技术","date":"2017-05-05T01:56:07.000Z","path":"2017/05/05/理论篇-操作系统中的各种技术/","text":"COWCOW(copy on write)翻译成中文为写时复制技术，一般用在创建子进程的时候。当创建子进程时，子进程应该复制一份父进程的资源，但是这样做效率不是很高，特别是在复制一些不被修改的资源的时候，所以操作系统采用了写时复制技术，让子进程引用父进程的资源。只有当子进程修改该资源时，才会复制一份自己私有的资源。","tags":[{"name":"os","slug":"os","permalink":"http://yoursite.com/tags/os/"}]},{"title":"理论篇-数据结构之哈希表VS红黑树","date":"2017-05-05T00:12:34.000Z","path":"2017/05/05/理论篇-数据结构之哈希表VS红黑树/","text":"哈希表和红黑树都可用作实现字典的底层数据结构，而且现实中都有对应的例子。那到底应该采用哪个呢？下面我们做一下对比: - 查找速度 数据特点 内存使用 可扩展性 有序性 操作 哈希表 O(1) 小或静态 数据量大占用大 差 无序 简单查找 红黑树 O(lgn) 大或动态 可控制 好 有序 交并差集 具体应用 语言 哈希表 红黑树 java HashMap TreeMap python dict 无 redis dict 无","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"理论篇-redis","date":"2017-05-04T08:20:50.000Z","path":"2017/05/04/理论篇-redis/","text":"redis设计的主旨: 简单 高效 数据结构与对象redis中一切皆对象，共包含5种对象，分别为字符串对象(string object)、列表对象(list object)、哈希对象(hash object)、集合对象(set object)、有序集合对象(sorted set object)。 数据结构简单动态字符串12345struct sdshdr &#123; int len; # 字符串长度 int free; # 未使用空间长度 char buf[]; # 字节数组&#125; 与C字符串的比较: 通过len字段，获取字符串长度的时间复杂度为O(1) 通过len字段，杜绝了缓冲区溢出问题 通过预分配策略和惰性空间释放策略避免了频繁的内存重分配 二进制安全 通过保留最后一个字符为空字符，可以复用C的字符串库函数，但是前提是字符串中不包含空字符，否则处理出错 双向列表1234567891011121314typedef struct listNode &#123; struct listNode *prev; # 前一个节点 struct listNode *next; # 后一个节点 void *value; # 节点值&#125; listNode;typedef struct list &#123; listNode *head; # 表头节点 listNode *tail; # 表尾节点 unsigned long len; # 节点数量 void *(*dup)(void *ptr); # 节点值复制函数 void *(*free)(void *ptr); # 节点值释放函数 int (*match)(void *ptr, void *key); # 节点值对比函数&#125; list; 通过使用指定value的值为void*和dup、free、match可以实现多态链表。 哈希表1234567891011121314151617181920212223242526272829303132333435363738哈希表typedef struct dictht &#123; dictEntry **table; # 哈希表数组 unsigned long size; # 哈希表大小 unsigned long sizemask; # 哈希表大小掩码，用于计算索引值，总是等于size-1 unsigned long used; # 键值对数量&#125; dictht;load_factor = ht[0].used/ht[0].size; # 负载因子哈希表节点typedef struct dictEntry &#123; void *key; # 键 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; # 值 struct dictEntry *next; # 下一个节点，用于解决冲突&#125; dictEntry;字典typedef struct dict &#123; dictType *type; # 类型特定函数，为实现多态字典 void *privdata; # 保存传给特定函数的可选参数 dictht ht[2]; # 哈希表 int rehashidx; # 当rehash不在进行时，值为-1，否则为哈希表数组的索引&#125; dict;ht属性包含两个哈希表，一般使用第一个，第二个只在rehash时才使用。typedef struct dictType &#123; unsigned int (*hashFunction)(const void *key); # 哈希函数 void *(*keyDup)(void *privdata, const void *key); # 复制键的函数 void *(*valDup)(void *privdata, const void *obj); # 复制值的函数 int *(*keyCompare)(void *privdata, const void *key1, const void *key2); # 比较键的函数 void *(*keyDestructor)(void *privdata, void *key); # 销毁键的函数 void *(*valDestructor)(void *privdata, void *obj); # 销毁值得函数&#125; dictType; MurmurHash算法 跳跃表实现有序集合的底层数据结构之一是跳跃表。当有序集合包含的元素数量比较多，又或者有序结合中元素的成员是比较长的字符串时，redis就会使用跳跃表作为有序集合键的底层实现。 跳跃表支持平均O(lgN)，最坏O(N)的时间复杂度。大部分情况下，跳跃表的性能可以和平衡树相媲美，又因为跳跃表的实现比平衡树简单，所以很多程序使用跳跃表来代替平衡树。 123456789101112131415typedef struct zskiplistNode &#123; struct zskiplistLevel &#123; struct zskiplistNode *forward; # 前进指针 unsigned int span; # 跨度 &#125; level[]; # 层 struct zskiplistNode *backward; # 后退指针 double score; # 分值 robj *obj; # 成员对象&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; # 头尾节点 unsigned long length; # 节点数量 int level; # 层数最大的节点的层数&#125; zskiplist; 根据幂次定律生成层数。 整数集合实现集合的底层数据结构之一是整数集合。当一个集合只包含整数元素，并且这个集合的元素数量不多时，redis就会使用整数集合作为集合的底层实现。 12345typedef struct intset &#123; uint32_t encoding; # 编码方式: int16_t int32_t int64_t uint32_t length; # 元素数量 int8_t contents[]; # 保存元素的数组&#125; intset; 升级:每当添加一个新元素，并且新元素比所有现有元素的类型都要长时整数集合需要先进行升级，然后才能将新元素添加到整数集合里面。 只有升级没有降级 压缩列表压缩列表是列表和哈希的底层实现之一。当一个列表键只包含少量列表项，并且每个列表项要么是小整数要么是长度比较短的字符串，那么redis就会使用压缩列表作为列表的底层实现。当一个字典，只包含少量键值对，并且每个键值对的键和值要么是小整数要么是长度比较短的字符串，那么redis就会使用压缩列表作为字典的底层实现。 12345# ziplistzlbytes|zltail|zllen|entry1|entry2|...|entryN|zlend# ziplistEntryprevious_entry_length|encoding|content 压缩列表是一种为节约内存而开发的顺序型数据结构 压缩列表被用作列表和字典的底层实现之一 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或整数值 添加新节点到压缩列表或从压缩列表中删除节点，可能会引发连锁更新操作，但这种操作出现的几率并不高 对象redis有一个对象系统，该系统包括字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象。每种对象至少用到了一种我们之前介绍的数据结构。 redis执行命令前，根据对象的类型来判断一个对象是否可以执行给定的命令。redis可以在不同的场景下，为同样的对象选择不同的数据结构，从而达到最高的使用效率。 redis实现了基于引用计数技术的内存回收机制，且通过引用计数技术实现了对象共享机制。 对象还带有时间信息，该信息用于计算键的空转时长，当服务器启用maxmemory时，空转时长长的那些键优先被回收。 123456typedef struct redisObject &#123; unsigned type:4; # 类型 unsigned encoding:4; # 编码 void *ptr; # 指向底层实现数据结构的指针 unsigned lru:22 # 空转时长&#125; robj; type的取值 类型常量 对象的名称 REDIS_STRING 字符串对象 REDIS_LIST 列表对象 REDIS_HASH 哈希对象 REDIS_SET 集合对象 REDIS_ZSET 有序集合对象 对于redis保存的键值对来说，键总是一个字符串对象，而值可以是字符串对象、列表对象、哈希对象、集合对象、有序集合对象。 encoding的取值 类型常量 底层数据结构 REDIS_ENCODING_INT long类型的整数 REDIS_ENCODING_EMBSTR embstr编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 哈希表 REDIS_ENCODING_LINKEDLIST 双向链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表 每种类型至少使用了两种不同的编码，以下是不同类型和编码的对象 类型 编码 使用条件 REDIS_STRING REDIS_ENCODING_INT 保存的是整数值，且可以使用long类型存储 REDIS_STRING REDIS_ENCODING_EMBSTR 字符串的长度小于等于32字节 REDIS_STRING REDIS_ENCODING_RAW 字符串的长度大于32字节 REDIS_LIST REDIS_ENCODING_ZIPLIST 1. 所有字符串长度都小于64字节 2. 保存的元素数量小于512个 REDIS_LIST REDIS_ENCODING_LINKEDLIST 违反以上两条的任意一条则使用该编码 REDIS_HASH REDIS_ENCODING_ZIPLIST 1. 所有键值对的键和值得字符串长度都小于64字节 2. 保存的键值对的数量小于512个 REDIS_HASH REDIS_ENCODING_HT 违反以上两条的任意一条则使用该编码 REDIS_SET REDIS_ENCODING_INTSET 1. 保存的所有元素都是整数值 2. 保存的元素数量不超过512个 REDIS_SET REDIS_ENCODING_HT 违反以上两条的任意一条则使用该编码 REDIS_ZSET REDIS_ENCODING_ZIPLIST 1. 保存的所有元素的长度都小于64字节 2. 保存的元素数量小于128个 REDIS_ZSET REDIS_ENCODING_SKIPLIST 违反以上两条的任意一条则使用该编码 1234567891011121314151617181920# 列表对象list-max-ziplist-value # 字符串最大长度list-max-ziplist-entries # 列表保存的最大元素数量# 哈希对象hash-max-ziplist-value # 哈希键值对的字符串最大长度hash-max-ziplist-entries # 哈希表保存的最大键值对数量# 集合对象set-max-intset-entries # 集合保存的最大元素数量# 有序集合对象typedef struct zset &#123; zskiplist *zsl; dict *dict;&#125; zset;有序集合对象同时使用跳跃表和字典来实现，为了兼得各自的优点。zset-max-ziplist-value # 有序集合保存的元素的最大长度zset-max-ziplist-entries # 有序集合保存的最大元素数 类型检查与命令多态类型检查通过redisObject结构的type属性实现。 内存回收对象共享redis服务启动的时候，会自动创建一万个字符串对象，这些对象包括了从0到9999的所有整数值。 好问题: 为什么redis不共享包含字符串的对象？ 如果共享对象是保存整数值的字符串对象，那么验证操作的复杂度是O(1) 如果共享对象是保存字符串值得字符串对象，那么验证操作的复杂度是O(N) 如果共享对象是包含了多个值(或者对象)的对象，比如列表对象或者哈希对象，那么验证操作的复杂度是O($N^2$) 超时机制redis里面的超时时间是以unix时间戳(2.6之后是毫秒)的形式保存的。过期的精度在0~1毫秒之间。 redis里key的过期方式有两种: 1.被动过期 2.主动过期 被动过期方式: 当客户端尝试访问一个key时，检查这个key是否超时。 主动过期方式: redis会每隔一段时间检查过期key集合里面的key是否超时。 定时删除方式: 在设置键的过期时间的同时，创建一个定时器(timer)，让定时器在键的过期时间来临时，立即执行对键的删除操作。 redis主动检查过期的频率为每秒10次: 从过期的key集合里面随机抽取20个进行测试 删除所有过期的key 如果过期的key超过25%，则再从第一步开始 在集群之间，对于过期的key，由主节点向从节点发送DEL操作，从而保证一致性问题。但是从节点也保存过期信息，这样当从节点被选举为主节点时，也可以执行过期操作。 数据库12345678910111213struct redisServer &#123; redisDb *db; # 数组，保存服务器中的所有数据库 int dbnum; # 服务器的数据库数量&#125;;typedef struct redisClient &#123; redisDb *db; # 记录客户端当前正在使用的数据库 &#125; redisClient;typedef struct redisDb &#123; dict *dict; # 数据库键空间 dict *expires; # 保存着键的过期时间 &#125; redisDb; 持久化redis有两种持久化方式和: RDB持久化和AOF持久化。 RDB持久化方式通过将数据库中的所有键值对持久化到磁盘的方式完成。AOF持久化方式通过记录修改命令来记录数据库的状态。 1234567891011struct redisServer &#123; long long dirty; # 修改计数器 time_t lastsave; # 上次保存的时间 struct saveparam *saveparams; # 记录了保存条件的数组 sds aof_buf; # AOF缓冲区&#125;;struct saveparam &#123; time_t seconds; # 秒数 int changes; # 修改数&#125;; RDB持久化RDB持久化有两种触发方式: 手动触发: BGSAVE和SAVE 自动触发: save配置 123456789101112131415161718192021222324252627282930313233343536RDB文件格式:REDIS|db_version|databases|FOF|check_sumREDIS: 5个字节 值为REDISdb_version: 4个字节 rdb文件的版本号 比如0006databases: 0个或多个数据库EOF: 1个字节 值为EOFcheck_sum: 8个字节的无符号整数 通过前面的内容计算出校验和database结构:SELECTDB|db_number|key_value_pairsSELECTDB: 1个字节db_number: 数据库号 长度可能是1字节 2字节或者5字节key_value_pairs: 所有键值对数据，大小不定key_value_pairs(没有过期时间)结构:TYPE|key|valuekey_value_pairs(有过期时间)结构:EXPIRETIME_MS|ms|TYPE|key|valueEXPIRETIME_MS: 1个字节ms: 8个字节 毫秒级的时间戳TYPE记录了value的类型:REDIS_RDB_TYPE_STRINGREDIS_RDB_TYPE_LISTREDIS_RDB_TYPE_SETREDIS_RDB_TYPE_ZSETREDIS_RDB_TYPE_HASHREDIS_RDB_TYPE_LIST_ZIPLISTREDIS_RDB_TYPE_SET_INTSETREDIS_RDB_TYPE_ZSET_ZIPLISTREDIS_RDB_TYPE_HASH_ZIPLIST各个value的编码方式参看《redis设计与实现》或官网文档 AOF持久化AOF持久化分为三个部分: 命令追加、文件写入、文件同步 随着服务器的运行，AOF的体积会越来越大，所以需要对AOF文件进行重建。AOF文件重建原理如下:通过添加对数据库中现有键值对的重建命令而完成。 redis创建一个子进程在后台完成AOF重建工作。由于主进程还在处理客户端的请求，所以会造成重建的AOF文件与实际数据库状态不一样。redis新增了一个AOF重建缓冲区，将重建过程中所有的命令写入到该缓冲区，待重建完成后，子进程向父进程发送信号，父进程收到信号后将该缓冲区的内容追加到AOF重建文件中，然后原子的替换原来的AOF文件。 事件redis服务器是一个事件驱动程序，处理的事件包含两大类: 文件事件和时间事件。 文件事件文件事件就是对网络IO的一种抽象。 网络IO 文件事件 accept READABLE read READABLE close READABLE write WRITABLE 时间事件 定时事件: 让一段程序在指定的时间之后执行一次。 周期性事件: 让一段程序每个一定时间就执行一次。 redis通过程序的返回值来区分定时事件和周期性事件。返回值为下次该函数执行的间隔时间。(该方法可以借鉴) 客户端与服务器客户端123456789101112131415161718192021struct redisServer &#123; list *clients; # 一个链表，保存所有的客户端的状态&#125;;typedef struct redisClient &#123; int fd; # 套接字描述符 robj *name; # 名字 int flag; # 标记客户端的角色 sds querybuf; # 输入缓冲区 robj **argv; # 命令参数 int argc; # 命令参数个数 struct redisCommand *cmd; # 命令对应的执行函数 char buf[REDIS_REPLY_CHUNK_BYTES] # 固定输出缓冲区 int bufpos; # 固定输出缓冲区中目前已使用的字节数量 list *reply; # 可变输出缓冲区 int authenticated; # 身份验证 time_t ctime; # 建立连接的时间 time_t lastinteraction; # 上次交互的时间 time_t obuf_soft_limit_reached_time; # &#125; redisClient; redis中的客户端有两种: 真客户端和伪客户端。其中，伪客户端用于载入AOF文件或执行lua脚本中包含的redis命令。 服务器123struct redisServer &#123; unsigned lruclock:22; # 系统用于计算键的空转时长&#125;; redis通过周期性的执行serverCon函数来维持服务器的状态。 redis在服务器启动的时候会创建一些共享对象，比如”OK”, “ERR”, 1到10000的字符串对象。(这种技术在很多地方都可见到，比如jvm里) 主从复制当slaveof命令执行完毕后，从节点会向主节点发送PSYNC命令，如果是初次同步，则执行完整重同步(full resynchronization)，主节点生成RDB文件，然后传输给从节点，从节点载入RDB文件。若载入RDB文件期间，主节点有写操作，则主节点将命令传播给从节点，使主从一致。若断线重连后，则执行部分重同步(partial resynchronization)，主机点只将从节点断线期间执行的写操作发送给从节点，使主从一致。 1234struct redisServer &#123; char *masterhost; # 主服务器地址 char *masterport; # 主服务器端口&#125;; 主从复制的实现: 设置主服务器的地址和端口 建立连接 发送PING命令 身份验证 发送端口信息 同步 命令传播 sentinel(哨兵节点)sentinel(哨兵节点)是redis的高可用解决方案。 123456789101112131415161718192021222324struct sentinelState &#123; uint64_t current_epoch; # dict *masters; # 所有被监视的服务器 int tilt; int running_scripts; mstime_t tilt_start_time; # mstime_t previous_time; list *scripts_queue; # &#125;;masters的值:typedef struct sentinelRedisInstance &#123; int flags; # 记录了实例的类型以及该实例的状态 char *name; # 实例的名字 char *runid; # 实例运行id uint64_t config_epoch; # 配置epoch sentinelAddr *addr; # 实例地址 dict *slaves; # 从节点信息 dict *sentinels; # 其它sentinels信息 mstime_t down_after_period; # 判断主节点下线的时间限制 int quorum; # 判断主节点下限的sentinel的投票数量 int parallel_syncs; # mstime_t failover_timeout; # &#125; sentinelRedisInstance; 节点之间的连接当启动sentinel节点后，sentinel与主节点建立如下连接: 命令连接 订阅连接 sentinel从主节点获取从节点信息后，也建立以上两个连接。 其他监控主节点的sentinel也对主节点和从节点建立以上连接。sentinel会通过订阅连接向主节点发送消息，其它订阅了该主节点的sentinel节点收到消息后可得知监视同一主节点的所有其它所有sentinel节点。 sentinel节点之间会互相建立命令连接。 判断主节点失效的机制当一个主节点对于一个sentinel节点不可达down-after-milliseconds毫秒后，该sentinel节点就认为该主节点主观下线。 然后询问其它监视该主节点的sentinel节点，若超过预设置的值则认为该节点客观下线。随后进行新主节点的选举。 节点选举首先，简单介绍下redis的sentinel的概念，然后通过一个简单的例子来说明redis的sentinel的运行机制。 一个主节点下可以有多个从节点 一个主节点可以被多个sentinel节点监视 当主节点被判断为客观下线状态时，会有两个选举过程 第一个选举过程是从所有监视该主节点的sentinel里产生领头sentinel，第二个选举过程是从所有的从节点中产生主节点 这个选举机制和总统选举很像。总统相当于主节点，总统胡选人相同于从节点，各大有钱有势的集团相当于sentinel。当总统换届时，各大集团选举出一个领头的集团，该领头的集团从总统候选人中选出一个新的总统。 redis采用了Raft算法保证各个节点达成共识。 集群1234567891011121314151617181920212223242526272829struct clusterNode &#123; mstime_t ctime; # 创建节点的时间 char name[REDIS_CLUSTER_NAMELEN]; # 节点的名字 int flags; # 节点标识(主节点或从节点 上线或下线) uint64_t configEpoch; # 用于故障转移 char ip[REDIS_IP_STR_LEN]; # 节点的ip地址 int port; # 节点的端口号 clusterLink *link; # 保存连接节点的相关信息 unsigned char slots[16384/8]; # 槽 int numslots; # 槽数&#125;;typedef struct clusterLink &#123; mstime_t ctime; # 连接的创建时间 int fd; # tcp套接字 sds sndbuf; # 输出缓冲区 sds rcvbuf; # 输入缓冲区 struct clusterNode *node; # 与该连接相关联的节点&#125; clusterLink;typedef struct clusterState &#123; clusterNode *myself; # 指向当前节点的指针 uint64_t currentEpoch; # 用于故障转移 int state; # 集群状态: 在线或下线 int size; # dict *nodes; # 集群中所有的节点 clusterNode *slots[16384]; # 所有槽的分配情况 zskiplist *slots_to_keys; # 槽与键的对应关系&#125; clusterState; redis集群思想: redis的集群由节点组成，其中包括主节点和从节点。集群按照槽进行分片，共支持16384个槽，每个主节点负责一部分的槽存储。当进行某个键的存取操作时，首先根据键计算出对应的槽值，然后根据槽值去对应的节点进行操作。从节点负责备份主节点，并且当主节点失效时，进行故障转移。 发布订阅redis的发布订阅系统底层通过字典和链表实现。 事务1234567891011121314typedef struct redisClient &#123; multiState mstate; # 事务状态&#125; redisClient;typedef struct multiState &#123; multiCmd *commands; # 事务队列 int count; # 命令数量&#125; multiState;typedef struct multiCmd &#123; robj **argv; # 参数 int argc; # 参数数量 struct redisCommand *cmd; # 命令指针&#125; multiCmd; 待研究 内存回收算法","tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"理论篇-计算机之原码反码补码","date":"2017-05-04T01:34:42.000Z","path":"2017/05/04/理论篇-计算机之原码反码补码/","text":"在计算机的世界里，万物皆01。我们平时听得歌曲，看的电影，使用的软件等等都是由0和1组成。有人说计算机很厉害，比人类聪明，能做各种事情，但事实上，计算机只会处理0和1。由这些0和1组成的有规则的数据叫二进制数据。那二进制数据在计算机里又是什么样的呢？ 为什么需要这些码日常生活中，我们使用十进制来表示数字，比如7，19等。但是，因为计算机只能处理0和1两种状态，所以在计算机的世界里使用二进制来表示数字。比如十进制的7对应的二进制为00000111, 十进制的19对应的二进制为00011001。现实生活中，还有负数的情况，比如-2，这在计算机中如何表示呢？ 原码2的8位二进制表示是00000010，那-2呢？现在我们约定如下，第一位为符号位，0表示正数，1表示负数。那么-2的8位二进制应该为10000010。00000010是2的原码，10000010是-2的原码。 反码我们知道2+(-2)=0。现在我们使用原码计算一边 100000010(原)+10000010(原)=10000100(原) 10000100转换为十进制是-4，肯定是不对的。得想办法解决这个问题，于是科学家们发明了反码。对于正数而言，反码与原码相同，对于负数而言，反码是除了符号位不变，其他位按位取反。比如2的反码是00000010, -2的反码是11111101。现在再使用反码计算2+(-2)为 100000010(反)+11111101(反)=11111111(反)=10000000(原) 10000000转换为十进制是-0。这样0的表示就有了两种，+0为00000000，-0为10000000。 补码现在我们计算1+(-0) 100000001(反)+11111111(反)=00000000(反)=00000000(原) 00000000转换为十进制是0，显然是不对的。看来用反码表示负数也有问题，于是科学家们又发明了补码。对于正数而言，补码与原码相同，对于负数而言，补码是在反码的基础上加1。比如2的补码是00000010, -2的补码是11111110。现在我们再使用补码计算2+(-2)为 100000010(补)+11111110(补)=00000000(补)=00000000(原) 00000000转换为十进制是0。这样0就只有一种表示了。而且之前的-0即10000000可以用来表示-128。 所以在计算机中，采用补码来表示整数。8位有符号整数的范围为(-128, 127)，8为无符号整数的范围为(0, 255)。","tags":[{"name":"计算机","slug":"计算机","permalink":"http://yoursite.com/tags/计算机/"}]},{"title":"理论篇-数据结构之树","date":"2017-04-30T06:59:36.000Z","path":"2017/04/30/理论篇-数据结构之树/","text":"集合支持的操作: 1. 搜索 2. 插入 3. 删除 4. 最小值 5. 最大值 6. 前一个 7. 后一个 树是在计算机里实现动态集合的一种数据结构。树可以有很多分支，叫多叉树。但是在计算机世界中，常见的是二叉树。二叉树的时间复杂度依赖树的高度，如果二叉树是一棵平衡的二叉树，那么时间复杂度是O(lgn)。如果是一棵非常不平衡的二叉树，时间复杂度有可能为O(n)。 二叉查找树的定义: 左子节点的值小于等于父节点的值 右子节点的值大于等于父节点的值 但是二叉查找树不是一棵自平衡的二叉树。为了稳定的得到O(lgn)的时间复杂度，需要保持树的平衡。AVL树、红黑树、B树是自平衡的二叉查找树。 AVL树是最先发明的自平衡的二叉查找树，名称以创始人的名字命名。 AVL树的定义: 红黑树的定义: 二叉查找树的所有性质 每个节点要么是红的要么是黑的 根节点是黑的 每个叶子节点(空节点)是黑的 如果一个节点是红的，那么它的孩子都是黑的 对于每个节点，从该节点到后代叶子节点包含同样数量的黑节点 红黑树主要用于实现集合和字典等内存型数据结构。 B树的定义: 每个节点x都有下列属性 x.n是当前被存储在节点x里的关键字的数量 x.key是关键字，其中关键字以非降序存储 x.leaf标识是否为叶子节点。若是，则为TRUE，若不是， 则为FALSE 每个节点x也包含x.n+1个指向孩子节点的指针。叶子节点没有孩子，因此叶子节点的指针未定义 关键字x.key分割存储在子树里的关键字的范围 所有的叶子节点都有同样的深度，即树的高度 每个节点拥有的关键字数量有上限和下限。t表示关键字的数量，当t&gt;=2时称为最小的B树。 除了根节点外每个节点至少有t-1个关键字。除了根节点外每个节点至少有t个孩子。如果树是非空的，根节点至少有一个关键字。 每个节点至多包含2t-1个关键字。因此，内部节点至多包含2t个孩子。如果包含了2t-1个关键字，则该节点是满的。 B树主要用于对机械硬盘等第二存储设备的访问。 参考 算法导论","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"思考篇-各种面试题","date":"2017-04-29T11:04:02.000Z","path":"2017/04/29/思考篇-各种面试题/","text":"数组相关 请实现一个函数，把字符串中的每个空格替换成“%20”。例如输入“We are happy.”，则输出“We%20are%20happy.”。 解题思路: 首先遍历一遍数组，统计空格的个数，计算新字符串的大小。如果可以创建新的数组，则创建新的数组，然后遍历旧数组，依次拷贝，遇到空格做替换。时间复杂度为O(n)。如果不能创建新的数组，则使用两个指针，从后向前，逐字符遍历，遇到空格做替换，直到两个指针相等，时间复杂度O(n)。 旋转数组 把一个有序数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 现有一旋转数组，给定一个值，判断该值在不在数组中。比如[7,8,9,1,3,4,5,6] 参考答案 解题思路: 使用两个指针p1和p2，分别指向数组的开始和末尾位置，使用二分查找，二分查找结束条件: 当p1和p2相邻时，查找结束。p2指向该数组的最小值。(有种特殊情况需要顺序遍历) 时间复杂度O(lgn) 给定一个数组，将数组中的奇数放到偶数的前面。 解题思路: 使用两个指针，一个指向头部，向后移动；一个指向尾部，向前移动，中间做一些操作，直到相遇。时间复杂度O(1) 数组中有一个数字出现的次数超过数字长度的一半，请找出这个数字。例如输入一个长度为9的数组{1，2，3，2，2，2，5，4，2}，由于2在数组中出现的次数为5，超过了数组长度的一半，因此输出为2。 解题思路: 有一个成熟的近似O(n)的算法可以在一个数组中找到任意第k大的数字。所以只要找到将中间位置设为k，就可以在O(n)的时间复杂度下找到那个数字。 为什么是近似O(n)呢？因为每次都是随机挑选一个数字，这个数字并不一定是第k小的数，所以需要进行收敛，虽然收敛的过程还是很快的，但是每次收敛都执行一个O(n)的遍历，所以是近似O(n)。 连续子数组的最大和 输入一个整型数组，数组里有正数也有负数。数组中的一个或连续的多个组成一个子数组。求所有子数组的和的最大值。要求时间复杂度为O(n) 如果之前数字的和为负数，则最大和从下一个数字开始计算。 把数组排成最小的数 输入一个正整数数组，把数组里面所有的数拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则符合要求的是321323 解题思路: xxx 在一个单调非递减的数组里，给定一个数，找到第一个大于等于该数的位置，若数组中最大的数都小于给定的数，则返回数组的长度。 参考答案 解题思路: 二分查找的变种。注意各种边界条件的检查 螺旋数组 给定一个n*n的矩阵，生成螺旋矩阵。 参考答案 链表相关 单链表反转 核心代码如下: 12345678910Node *new_head = NULL;Node *old_head = list-&gt;head-&gt;next;Node *temp = head;while (old_head != NULL) &#123; old_head = old_head-&gt;next; temp-&gt;next = new_head; new_head = temp; temp = old_head;&#125;list-&gt;head-&gt;next = new_head; 删除单链表节点 解题思路: 将下一个节点的值复制到当前节点，让当前节点指向下一个节点的下一个节点，删除下一个节点。特殊的地方: 如果删除的节点是尾节点，扔需要遍历。若是头结点，将头结点置为NULL。时间复杂度O(1) 得到链表的倒数第k个节点 解题思路: 使用两个节点，第一个指向头结点，与第二个节点相距k-1，当第二个节点指向尾节点时，第一个就指向了倒数第k个节点。时间复杂度O(n) 合并两个有序链表 解题思路: 可以使用递归，也可以使用循环。记住对输入链表是否为空的检查。 堆相关 输入n个整数，找出其中最小的k个数。 解题思路:若n是一个非常大的数，则考虑创建一个有k个元素的大顶堆。 树相关树的遍历 输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果都不包含重复的数字。例如输入前序遍历序列[1, 2, 4, 7, 3, 5, 6, 8]和中序遍历序列[4, 7, 2, 1, 5, 3, 8, 6]，请构建出二叉树。 树的子结构 输入两颗二叉树A和B，判断B是不是A的子结构。二叉树节点定义如下: 12345struct BinaryTreeNode &#123; int value; BinaryTreeNode *left; BinaryTreeNode *right;&#125;; 算法相关递归与循环 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法？ 解题思路:斐波那契数列 位运算 请实现一个函数，输入一个整数，输出该数二进制表示中1的个数 解题思路: 正数与负数在计算机中的表示是不一样的，正数是原码表示，负数是补码表示。小技巧:将一个整数减去1，再和原整数做与运算，会把该整数最右边的1变成0 异或运算: 相同为0，不同为1","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-数据结构之哈希表","date":"2017-04-28T07:58:20.000Z","path":"2017/04/28/理论篇-数据结构之哈希表/","text":"直接定址表当数据量有限时，通过将数据一一映射到数组，可以获得O(1)的时间复杂度。 哈希表当真正被存储的数据量比实际可能的数据量要小很多时，哈希表就显示出它的威力来了。 关键字尽可能的将关键字使用数字表示 哈希函数一个好的哈希函数的标准: 任何一个关键字都有平等的机会映射到哈表表的每个槽位，并且与其他关键字无关。 通常使用的哈希算法有: 1. 取模 实现原理通过使用哈希函数将关键字映射到数组的下标地址，但是，由于哈希表空间有限，所以会出现两个不同的关键字映射到了同一个数组下标的情况，因此需要冲突解决。 冲突解决的方法有: 1. 链式 2. 开放定址 负载因子负载因子=已存节点数量/槽的数量，应尽量保持其值小于等于1。 应用哈希表一般用于字典的底层实现","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"理论篇-一致性哈希算法","date":"2017-04-26T10:02:05.000Z","path":"2017/04/26/理论篇-一致性哈希算法/","text":"DHTDHT(distributed hash table)分布式哈希表，是一种分布式存储方法。一致性哈希算法是DHT的一种实现。 普通哈希普通哈希算法是一个将范围很大的集合通过哈希函数映射到范围固定的集合上的一种方法。 问题普通哈希算法有自己的局限性，比如在分布式缓存中，如果增减服务器，会造成大面积的缓存失效。具体例子: 假设我们现在有100台服务器，机器编号为0-99，之前关键字为101的请求会路由到101%100=1这台机器。现在我们需要增加一台机器，那么关键字为101的请求将会路由到101%101=0这台机器，最终导致缓存访问失效。 一致性哈希算法(consistent hashing)一致性哈希有如下几个特性: 冗余少 负载均衡 过度平滑 存储均衡 关键词单调 实现","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-各种锁","date":"2017-04-26T08:36:35.000Z","path":"2017/04/26/理论篇-各种锁/","text":"乐观锁与悲观锁乐观锁乐观锁其实本质没有使用任何锁，原名是乐观并发控制(Optimistic Concurrency Control)。原理是乐观的假设不会发生冲突，只有在真正更新数据时才会检查是否冲突。通常使用版本号等实现。 使用场景: 冲突少的场景下 在数据库中的使用方法如下:123select status, version from goods where id=xxx对数据做一些修改update goods set status=2, version=version+1 where id=xxx and version=&#123;version&#125; 悲观锁悲观锁是悲观的认为会发生冲突，所以需要拿到锁之后再对数据做一些操作。 使用场景: 冲突多的场景 在数据库中使用方法如下: 12345begin # 开启一个事务select status from goods where id=xxx对数据做一些修改update goods set status=2 where id=xxxcommit # 提交事务","tags":[{"name":"锁","slug":"锁","permalink":"http://yoursite.com/tags/锁/"}]},{"title":"理论篇-mysql","date":"2017-04-25T03:44:47.000Z","path":"2017/04/25/理论篇-mysql/","text":"索引最左前缀原理与相关优化索引参考","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"实战篇-操作系统面试","date":"2017-04-25T02:37:10.000Z","path":"2017/04/25/实战篇-操作系统面试/","text":"IO多路复用select的缺点如下: 连接数受限(1024) 查找配对速度慢(需将所有id遍历一遍) 数据由内核态拷贝到用户态 poll解决了第一个缺点，epoll解决了上述三个缺点。","tags":[{"name":"os","slug":"os","permalink":"http://yoursite.com/tags/os/"}]},{"title":"实战篇-python面试","date":"2017-04-24T10:58:38.000Z","path":"2017/04/24/实战篇-python面试/","text":"数据类型及变量引用1234567891011a = 1def f(a): a = 2f(a)print a # 1-------------------a = []def f(a): a.append(1)f(a)print a # [1] 涉及python中的引用以及可变量与不可变量的知识 字符串格式化123456name = &quot;x&quot;&quot;hi there %s&quot; % name # hi there xname= (&quot;x&quot;, )&quot;hi there %s&quot; % (name, ) # hi there x&quot;hi there &#123;0&#125;&quot;.format(name) 123456789101112131415161718192021222324class MyClass(): def __init__(self): self.__superprivate = &quot;hello&quot; self._semiprivate = &quot;world&quot; def f(self): print self.__superprivatemc = MyClass()print mc.__dict__print mc._semiprivatemc.f()print mc.__superprivate--------output--------&#123;&apos;_MyClass__superprivate&apos;: &apos;hello&apos;, &apos;_semiprivate&apos;: &apos;world&apos;&#125;worldhelloTraceback (most recent call last): File &quot;test.py&quot;, line 32, in &lt;module&gt; print mc.__superprivateAttributeError: MyClass instance has no attribute &apos;__superprivate&apos; __foo__: 一种约定，python内部的名字，用来区别用户自定义的名字，以防冲突 _foo: 一种约定，程序员用来指定私有变量的形式 __foo: 真正的私有变量，会变成_classname__foo is与==12is比较引用地址==比较值 类相关__new__与__init__ __new__是一个类方法，__init__是一个实例方法 __new__返回一个创建的实例，__init__什么都不返回 __new__执行后__init__才执行 类的各种方法1234567891011121314def foo(x): print(&quot;foo %s&quot; % x) class A(object): def foo(self, x): print(&quot;foo %s %s&quot;, self, x) @classmethod def class_foo(cls, x): print(&quot;class_foo %s %s&quot;, cls, x) @staticmethod def static_foo(x): print(&quot;static_foo %s&quot;, x) \\ 实例方法 类方法 静态方法 a = A() a.foo(x) a.class_foo(x) a.static_foo(x) A 不可用 A.class_foo(x) A.static_foo(x) 实例方法的本质是foo(a, x)，类方法的本质是class_foo(A, x)，静态方法的本质是普通方法，只是作用域不同 类的各种变量1234567891011121314151617class Person: name = &quot;aaa&quot; p1 = Person()p2 = Person()p1.name = &quot;bbb&quot;print p1.name # bbbprint p2.name # aaaprint Person.name # aaa-----------------------class Person: name = []p1 = Person()p2 = Person()p1.name.append(1)print p1.name # [1]print p2.name # [1] 单例参看源码 自省机制自省就是程序执行时能知道对象的类型。 12345type()dir()getattr()hasattr()isinstance() 推导式12345[x for x in xrange(3)] # [0, 1, 2][x for x in xrange(10) if x%2 == 0] # [0, 2, 4, 6, 8][[x, y] for x in xrange(2) for y in xrange(2)] # [[0, 0], [0, 1], [1, 0], [1, 1]]&#123;key: value for (key, value) in iterable&#125; 迭代器与生成器12345678910111213141516171819202122mylist = [1, 2, 3]for i in mylist: print ifor i in mylist: print imygenerator = (x for x in range(3))for i in mygenerator: print ifor i in mygenerator: print i ---- output ----123123012 迭代器的本质是: __iter__和__next__ 生成器的本质是: yield 函数*args和**kwargs 1234567891011121314151617def print_everything(*args): for count, thing in enumerate(args): print &apos;&#123;0&#125; &#123;1&#125;&apos;.format(count, thing)print_everything(&apos;apple&apos;, &apos;banana&apos;, &apos;cabbage&apos;)def table_things(**kwargs): for key, value in kwargs.items(): print &apos;&#123;0&#125;=&#123;1&#125;&apos;.format(key, value)table_things(apple=&apos;fruit&apos;, cabbage=&apos;vegetable&apos;)---- output ----0 apple1 banana2 cabbagecabbage=vegetableapple=fruit 装饰器1234567891011121314151617181920def makebold(fn): def wrapped(): return &apos;&lt;b&gt;&apos; + fn() + &apos;&lt;/b&gt;&apos; return wrappeddef makeitalic(fn): def wrapped(): return &apos;&lt;i&gt;&apos; + fn() + &apos;&lt;/i&gt;&apos; return wrapped@makebold@makeitalicdef say(): return &apos;hello world&apos;print say()---- output ----&lt;b&gt;&lt;i&gt;hello world&lt;/i&gt;&lt;/b&gt; 闭包 必须有一个内嵌函数 内嵌函数必须引用外部函数中的变量 外部函数的返回值必须是内嵌函数 lambda表达式12f = lambda x, y, z: x+y+zf(1, 2, 3) # 6 函数式编程1234567print filter(lambda x: x&gt;5, [1, 2, 3, 4, 5, 6, 7])print map(lambda x: x**2, [1, 2, 3, 4, 5, 6, 7])print reduce(lambda x, y: x*y, range(1, 4))---- output ----[6, 7][1, 4, 9, 16, 25, 36, 49]6 鸭子类型作用域 本地作用域(local) 当前作用域被嵌入的作用域(enclosing local) 全局/模块作用域(global) 内置作用域(built-in) 全局解释器锁(GIL)协程拷贝12345678910111213141516171819import copya = [1, 2, 3, 4, [&apos;a&apos;, &apos;b&apos;]]b = ac = copy.copy(a)d = copy.deepcopy(a)a.append(5)a[4].append(&apos;c&apos;)print aprint bprint cprint d---- output ----[1, 2, 3, 4, [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], 5][1, 2, 3, 4, [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], 5][1, 2, 3, 4, [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]][1, 2, 3, 4, [&apos;a&apos;, &apos;b&apos;]] 垃圾回收机制GC主要使用引用计数(reference counting)来跟踪和回收垃圾。在引用计数的基础上通过”标记-清除”(mark and sweep)解决容器对象可能产生的循环引用问题，通过”分代回收”(generation collection)以空间换时间的方法提高垃圾回收效率。 引用计数PyObject是每个对象必有的内容，其中ob_refcnt就是引用计数器。当一个对象有新的引用时，ob_refcnt就增加，当引用它的对象被删除时，ob_refcnt就减少。引用计数器为0时，该对象的生命就结束了。 优点 简单 实时性 缺点 维护引用计数消耗资源 循环引用 标记-清除机制基本思路是先按需分配，等内存空间不够时从寄存器或程序栈上的引用出发，遍历以对象为节点，以引用为边构成的图，把所有可访问的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象清除。 分代回收分代回收的基本思想: 将系统中的所有内存块根据其存活时间分为不同的集合，每个集合就成为一个代，垃圾回收频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来衡量。","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-不错的工具","date":"2017-04-24T03:50:10.000Z","path":"2017/04/24/实战篇-不错的工具/","text":"开源项目ascii logo生成器","tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"理论篇-编程语言","date":"2017-04-20T13:31:41.000Z","path":"2017/04/20/理论篇-编程语言/","text":"类型动态/静态类型: 当声明一个变量时，若需明确指定该变量的类型，则该语言是静态类型，否则是动态类型 强弱类型: 若某个变量的类型确定之后，则只能对其进行该类型的操作，则该语言是强类型，否则是弱类型 类型 例子 动态 强类型 python 动态 弱类型 php lua 静态 强类型 静态 弱类型 c c++","tags":[]},{"title":"理论篇-python编程之基础","date":"2017-04-20T12:56:32.000Z","path":"2017/04/20/理论篇-python之基础/","text":"在python的世界中，万物皆对象。 可作用于多种类型的通用型操作都是以内置函数或表达式的形式出现的，类型特定的操作是以方法调用的形式出现的 数据类型 类型 例子 number 1234, 3.14 string ‘xxx’ list [1, [2, 3], 4] dict {“xxx”:[1, 2], “a”: “b”} tuple (1, ‘xxx’, 4) file f = open(‘xxx’, ‘r’) set set(‘abc’) other core types boolean type None program unit types function module class 字符串 以字符序列的形式存储的 支持负索引 不可变 字符串方法 格式化操作 1234567a = &quot;aaa&quot;b = &quot;bbb&quot;a + b &gt; &quot;aaabbb&quot;a * 2 &gt; &quot;aaaaaa&quot;&quot;%s %s&quot; % (&quot;hello&quot;, &quot;world&quot;)&quot;&#123;0&#125; &#123;1&#125;&quot;.format(&quot;hello&quot;, &quot;world&quot;)","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Hello World","date":"2017-04-20T12:43:09.000Z","path":"2017/04/20/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]},{"title":"实战篇-git","date":"2017-04-20T11:23:12.000Z","path":"2017/04/20/实战篇-git/","text":"submodule123456git submodule add url pathgit commit -m &apos;add module xxx&apos; # 增加子模块git submodule update # 更新子模块git submodule update --init --recursive # clone带有子模块的工程后执行","tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"实战篇-运维之日志","date":"2017-04-20T09:10:16.000Z","path":"2017/04/20/实战篇-运维之日志/","text":"根据日志查问题是工作中不可避免的，但是当服务器不止一台时，此时查日志成为了问题。一台一台的看，效率很低，而且做很多重复性的动作。下面推荐一个同时查询多台机器的日志工具: polysh 下载地址 123unzip polysh-0.4.zippython setup.py installpython setup.py install --home=~/xxx # 在没有安装权限的时候，指定安装目录 注意:机器之间需要免密登录","tags":[]},{"title":"实战篇-python编程之各种库","date":"2017-04-20T03:59:12.000Z","path":"2017/04/20/实战篇-python之各种库/","text":"内置库1types python支持的所有类型 glob功能: 查找符合特定规则的文件路径名使用: 利用简单的正则符号匹配文件 123456* # 匹配0个或多个字符? # 匹配1个字符[] # 匹配指定范围内的字符 比如[0-9]glob.glob(&quot;*.xxx&quot;) # 返回以xxx结尾的文件组成的列表glob.iglob(&quot;*.xxx&quot;) # 返回迭代器 functiontools 函数 功能 partial 预设部分参数 wraps 将被包装函数的属性赋值给包装函数，方便调试 123456789101112131415161718192021import functoolsdef add(a, b): return a + bprint(add(1, 2))plus1 = functools.partial(add, 1)print(plus1(2))plus1_2 = functools.partial(add, 1, 2)print(plus1_2())plus1_2_3 = functools.partial(add, 1, 2, 3)print(plus1_2_3())----output----333Traceback (most recent call last): File &quot;functiontools_test.py&quot;, line 12, in &lt;module&gt; print(plus1_2_3())TypeError: add() takes exactly 2 arguments (3 given) 数据库相关MySQLdb1234567891011121314151617181920212223242526272829import MySQLdbconn = MySQLdb.connect(host=&apos;&apos;,user=&apos;&apos;,passwd=&apos;&apos;,db=&apos;&apos;,port=5002)cur = conn.cursor()# insert# delete# updatecur.execute(&quot;update ...&quot;)conn.commit()# querycur.execute(&quot;select ...&quot;)for doc in cur: pass # 事务conn.commit()conn.rollback() # 回滚到上次committry: cur = conn.cursor() cur.execute(&quot;xxx1&quot;) cur.execute(&quot;xxx2&quot;) cur.close() conn.commit()except Exception, e: cur.close() conn.rollback()","tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"实战篇-rpc之thrift","date":"2017-04-20T03:19:58.000Z","path":"2017/04/20/实战篇-rpc之thrift/","text":"安装1yum install thrift 使用编写idl文件shared.thrift 1234567891011namespace java sharednamespace php sharedstruct SharedStruct &#123; 1: i32 key, 2: string value&#125;service SharedService &#123; SharedStruct getStruct(1: i32 key)&#125; tutorial.thrift 1234567891011121314151617181920212223242526272829303132333435include &quot;shared.thrift&quot;namespace java tutorialnamespace php tutorialtypedef i32 MyIntegerconst i32 INT32CONSTANT = 9853const map&lt;string, string&gt; MAPCONSTANT = &#123;&apos;hello&apos;:&apos;world&apos;&#125;enum Operation &#123; ADD = 1, SUB, MUL, DIV&#125;struct Work &#123; 1: i32 num1 = 0, 2: i32 num2, 3: Operation op, 4: optional string comment&#125;exception InvalidOperation &#123; 1: i32 whatOp, 2: string why&#125;service Calculator extends shared.SharedService &#123; void ping(), i32 add(1:i32 num1, 2:i32 num2), i32 calculate(1:i32 logid, 2:Work w) throws (1:InvalidOperation ouch), oneway void sub(1:i32 num1, 2:i32 num2)&#125; 生成特定语言的包1thrift -r -gen py tutorial.thrift","tags":[{"name":"rpc","slug":"rpc","permalink":"http://yoursite.com/tags/rpc/"}]},{"title":"理论篇-rpc之thrift","date":"2017-04-19T09:43:24.000Z","path":"2017/04/19/理论篇-rpc之thrift/","text":"RPC(Remote Procedure Call Protocol)远程过程调用协议。该协议允许运行于一台计算机上的程序调用另一台计算机上的子程序，而程序员无需为这个额外的交互过程编程。 thrift是众多rpc框架中的一个。本文主要介绍下thrift。 thrift的结构1234567服务器层: 单线程，事件驱动等-----------------------处理器层: 特定服务的实现-----------------------协议层: json binary compact---------------------------传输层: 基于tcp协议或者http协议传输数据 传输层传输层提供了一个从网络上读写的简单抽象。有两个接口Transport和ServerTransport。 12Transport: open close read write flushServerTransport: open listen accept close 协议层协议层定义了内存数据结构映射为线性结构的机制。简单的说就是将内存里的数据转换成可以在传输层收发的格式。比如json、xml、plain text、compact binary等 1234567891011121314151617181920212223242526272829303132333435363738394041writeMessageBegin(name, type, seq)writeMessageEnd()writeStructBegin(name)writeStructEnd()writeFieldBegin(name, type, id)writeFieldEnd()writeFieldStop()writeMapBegin(ktype, vtype, size)writeMapEnd()writeListBegin(etype, size)writeListEnd()writeSetBegin(etype, size)writeSetEnd()writeBool(bool)writeByte(byte)writeI16(i16)writeI32(i32)writeI64(i64)writeDouble(double)writeString(string)name, type, seq = readMessageBegin() readMessageEnd()name = readStructBegin() readStructEnd()name, type, id = readFieldBegin() readFieldEnd()k, v, size = readMapBegin() readMapEnd()etype, size = readListBegin() readListEnd()etype, size = readSetBegin() readSetEnd()bool = readBool()byte = readByte()i16 = readI16()i32 = readI32()i64 = readI64()double = readDouble()string = readString() 处理器层特定的服务实现特定的处理器123interface TProcessor &#123; bool process(TProtocol in, TProtocol out) throws TException&#125; 服务器层服务器层负责将所有功能组装起来 创建一个传输层 为传输层创建输入/输出协议 基于协议创建一个处理器 等待一个连接，然后将连接分发到处理器 实现py 12345678910111213141516171819传输层:thrift.transport.THttpClientthrift.transport.TSocketthrift.transport.TSSLSocketthrift.transport.TTransport.TBufferedTransportthrift.transport.TTransport.TFramedTransport协议层:thrift.protocol.TBinaryProtocolthrift.protocol.TCompactProtocol服务器层:thrift.server.TServer # 接口thrift.server.THttpServer # 基于http协议的服务thrift.server.TNonblockingServer.TNonblockingServer # 基于事件的服务器模型thrift.server.TProcessPoolServer.TProcessPoolServer # 进程池服务器模型thrift.server.TServer.TForkingServer # 为每个请求创建一个新进程thrift.server.TServer.TSimpleServer # 单线程thrift.server.TServer.TThreadPoolServer # 线程池服务器模型thrift.server.TServer.TThreadedServer # 每个连接产生一个新的线程 参考测试代码TThreadedServer VS TNonblockingServer","tags":[{"name":"rpc","slug":"rpc","permalink":"http://yoursite.com/tags/rpc/"},{"name":"thrift","slug":"thrift","permalink":"http://yoursite.com/tags/thrift/"}]},{"title":"理论篇-网络安全之重放攻击","date":"2017-04-19T08:29:13.000Z","path":"2017/04/19/理论篇-网络安全之重放攻击/","text":"重放攻击是指攻击者发送一个目的主机已经接收过的包来达到欺骗系统的目的，主要用于身份认证的过程，破坏认证的正确性。 例子当你在咖啡厅里，悠闲地喝着咖啡，蹭着网(咖啡厅里的公共网络)。这时你登录某个网站时，被第三方劫持到你发给服务器的请求，此时第三方可以将这个请求重新发给服务器，使用你的账号登录了网站，第三方可以替你买很多东西，你却浑然不知。 防御手段 随机数+数字签名 时间戳+数字签名 随机数+数字签名客户端发送请求到服务端，服务端生成一个与id对应的随机数，然后返还给客户端。客户端利用该随机数+盐作为密钥对参数进行数字签名，再次请求服务端。 优点: 不依赖时钟同步缺点: 需要两次请求 时间戳+数字签名客户端利用时间戳+盐作为密钥对参数进行数字签名，请求服务端。服务端设置一个时间窗口，该窗口内请求有效，其他请求无效。 优点: 请求一次缺点: 依赖时钟同步，时间窗口内，扔可重放攻击","tags":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"},{"name":"网络","slug":"网络","permalink":"http://yoursite.com/tags/网络/"}]},{"title":"java编程之各种坑","date":"2017-04-17T12:38:29.000Z","path":"2017/04/17/实战篇-java编程之各种坑/","text":"比较大小在java的世界里，会对[-128, 127]之间的Integer做一个缓存。而==比较的引用。所以会出现如下现象: 123456789101112Integer a_I = 100;Integer b_I = 100;Integer c_I = 200;Integer d_I = 200;int a_i = 100, b_i = 100, c_i = 200, d_i = 200;System.out.println(a_I == b_I); # trueSystem.out.println(c_I == d_I); # falseSystem.out.println(c_I.equals(d_I)); # trueSystem.out.println(c_I &gt;= d_I); # trueSystem.out.println(a_i == b_i); # trueSystem.out.println(c_i == d_i); # trueSystem.out.println(c_i &gt;= d_i); # true 解决办法: 尽量使用equals()方法。","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"实战篇-java编程之spring","date":"2017-04-16T02:49:14.000Z","path":"2017/04/16/实战篇-java编程之spring/","text":"","tags":[]},{"title":"理论篇-java编程之spring","date":"2017-04-16T02:49:07.000Z","path":"2017/04/16/理论篇-java编程之spring/","text":"记得第一次接触java是在2010年，当时在读大二，当时只是学习java的基础语法。由于那时候对网络等知识的欠缺再加上java web的复杂性，所以一直也没弄明白java web开发到底是什么东西。 前置知识java世界中，还有一个很明显的特点，就是专业术语特别的多，很容易让新学者摸不着头脑。下面就将学习过程中遇到的专业术语尽可能简单的介绍给大家。 javabean简单的说就是只拥有属性及其对应的get set方法的java类。 pojo(plain old java object)就是指简单的javabean，为了避免与EJB混淆所创造的简称。 EJB(enterprise javabean)是一个用来构筑企业级应用的服务器端可被管理组件。个人理解就是实现了服务器端一些通用功能的java类。spring就是用来代替EJB的。 springspring是一个模块化的框架。spring的本质是依赖注入(dependency injection, DI)和面向切面编程(aspect-oriented programming, AOP)。 spring的核心理念: 基于pojo的轻量级和最小侵入性编程 通过依赖注入和面向接口编程实现松耦合 基于切面和惯例实现声明式编程 通过切面和模板减少样板式代码 侵入编程指的是在使用某些框架时，在写业务代码的时候需要继承框架的某些类以利用框架的某些功能。 DI写代码的时候，我们一直在追求低耦合高内聚。没有耦合的代码意味着一点关系也没有，如果需要多个类配合完成一个任务时肯定是不行的。如果耦合过高，代码将难扩展难测试。spring是如何解决低耦合问题的呢？ 创建应用组件之间协作的行为称为装配(wiring)。 spring装配应用组件的方式有三种。 在xml中进行显式配置 在java中进行显式配置 隐式的bean发现机制(组件扫描(component scanning))和自动装配 当使用第三方组件时，需要通过java或xml显式的配置。 通过xml文件如下: 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;&gt;&lt;beans&gt; &lt;bean id=&quot;knight&quot; class=&quot;com.xxx.BraveKnight&quot;&gt; &lt;constructor-arg ref=&quot;quest&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;quest&quot; class=&quot;com.xxx.SlayDragonKnight&quot;&gt; &lt;constructor-arg value=&quot;#&#123;T(System).out&#125;&quot;&gt; &lt;/bean&gt;&lt;/beans&gt; 通过java如下:bean的id与方法名一致。 123456789101112131415161718192021222324252627@Configurationpublic class KnightConfig &#123; @Bean public Knight knight() &#123; return new BraveKnight(quest()); &#125; @Bean public CompactDisc sgtPeppers() &#123; return new SgtPeppers(); &#125; # 以下两种方法等价 @Bean public CDPlayer cdPlayer() &#123; return new CDPlayer(sgtPeppers()); &#125; @Bean pubilc CDPlayer cdPlayer(CompactDisc compactDisc) &#123; return new CDPlayer(compactDisc); &#125;&#125;@Configuration@Bean * name=&quot;xxx&quot; 组件扫描和自动装配: 12345678@Component@ComponentScan() # 从哪些包中扫描 * basePackages=&#123;&quot;xxx1&quot;, &quot;xxx2&quot;&#125; * basePackageClasses=&#123;XXX1.class, XXX2.class&#125;@ContextConfiguration() # 配置类 * classes=XXX.class@Autowired * required=false java注解 12@Named@Inject spring应用上下文(Application Context)全权负责对象的创建的装配。 spring中的每个bean都有一个ID，可指定可不指定，若不指定，则类名第一个字母小写即为ID。 AOP面向切面编程可以让很多功能性代码(比如日志)脱离核心业务代码，使核心业务代码保持简单。实现方式如下: 通过xml文件实现AOP 通过注解实现(本质是基于代理的AOP) 通过xml文件实现AOP: 1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;&gt;&lt;beans&gt; &lt;bean id=&quot;knight&quot; class=&quot;com.xxx.BraveKnight&quot;&gt; &lt;constructor-arg ref=&quot;quest&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;quest&quot; class=&quot;com.xxx.SlayDragonKnight&quot;&gt; &lt;constructor-arg value=&quot;#&#123;T(System).out&#125;&quot;&gt; &lt;/bean&gt; &lt;bean id=&quot;minstrel&quot; class=&quot;com.xxx.Minstrel&quot;&gt; &lt;constructor-arg value=&quot;#&#123;T(System).out&#125;&quot;&gt; &lt;/bean&gt; &lt;aop:config&gt; &lt;aop:aspect ref=&quot;minstrel&quot;&gt; &lt;aop:pointcut id=&quot;embark&quot; expression=&quot;execution(* *.embarkOnQuest(..))&quot;&gt; # 定义切点 &lt;aop:before pointcut-ref=&quot;embark&quot; method=&quot;singBeforeQuest&quot;&gt; &lt;aop:after pointcut-ref=&quot;embark&quot; method=&quot;singAfterQuest&quot;&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 容器 spring容器负责创建对象，装配它们，配置它们并管理它们的整个生命周期。 spring容器有多种实现。BeanFactory和ApplicationContext是其中的两种实现。 bean的生命周期123456789101112131415实例化填充属性调用BeanNameAware的setBeanName()方法调用BeanFactoryAware的setBeanFactory方法调用ApplicationContextAware的setApplicationContext()方法调用BeanPostProcessor的与初始化方法调用InitializingBean的afterPropertiesSet()方法调用自定义的初始化方法调用BeanPostProcessor的初始化方法----------------------- bean创建完成-----------------------容器关闭调用DisposableBean的destroy()方法调用自定义的销毁方法","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"}]},{"title":"理论篇-洗牌","date":"2017-04-13T10:03:32.000Z","path":"2017/04/13/理论篇-洗牌/","text":"之前面试的时候被问到该问题，今天看到了一个不错的算法。所以写下来纪念下。 洗牌定义如下: 将一组数尽可能的打乱。 方案一: 任意选中两张，做交换处理，执行多次。 方案二: 在一个不易发生碰撞的随机数区间内生成n个随机数，每个随机数对应一张牌，然后将随机数排序。 很明显，方案二要优于方案一。当时面试时只想到了方案一，汗颜。","tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"理论篇-分布式环境下如何保证消息有序","date":"2017-04-13T10:03:18.000Z","path":"2017/04/13/理论篇-分布式环境下如何保证消息有序/","text":"分布式环境下，保证消息的有序性是一个经典的问题，在分布式环境的很多业务场景中都会遇到该问题。下面让我们从简单到复杂，一步一步分析。 当只有一个生产者一个消费者的时候，这个问题是不存在的。如下所示: 1生产者 --&gt; 队列 --&gt; 消费者 真正的生产环境下，肯定不会是这么简单的，因为该模型的处理能力真的很有限。一般生产环境的模型应该是如下图所示: 123456789生产者 生产者 ... 生产者 \\ | / \\ | / \\ | / 队列 / | \\ / | \\ / | \\消费者 消费者 ... 消费者 消息定义: 每个id下有序号分别为1到n的消息。比如xxx_1、xxx_2、xxx_3等分别是id为xxx的序号分别为1 2 3的三条消息。 在该场景下保证消息有序的方案如下: 方案一: 保证某个id的消息只会被分发到特定的消费者 方案二: 使用分布式锁和带有序列信息的消息 方案一的原理很简单，具体实施的时候需要在队列与消费者之间增加一层消息分发模块，保证某一类消息只会被分发到特定的消费者。该方案的缺点:1.使用某些消息队列服务比如RabbitMQ的时候，实现困难 2.不能充分利用多个消费者的能力，比如某些消费者处于饥饿状态 方案二需要生产者和消费者互相配合来完成。 分布式锁保证某一类消息只能同时被一个消费者消费。只有分布式锁还不足以保证消息的有序消费，比如，生产者生产了xxx_1 xxx_2 xxx_3三条消息，虽然消息是按照如上顺序分发的，但是由于网络等原因导致xxx_2消息被提前消费，这样消息就乱序了。 如果消费者在消费xxx_2时能判断出xxx_1还没有被消费，那么就可以采取一些措施来保证消息的有序消费。比如将xxx_2消息重新放到队列里。具体实施的时候需要生产者做一些配合，比如将消息的格式改为如下xxx_1_0 xxx_2_1 xxx_3_2。这样xxx代表id号 1代表消息序号 0代表前一个消息的序号。 该方案的优点:充分利用每个消费者的能力。缺点:实现复杂，依赖分布式锁 方案二的优化版:根据消息的特点，可以做一些优化。比如有如下两种消息序列，时间从1秒开始计时。第一行是某个id的消息完全有序。第二行是某个id的消息区间内有序。 12xxx_1_1 xxx_2_1 xxx_3_2 xxx_70_3 xxx_73_70xxx_1_1 xxx_2_1 xxx_3_2 xxx_70_70 xxx_73_70 第一种方案需要在缓存里一直维护id与序号之间的关系，并且不知道什么时候该删除该对应关系，给缓存增加了压力。第二种方案可以给缓存设个有效时间。这样既能保证某区间段内消息有序，又能减少缓存的压力。","tags":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/tags/架构/"}]},{"title":"实战篇-服务器配置","date":"2017-04-12T14:45:13.000Z","path":"2017/04/12/实战篇-服务器配置/","text":"CentOS1yum install epel-release # 安装epel源","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"实战篇-ssh","date":"2017-04-11T13:29:53.000Z","path":"2017/04/11/实战篇-ssh/","text":"认证原理1234A----发送公钥---&gt;B(若A的公钥在B的认证列表里，则省略密码验证部分)A&lt;---发送公钥----BA----使用B公钥加密后的密码----&gt;BA&lt;---通过后连接建立----B 免密登录原理: 假如想从A免密登录B，需要在A上生成一个.ssh/id_rsa.pub，然后拷贝到B的.ssh/authorized_keys。 123A:ssh-key-genssh-copy-id B ssh翻墙1ssh -qTfnN -D port user@host","tags":[{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"理论篇-构建工具的历史","date":"2017-04-10T08:09:57.000Z","path":"2017/04/10/理论篇-构建工具的历史/","text":"构架过程简单来讲就是编译，测试，生成文档，打包，部署。 最简单直接的构建工具应该是我们自己写的shell脚本，通过脚本来管理整个构建过程。这样做的缺点很明显: 风格不统一 不能胜任大型项目的管理工作 于是，make诞生了，通过makefile文件，通过一系列的规则将整个构建过程串起来。每个规则包含目标、依赖、命令。make的强大之处在于可以利用本地系统的所有命令。 12target: prerequisite command 由于make使用你了大量的本地系统命令，所以不能很好的跨平台。于是java有了一套自己的构建工具Ant(Another Neat Tool)。配置文件build.xml 123456789101112131415&lt;?xml version=&quot;1.0&quot;?&gt;&lt;project name=&quot;Hello&quot; default=&quot;compile&quot;&gt; &lt;target name=&quot;compile&quot; desription=&quot;compile java source code to class files&quot;&gt; &lt;mkdir dir=&quot;classes&quot;/&gt; &lt;javac srcdir=&quot;.&quot; destdir=&quot;classes/&quot;/&gt; &lt;/target&gt; &lt;target name=&quot;jar&quot; depends=&quot;compile&quot; description=&quot;create a jar file&quot;&gt; &lt;jar destfile=&quot;hello.jar&quot;&gt; &lt;fileset dir=&quot;classes&quot; includes=&quot;**/*.class&quot;/&gt; &lt;manifest&gt; &lt;attribute name=&quot;Main-Class&quot; value=&quot;HelloProgram&quot;&gt; &lt;/manifest&gt; &lt;/jar&gt; &lt;/target&gt;&lt;/project&gt; make与ant都需要显式的指定每个目标，以及完成目标所需要的工作，所以对于每个项目都需要大量的重复工作。maven只要指定构建过程，每个阶段的工作都由插件完成。maven依赖插件来完成具体工作，这些插件基本都是现成的，而且天生支持依赖管理。配置文件pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.xxx&lt;/groupId&gt; &lt;artifactId&gt;hello&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello&lt;/name&gt; &lt;description&gt;测试模板&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/profiles/$&#123;conf-dir&#125;&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;src/main/profiles/$&#123;conf-dir&#125;&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;/build&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;local&lt;/id&gt; &lt;properties&gt; &lt;env&gt;local&lt;/env&gt; &lt;conf-dir&gt;local&lt;/conf-dir&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;env&gt;dev&lt;/env&gt; &lt;conf-dir&gt;dev&lt;/conf-dir&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;properties&gt; &lt;env&gt;test&lt;/env&gt; &lt;conf-dir&gt;test&lt;/conf-dir&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;stage&lt;/id&gt; &lt;properties&gt; &lt;env&gt;stage&lt;/env&gt; &lt;conf-dir&gt;stage&lt;/conf-dir&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;env&gt;prod&lt;/env&gt; &lt;conf-dir&gt;prod&lt;/conf-dir&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt;","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"历史","slug":"历史","permalink":"http://yoursite.com/tags/历史/"}]},{"title":"理论篇-maven","date":"2017-04-10T05:49:25.000Z","path":"2017/04/10/理论篇-maven/","text":"印象中第一次接触maven是在2013年，到2017年才真正系统得学习了一下。 Maven本身解压后maven目录下包含如下内容: 1234567bin # mvn运行的脚本boot # mvn的类加载器conf # 配置文件，其中包含settings.conflib # 真正的mvn及第三方类库LICENSE.txt # 软件许可证NOTICE.txt # mvn使用的第三方软件README.txt # mvn简介 坐标系统12345groupId # 必须 当前项目隶属的实际项目 一般为 组织.实际项目artifactId # 必须 实际项目中的一个maven项目 一般为实际项目-模块version # 必须 当前模块的版本packaging # 可选 打包方式classifier # 附属构建 暂时还没弄明白 依赖范围maven在编译项目主代码的时候需要一套classpath，编译和执行测试的时候需要另一套classpath，实际运行项目的时候又会使用另一个classpath。依赖范围就是针对这三种classpath的。 依赖范围 编译 测试 运行 例子 compile Y Y Y spring-core test N Y Y JUnit provided Y Y N servlet-api runtime N Y Y JDBC system Y Y N 本地的，maven之外的类库文件 传递性依赖当依赖产生冲突的时候，按序依据如下规则进行解决: 路径最近者优先 第一声明者优先 注意:可选依赖不被传递。 仓库maven的仓库分为本地仓库和远程仓库两种。当编译项目时，优先从本地仓库获取资源，若本地仓库没有，则从远程仓库获取，若远程仓库也没有，则报错。 从仓库解析依赖的机制 当依赖的范围是system时，直接从本地文件系统解析构件 根据依赖坐标计算仓库路径后，尝试直接从本地仓库寻找构件，如果发现相应构件，则解析成功 在本地仓库不存在相应构件的情况下，如果依赖的版本是显式的发布版本构件，则遍历所有的远程仓库，发现后，下载并解析使用 如果依赖的版本是RELEASES或LATEST，则基于更新策略读取所有远程仓库的元数据groupId/artifactId/maven-metadata.xml，将其与本地仓库的对应元数据合并后，计算出RELEASES或LATEST的真实值，然后基于这个值检查本地仓库和远程仓库，如步骤2和3 如果依赖的版本是SNAPSHOT，则基于更新策略读取所有远程仓库的元数据groupId/artifactId/version/maven-metadata.xml，将其与本地仓库的对应元数据合并后，得到最新快照版本的值，然后基于该版本检查本地仓库，或者从远程仓库下载 如果最后解析得到的构建版本是时间戳格式的快照，则复制其时间戳格式的文件至非时间戳格式，并使用该非时间戳格式的构件 生命周期与插件每一个插件里包含很多功能，每一个功能就是一个插件目标 clean生命周期的各个阶段 123pre-clean # 执行一些清理前需要完成的工作clean # 清理上一次构建生成的文件post-clean # 执行一些清理后需要完成的工作 default生命周期的各个阶段 1234567891011121314151617181920212223validateinitializegenerate-sourcesprocess-sources # 处理项目主资源文件，一般来说，是对src/main/resources目录的内容进行变量替换等工作后，复制到项目输出的主classpath目录中generate-resourcesprocess-resourcescompile # 编译项目的主源码，一般来说，是编译src/main/java目录下的java文件至项目输出的主classpath目录中process-classesgenerate-test-sourcesprocess-test-sources # 处理项目测试资源文件，一般来说，是对src/test/resources目录的内容进行变量替换等工作后，复制到项目输出的测试classpath目录中generate-test-resourcesprocess-test-resourcestest-compile # 编译项目的测试源码，一般来说，是编译src/test/java目录下的java文件至项目输出的测试classpath目录中process-test-classestest # 使用单元测试框架运行测试，测试代码不会被打包或部署prepare-packagepackage # 接收编译好的代码，打包成可发布的格式 如jarpre-integration-testintegration-testpost-integration-testverifyinstall # 安装到本地仓库deploy # 发布到远程仓库 site生命周期的各个阶段 1234pre-sitesitepost-sitesite-deploy 配置文件配置文件settings.xmlsettings.xml配置文件有两个，一个是全局的，位于M2_HOME/conf/settings.xml，另一个是用户级的，位于USER_HOME/.m2/settings.xml。如果两个配置文件都存在，会合并，若出现冲突，优先采用用户级别的内容。 3.0版本之后，settings.xml文件内的值可以采用${USER_HOME}这样的变量。 配置文件的内容如下: 123456789101112131415161718192021222324252627&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;localRepository&gt; user.home/.m2/repository &lt;/localRepository&gt; # 本地仓库地址 &lt;interactiveMode&gt;true&lt;/interactiveMode&gt; &lt;usePluginRegistry&gt;false&lt;/usePluginRegistry&gt; # 是否使用user.home/.m2/plugin-registry.xml &lt;offline&gt;false&lt;/offline&gt; # 若不能联网使用true &lt;pluginGroups/&gt; &lt;servers/&gt; # 服务认证信息 &lt;mirrors/&gt; # 镜像配置 &lt;proxies&gt; # 设置代理服务器 &lt;proxy&gt; &lt;id&gt;my-proxy&lt;/id&gt; &lt;active&gt;true&lt;/active&gt; &lt;protocol&gt;http&lt;/protocol&gt; &lt;host&gt;127.0.0.1&lt;/host&gt; &lt;port&gt;8888&lt;/port&gt; &lt;!-- &lt;username/&gt; &lt;password/&gt; &lt;nonProxyHosts/&gt; --&gt; &lt;/proxy&gt; &lt;/proxies&gt; &lt;profiles/&gt; &lt;activeProfiles/&gt;&lt;/settings&gt; 配置项mirrors123456789101112&lt;mirror&gt; &lt;id/&gt; &lt;name/&gt; &lt;url/&gt; mirrorOf&gt;*&lt;/mirrorOf&gt; # 匹配所有远程仓库&lt;/mirror&gt;mirrorOf取值如下:*external:*repo1,repo2*, !repo1 配置文件pom.xmlpom.xml是每个项目的配置文件，内容如下: 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.xxx&lt;/groupId&gt; &lt;artifactId&gt;hello&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; # 值为pom时是聚合，与modules配合使用 &lt;name&gt;hello&lt;/name&gt; &lt;description&gt;测试模板&lt;/description&gt; &lt;parent/&gt; # 父模块 &lt;repositories/&gt; # 远程仓库配置 &lt;distributionManagement/&gt; # 部署远程仓库 &lt;properties/&gt; # maven属性 &lt;dependencies/&gt; &lt;build/&gt; # 插件绑定 &lt;profiles/&gt; &lt;modules/&gt; # 同时编译多个模块&lt;/project&gt; 配置项parent123456&lt;parent&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;relativePath/&gt; # 父模块路径 优先从该目录查找，若找不到，则去本地资源库&lt;/parent&gt; 配置项build1234567891011121314151617181920&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;configuration/&gt; # 插件配置 &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; # 生命周期的某个阶段 &lt;goals&gt; &lt;goal/&gt; &lt;/goals&gt; # 该阶段对应的插件目标 &lt;configuration/&gt; # 特定任务的配置 &lt;/execution&gt; &lt;executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置项distributionManagement123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id/&gt; # 远程仓库id &lt;name/&gt; # 简介 &lt;url/&gt; # 远程仓库地址 &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id/&gt; &lt;name/&gt; &lt;url/&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 配置项repositories1234567891011121314&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jboss&lt;/id&gt; &lt;name&gt;JBoss Repository&lt;/name&gt; &lt;url&gt;http://repository.jboss.com/maven2&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt;&lt;/repositories&gt; 配置项dependencies12345678910111213141516&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;type/&gt; # 对应packaging &lt;scope/&gt; # 依赖的范围 &lt;optional/&gt; # &lt;exclusions&gt; # 排除传递性依赖，若还要使用该库，则需再声明 &lt;exclusion&gt; &lt;groupId/&gt; # 只需这两项 &lt;artifactId/&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置项modules123&lt;modules&gt; &lt;module&gt;xxx&lt;/module&gt; # 值为子模块的目录&lt;/modules&gt;","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"实战篇-maven","date":"2017-04-10T03:50:06.000Z","path":"2017/04/10/实战篇-maven/","text":"官方地址 下载及安装下载二进制包，解压到自定义目录，比如third 123456tar xzvf apache-maven-3.5.0-bin.tar.gzln -s apache-maven-3.5.0 apache-mavenMac下在.bash_profile文件下增加export M2_HOME=$HOME/third/apache-mavenexport PATH=$M2_HOME/bin:$PATHmvn -v 配置完成安装之后，会在HOME目录下生成.m2目录。在.m2目录下有一个settings.xml文件。由于访问国外的源速度比较慢，所以在这里推荐阿里云的maven源。settings.xml文件的内容如下: 123456&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;&lt;/mirror&gt; 常用命令12345678mvn archetype:generatemvn clean compile # 编译mvn clean test # 测试mvn clean install # 安装资源到本地仓库mvn clean deploy # 发布资源到远程仓库mvn dependency:list # 查看所有依赖mvn dependency:tree # 查看所有依赖，以树的形式表示mvn dependency:analyze # 依赖分析 只会分析编译主代码和测试代码需要用到的依赖 搜索库","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"实战篇-装机","date":"2017-04-08T14:46:30.000Z","path":"2017/04/08/实战篇-装机/","text":"本人thinkpad笔记本电脑，原来安装了ubuntu，折腾了好长时间，终于换成了win7+centos。 不懂理论的可看下理论篇-装机 下载镜像网易开源镜像站 中科大开源镜像站 U盘安装linux系统下安装在将系统镜像写到U盘之前，需对U盘做一些处理。处理步骤如下 确定设备分区类型(MBR还是GPT) 给设备分区 给创建的分区创建文件系统 写镜像到创建的分区 123parted device # 确定设备分区类型及给设备分区mkfs.vfat device_partition # 给分区创建文件系统dd if=iso of=device_partition # 将镜像写到设备分区 网络安装服务端配置安装dhcp1234567891011121314151617yum install dhcp配置文件:/etc/dhcp/dhcpd.conf(注意: 必须与主机在同一网段内)option domain-name &quot;test&quot;;option domain-name-servers 8.8.8.8, 114.114.114.114;default-lease-time 6000;max-lease-time 7200;subnet 192.168.99.0 netmask 255.255.255.0 &#123; range 192.168.99.105 192.168.99.110; # 指定分配IP地址范围 option routers 192.168.99.1; next-server 192.168.99.250; # 指定TFTP服务器的地址 filename &quot;pxelinux.0&quot;; #指定TFTP服务器上的文件&#125;service dhcpd start 安装tftp12345yum install tftp-server tftp配置文件:/etc/xinetd.d/tftpdisable = noservice xinetd start 安装syslinux123456789yum install syslinuxcp /usr/share/syslinux/pxelinux.0 /var/lib/tftproot/mount -o loop -t iso9660 xxx.iso /mnt/cdrom # 挂在iso文件cp /mnt/cdrom/images/pxeboot/vmlinuz /var/lib/tftpboot/cp /mnt/cdrom/images/pxeboot/initrd.img /var/lib/tftpboot/mkdir /var/lib/tftpboot/pxelinux.cfgcp /mnt/cdrom/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default 安装httpd1234yum install httpdmount --bind /mnt/cdrom/ /var/www/html/cdrom/service httpd start 安装system-config-kickstart123yum install system-config-kickstart生成ks.conf 系统下安装ubuntu下安装win7准备工作: 利用ubuntu下的磁盘分区工具: GParted分出一个安装windows的磁盘空间。 下载grub4dos 1234cp grub4dos/grub.exe /dev/device_1/mount xxx.iso /mnt/cdromcp -r /mnt/cdrom/* /dev/device_1/update-grub 修改/etc/default/grub 12GRUB_HIDDEN_TIMEOUT=5GRUB_HIDDEN_TIMEOUT_QUIET=false win7下安装centos超级传送门,本人亲测,可用 各系统配置CentOS最小化安装时，默认没有安装网络管理工具NetworkManager，所以需要手动配置网络接口。文件路径:/etc/sysconfig/network-script/ifcfg-X。配置内容如下: 1234567891011121314151617181920自动获取DEVICE=eth0HWADDR=08:00:27:9F:0A:FATYPE=EthernetUUID=b25c6192-d7f9-4838-ba49-0186a1af8529ONBOOT=yesNM_CONTROLLED=noBOOTPROTO=dhcp手动设置DEVICE=eth0HWADDR=08:00:27:9F:0A:FATYPE=EthernetUUID=b25c6192-d7f9-4838-ba49-0186a1af8529ONBOOT=yesNM_CONTROLLED=noBOOTPROTO=staticNETMASK=255.255.255.0IPADDR=192.168.99.100GATEWAY=192.168.99.1","tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"理论篇-装机","date":"2017-04-08T07:31:28.000Z","path":"2017/04/08/理论篇-装机/","text":"BIOSBIOS(Basic Input/Output System)是固化在电脑硬件上的最基本的代码，保存着计算机基本输入输出程序、系统设置信息、开机后自检程序和系统自启动程序。它为计算机提供最底层、最直接的硬件设置。 UEFIUEFI(Unified Extensible Firmware Interface)是一种详细描述类型接口的标准，其主要目的是为了提供一组在OS加载之前在所有平台上一致性的、正确指定的启动服务。被看做是BIOS的替代者。 目前支持UEFI引导启动的操作系统只有Win Vista及Win7以上系统。 MBRMBR(Main Boot Record)是位于磁盘最前边的一段引导代码，由磁盘操作系统对磁盘进行初始化时产生，负责磁盘操作系统进行读写时分区合法性的判断、分区引导信息的定位。 GPTGPT(GUID Partition Table)是一个实体硬盘的分区表的结构布局标准。作为UEFI的一部分，是用来替代BIOS中的MBR。 GRUBGRUB是多重操作系统启动管理器，用来引导不同的系统，如linux、windows。","tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"电影篇-太空旅行","date":"2017-04-08T03:21:24.000Z","path":"2017/04/08/观后感-太空旅行/","text":"孤独是最可怕的，可以摧毁任何一切。当男主孤独的在飞船上生活一年多之后，于是产生了轻生的想法。 爱情是希望，爱情可以战胜孤独，可以战胜一切。当男主看到女主后，内心重新燃起了希望。 人是感官动物，总希望可以碰得到摸得着，同时，人也是一种社交动物，总希望可以和别人互动。所以，即使女主近在眼前，但对男主来说却好像远在天边。 男主是善良的。当知道唤醒女主的方法后，开始了选择的挣扎。最后，终于被孤独打败，尝试将女主唤醒。 每个人都不喜欢别人控制自己的人生。当女主知道了事情的真相后，接收不了现实，认为男主谋杀了自己。 当男主舍命拯救飞船的时候，女主开始原谅了他。因为她开始意识到了孤独的可怕。最后，男主告诉女主有一个可以重新进入休眠的机会的时候，女主最终释然了，原因很简单，她终于可以选择自己人生的方向，要么与男主一起在飞船上度过余生，要么重新进入休眠，按照之前自己预定的方向走。善良的人总会选择前者。 总体来说，这是一部非常不错的电影，值得一看！","tags":[{"name":"电影篇","slug":"电影篇","permalink":"http://yoursite.com/tags/电影篇/"}]},{"title":"理论篇-rabbitmq","date":"2017-04-01T11:55:17.000Z","path":"2017/04/01/理论篇-rabbitmq/","text":"消息队列的历史从前，有个思想活跃的小伙子突然有一个idea:为什么没有一种通用的软件总线呢？因此他设计了历史上的第一个消息队列，并且在金融领域崭露头角。后来，被其他各大公司看好，各大公司开始开发自己的商用消息队列。比如IBM MQ系列产品，微软消息队列(MSMQ)。这些商用消息队列另中小型公司望而却步，并且渐渐显现出另一个比较严重的问题:这些消息队列都是各自为营，之间不能兼容。后来，JMS诞生了，通过提供公共API的方式隐藏各个消息队列之间的差异性。后来有些人觉得这样设计还是不彻底，于是AMQP诞生了。 AMQP是消息队列的开放标准。RabbitMQ就是使用Erlang语言开发的遵从AMQP的消息队列。 连接与信道RabbitMQ使用了信道技术，好处是多个线程可以复用tcp连接。那什么是信道技术呢？官方解释，一个tcp连接上的多个虚拟连接(这就是屁话，说了半天等于没说，不明白的还是不明白)。下面讲下复用tcp连接的技术。假设，客户端与服务端有一个tcp连接，客户端有两个线程都在使用这个连接。那问题来了，两个线程同时请求服务器，服务器同时返回两个结果，我怎么区分哪个结果是哪个线程的呢？解决方案如下: 每个线程都需要一个唯一的id号。发送请求时将自己的id号发给服务器，同样服务器返回结果时，也要带上客户端发的id号。如下图所示: =========================== --------------------------- ++++ 发送请求id是1 ++++ ++++ 发送请求id是2 ++++ --------------------------- --------------------------- ++++ 返回结果id是2 ++++ ++++ 返回结果id是1 ++++ --------------------------- =========================== 因为tcp连接是全双工通信，所以发送请求和接收返回结果可以同时进行。=之间代表一个tcp连接。-之间代表tcp连接里的一个通道，其中一个用于发送请求，另一个用于接收请求。+代表一个信道，标识信道的是id。 当信道设置成confirm模式时，发布的每条消息都会获得唯一的ID。 RabbitMQ的组成部分RabbitMQ由三部分组成: 交换器、队列和绑定。三者之间的关系如下图所示: 队列消费者从队列中取出消息，并进行处理。若有多个消费者监听同一个队列，消息则以轮询的方式发送给每个消费者，消费者需对是否收到消息进行确认，若不确认，该条消息则永不删除。若连接断开，则该条消息会重新入队，发给另一个消费者。 queue.declare # 创建一个队列 * exclusive # 队列是私有的 * auto-delete # 当最后一个消费者取消订阅后，自动删除 * passive # 探测队列是否存在 basic.consume # 持续接收消息 basic.get # 只接收一条消息 basic.ack # 确认收到消息，若auto_ack=true，则收到消息后，自动确认 basic.reject # 拒绝消息 * requeue #true，消息重新入队，发给另一个消费者。false，消息直接删除。 交换器与路由规则交换器的类型: direct fanout topic和headers。headers允许匹配AMQP的header而非路由规则，类似direct，但性能稍差，使用场景不多。前三种如下图所示: fanout交换器适用于需对同一个消息做不同处理的场景。 路由规则123. 将路由规则分隔为几部分* 只匹配某一部分# 匹配0个或多个部分 相关命令12exchange.declare # 声明交换器channel.queue_bind(&quot;queue_name&quot;, &quot;exchange_name&quot;, &quot;routing_key&quot;) #绑定队列到交换器 虚拟主机一个RabbitMQ服务上可以创建多个虚拟主机，每个虚拟主机之间绝对隔离。 相关命令123rabbitmqctl list_vhosts # 列出所有虚拟主机rabbitmqctl add_vhost [vhost_name] # 增加虚拟主机rabbitmqctl delete_vhost [vhost_name] # 删除虚拟主机 消息持久化默认情况下，RabbitMQ宕机或重启后，交换器和消息队列需重新建立，队列里面的消息也随即消失。想让消息持久化存储，必须做到以下三点: 把消息的投递模式选项设置为2(持久) 发送到持久化的交换器 到达持久化的队列 持久化机制:消息到达持久化交换器时，只有将消息写入到磁盘的持久化日志文件以后才会返回结果。若消息路由到非持久化队列，则该消息将会从持久化日志文件中删除；若消息路由到持久化队列，当消费者消费了该条消息后，会从持久化日志文件中将该条消息标记为等待垃圾收集。当服务器重启后，服务器会自动重建队列、交换器以及绑定关系，重播持久化日志文件到相应的队列或交换器上(取决于服务器宕机时，消息处在路由的哪个环节)。 使用消息持久化会降低服务器性能，若对性能要求很高(100000qps)，可以使用一些其他机制来保证消息可靠到达。 事务由于RabbitMQ目的是异步处理，而事务需要同步处理，所以RabbitMQ采用publisher confirms模式实现了类似的事务机制。原理参看连接与信道","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"实践篇-java开发的环境配置","date":"2017-03-30T13:45:48.000Z","path":"2017/03/30/实战篇-java开发的环境配置/","text":"java版本管理工具jenv mac环境设置jenv add /Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home/","tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"理论篇-GNU/Linux操作系统的历史","date":"2017-03-28T13:41:28.000Z","path":"2017/03/28/理论篇-计算机世界里的重要概念/","text":"AT&amp;T是一家美国电信公司，贝尔实验室是该公司旗下的一个实验室。实验室里有两名牛逼的哥们。他们使用B语言开发了第一个版unix。后来，其中一个哥们在B语言的基础上设计了C语言。然后，unix用C语言又重写了一遍。 BSD是unix的一个衍生分支。在这个分支上，发明了很多新技术，比如socket, ipc, vi, termcap等。 GNU是由一个哥们创建的组织。该组织的目的是要制作一个类似unix的操作系统。它拥有各种工具，编译器，各种应用，但就是缺少一个内核。Linux是另一个哥们写的类似unix的操作系统内核，但是缺少周边工具来让它发挥更大的作用。 GNU/Linux是二者的组合，也就是我们平时使用的操作系统。其中，内核是Linux。shell, 编译工具链，各种实用程序和工具都是GNU软件。内核仅占整个操作系统极少的部分，大约3%。 GNU’s not UNIX. Linux’s not UNIX. GNU/Linux is UNIX. Debian也是一个致力于创建自由操作系统的组织，但是它是在GNU/Linux的基础之上。RedHat是一家开源解决方案供应商，基于GNU/Linux. Ubuntu是基于Debian的以桌面为主的操作系统。CentOS是基于RedHat的以服务器为主的操作系统。 以下是上面故事中的哥们，向他们致敬，如果没有他们，也就没有我们这群快乐的屌丝: 参考 GNU.Linux.Application.Programming","tags":[{"name":"历史","slug":"历史","permalink":"http://yoursite.com/tags/历史/"}]},{"title":"理论篇-linux之包管理的历史","date":"2017-03-27T14:40:30.000Z","path":"2017/03/27/理论篇-linux之包管理的历史/","text":"包管理的历史最初的软件包是tar.gz，人们将自己的程序打包，然后供别人免费下载使用。使用的人下载源码之后，解压，编译，使用。随着软件的发展，可用的软件越来越多，简单的打包已经不能满足人们对软件的管理，于是出现了包管理机制。 由于linux有两大阵营，所以出现了两个包管理工具:rpm和dpkg。 RedHat阵营rpmrpm(RedHat Package Manager)是以RedHat为中心的包管理工具。 123456rpm -ivh package.rpm # 安装rpm -Uvh package.rpm # 升级rpm -ev package # 卸载rpm -qlp package.rpm # 查询包中的所有文件列表rpm -qip package.rpm # 查询包中的内容信息rpm -qa # 查询系统中所有已安装的rpm包 yum由于rpm不支持依赖管理，所以每次使用rpm安装软件时，如果依赖其他包，需要我们手动下载安装依赖，显而易见，这样是很不方便的，于是yum(Yellowdog Updater Modified)出现了。yum在rpm的基础之上增加了自动更新和依赖关系管理。 123456yum search name # 在软件包详细信息中搜索指定字符串yum install name # 向系统中安装一个或多个软件包yum update name # 更新系统中的一个或多个软件包yum remove name # 从系统中移除一个或多个软件包yum erase name # 从系统中移除一个或多个软件包yum clean name # 删除缓存的数据 rpm与yum12rpm --import keyyum install package.rpm 参考 学习 Linux，101: RPM 和 YUM 包管理","tags":[{"name":"os","slug":"os","permalink":"http://yoursite.com/tags/os/"},{"name":"历史","slug":"历史","permalink":"http://yoursite.com/tags/历史/"}]},{"title":"实战篇-rabbitmq","date":"2017-03-27T13:53:44.000Z","path":"2017/03/27/实战篇-rabbitmq/","text":"安装12yum install epel-release # 安装epel源yum install rabbitmq epel是Fedora小组维护的软件仓库，为CentOS提供默认不提供的软件包。 启动与停止12345rabbitmq-server # 启动服务rabbitmq-server -detached # 以守护进程的方式启动服务rabbitmqctl stop # 关闭应用和节点rabbitmqctl stop-app # 只关闭应用rabbitmqctl stop -n rabbit@[hostname] # 关闭应用和节点 配置文件配置文件目录:/etc/rabbitmq/rabbitmq.config。配置文件内容格式如下: 1234[ &#123;mnesia, [&#123;dump_log_write_threshold, 1000&#125;]&#125;, &#123;rabbit, [&#123;vm_memory_high_watermark, 0.4&#125;]&#125;] 配置 值类型 默认值 备注 dump_log_write_threshold int 100 tcp_listeners [{“ip”, port}] [{“0.0.0.0”, 5672}] ssl_listeners [{“ip”, port}] 空 ssl_options [{key, value}] 空 vm_memory_high_watermark 十进制百分数 0.4 msg_store_file_size_limit int 字节 16777216 queue_index_max_journal_entries int 262144 管理命令通过运行rabbitmqctl -h可获得命名的具体使用方法。 1rabbitmqctl -h 安装之后需执行的命令1234rabbitmqctl [-n node_name] add_user username passwordrabbitmqctl [-n node_name] set_user_tags username administratorrabbitmqctl [-n node_name] set_permissions -p / username &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;rabbitmq-plugins [-n node_name] enable rabbitmq_management # 开启web管理插件","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/tags/rabbitmq/"}]},{"title":"实战篇-linux之常用命令","date":"2017-03-26T14:01:43.000Z","path":"2017/03/26/实战篇-linux之常用命令/","text":"配置相关1chkconfig service on/off 网络相关查看网络连接netstat -natp 参数含义 参数 含义 -n 显示数字地址 -a 显示所有监听和非监听的连接 -t tcp协议 -p 显示进程 抓包工具tcpdump -i eth0 host 127.0.0.1 and port 80 -s0 -w run.log 参数含义 参数 含义 -i 监听的接口 host 主机 port 端口 -s 设置快照的大小，默认为65535字节，0代表默认 -w 写到文件","tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"实战篇-mysql的基本操作","date":"2017-03-26T12:17:46.000Z","path":"2017/03/26/实战篇-Mysql的基本操作/","text":"服务启动Ubuntu环境1234/etc/init.d/mysql status/etc/init.d/mysql start/etc/init.d/mysql stop/setc/init.d/mysql restart CentOS环境12yum install mysql-server.x86_64/etc/init.d/mysqld start 用户相关mysql库 user表 12345678910111213select user, host from user;create user username identified by &apos;password&apos;; #创建用户rename user username1 to username2; #重命名用户drop user username; #删除用户use mysql;update user set password=password(&quot;新密码&quot;) where user=&quot;root&quot;; #更新用户密码show grants for username; #查看用户的权限GRANT ALL ON *.* TO &apos;username&apos;@&apos;%&apos;grant select on blog.* to username; #赋予用户权限grant all on *.* to username@&apos;%&apos;; #大招revoke select on blog.* from username; #收回用户权限revoke all on *.* from username; #大招flush privileges; #立即生效 user表中host的含义 host 说明 % 匹配所有主机 localhost 通过unix socket连接 127.0.0.1 通过tcp/ip, 且只能在本地连接 ::1 支持ipv6, 同127.0.0.1 权限表 权限 说明 all 所有权限 alter alter routine create create routine create temporary tables create user create view delete drop execute file grant option index insert 可以使用create index和drop index lock tables process reload 使用flush replication client replication slave select show databases show view shutdown super update usage 无访问权限 数据库相关建库建表12345create database blog; #创建数据库create table ab ( a int unsigned not null, b int unsigend not null) engine=innodb default charset=utf8 auto_increment=1; # 建表 表相关操作1234567891011121314151617181920desc table_name; # 查看表结构alter table ab add c int unsigned not null; # 新增一列ALTER TABLE tbl_name| ADD &#123;INDEX|KEY&#125; [index_name][index_type] (index_col_name, ...) [index_option] ... # 创建索引CREATE [UNIQUE] INDEX index_name[index_type]ON tbl_name (index_col_name, ...) # 创建索引alter table ab add key idx_c (c); # 新建一个索引alter table ab add key idx_c (c(10)); # 使用列值的一部分新建一个索引ALTER TABLE tbl_nameDROP PRIMARY KEY| DROP &#123;INDEX|KEY&#125; index_name # 删除索引DROP INDEX index_name ON tbl_name; # 删除索引ALTER TABLE t1 ADD COLUMN addr varchar(20) not null AFTER user1; # 增加一列 索引相关操作123ALTER TABLE ab ADD INDEX index_name (column); # 添加普通索引ALTER TABLE ab ADD INDEX index_name (column1, column2); # 添加联合索引DROP INDEX index_name on ab; # 删除索引 系统配置相关ubuntu环境，系统配置文件/etc/mysql/my.conf 12show global variables; #查看所有系统全局变量show global variables like &quot;%timeout%&quot; #查看所有与超时相关的全局变量 开放3306端口修改/etc/mysql/mysql.conf.d/mysqld.cnf 1#bind-address=127.0.0.1 #注释掉该行 新数据库设置服务配置12345678910#启动服务后mysqluse mysql;update user set password=password(&quot;新密码&quot;) where user=&quot;root&quot;; # 5.7.18不可用create user username identified by &apos;password&apos;;grant all on *.* to username@&apos;%&apos;;#配置防火墙 /etc/sysconfig/iptables-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPTservice iptables restart 5.7设置传送门 建库建表12345create database index_test;create table ab ( a int unsigned not null, b int unsigned not null) engine=innodb default charset=utf8 auto_increment=1; 查询1234567select col_name, ...from table_name1, ...(&#123;left join | right join | inner join on ...&#125;)where condition1, ...order_by col_namelimit offset countgroup by col_namehaving condition1, ... 优化12345show engine innodb status \\G # 查看innodb引擎状态show variables like &quot;xxx&quot; \\G # 查看配置参数explain sql # 查看执行计划show index from tbl_name \\G # 查看索引analyze table tbl_name; # 优化表 问题排查ERROR 1819","tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"理论篇-数据结构之B树","date":"2017-03-26T02:38:04.000Z","path":"2017/03/26/理论篇-数据结构之B树/","text":"B树的背景B树主要是为了提高硬盘的访问速度。首先，我们看下硬盘的结构: 硬盘主要由中心轴(spindle)，盘片(platter)、读写臂(arms)和读写头(read/write head)组成。读写臂可以在盘片上移动，当读写臂固定盘片转动时，读写头下面的部分称为磁道(track)。多个盘片只能增加磁盘的容量。 磁盘的访问是一种机械运动，主要包括盘片的旋转和读写臂的移动。磁盘的旋转速度一般在5400~15000RPM。盘片转动一圈需要的时间在8~11毫秒之间。然而，内存的访问速度是50纳秒。换言之，在我们等待某个数据转到读写头下的时间内，我们已经可以访问内存100000次了。 为了最小化机械运动的等待时间，一次硬盘访问不止读取一条数据，而是很多条。信息被分割为等大小的数据块，每块数据被称为一页。每页的数据在磁道内是连续的。每次硬盘读写一个或多个页。典型的配置是一页的数据包含$2^{11}$到$2^{14}$个字节。 由于访问硬盘数据的时间基本花费在读取磁盘的过程中，因此我们在关注程序执行时间的时候，主要关注两个指标:磁盘的访问次数和CPU的执行时间。硬盘的访问次数与每次访问磁盘时访问的页数量相关。 在典型的B树应用里，数据量太大以至于不能一次全部存储在内存里。B树算法从硬盘向内存拷贝需要的数据，拷贝内存中改变的数据到硬盘。在任何时间，B树只保存一定数量的页在内存中。因此，内存的大小不会限制B树能处理的数据的大小。 12345x = a pointer of some objectdisk_read(x)operations that access and/or modify the attributes of xdisk_write(x)other operations that access but do not modify attributes of x 以上是对内存中对象的典型访问方式。 B树算法的运行时间主要依赖于硬盘的读写次数。因此，我们希望每次硬盘读写尽量操作更多的数据，这样可以减少硬盘的读写次数。因此，一棵B树节点的大小通常是一个完整的硬盘页的大小。一个B树节点通常包含很多关键字，B树节点的大小和关键字的大小共同限制了B树节点能拥有的子节点的数量(即分裂因子)。分裂因子越大，树的高度越低，硬盘的访问数量越少。分裂因子一般在50~2000之间。 如上图所示，一个分裂因子为1001高度为2的B树能存储十亿个关键字。由于树的根节点一直保存在内存中，因此在这课树中访问任何一个节点至多需要两次硬盘访问。 B树的定义通常情况下，节点由关键字及与该关键字相关的其他信息页的指针组成。 B树的变种B+树B+树存储所有的相关信息在叶子节点，非叶子节点只存储关键字，这样使非叶子节点的分裂因子最大，降低树的高度，提高了访问速度。 B树的应用B树被广泛应用在数据库的索引中，比如Mysql、MongoDB。 后续会对这些具体的应用进行分析，敬请期待！","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"实战篇-新Mac之程序员的配置","date":"2017-03-26T02:27:03.000Z","path":"2017/03/26/实战篇-新Mac之程序员的配置/","text":"iterm终端调色 包管理工具 homebrew 命令行工具 coreutils 1brew install coreutils git 配置 markdown由于Mou暂时不支持10.12，暂时使用 macdown","tags":[{"name":"其它","slug":"其它","permalink":"http://yoursite.com/tags/其它/"}]},{"title":"实战篇-hexo和github搭建个人博客","date":"2017-03-25T08:17:47.000Z","path":"2017/03/25/实战篇-hexo和github搭建个人博客/","text":"安装node.js 此时会安装node和npm(js的包管理工具) 安装hexo1npm install -g hexo 使用hexo123hexo init myblog #初始化博客目录hexo generate #生成静态页面hexo server #启动服务 此时访问http://127.0.0.1:4000 如果访问成功， 恭喜安装成功 与github关联修改_confim.yml文件, 注意: 冒号后必须有空格 1234deploy: type: git repository: https://github.com/leopardpan/leopardpan.github.io.git branch: master 配置后执行如下命令 12npm install hexo-deployer-git --save #保存配置hexo deploy #发布 常用命令1234567891011部署命令hexo cleanhexo generatehexo deploy其他一些命令hexo new &quot;blog_name&quot; #新建一篇博客hexo new page &quot;page_name&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #启动本地服务调试hexo deploy #部署到github 好看的主题CoverOishiTKLTinnyppWritingYilia 强烈推荐Pacman Yilia主题相关支持latex12npm install hexo-math --savehexo math install","tags":[{"name":"blog","slug":"blog","permalink":"http://yoursite.com/tags/blog/"}]}]